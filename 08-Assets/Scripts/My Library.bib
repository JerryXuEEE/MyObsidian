@article{10315568Pdf,
  title = {{$<$}10315568.Pdf{$>$}}
}

@article{180605514Pdf,
  title = {{$<$}1806.05514.Pdf{$>$}}
}

@article{210316704Pdf,
  title = {{$<$}2103.16704.Pdf{$>$}}
}

@article{220107372Pdf,
  title = {{$<$}2201.07372.Pdf{$>$}}
}

@article{abeyasingheConsciousnessDimensionalityDOC2020,
  title = {Consciousness and the {{Dimensionality}} of {{DOC Patients}} via the {{Generalized Ising Model}}},
  author = {Abeyasinghe, Pubuditha M. and Aiello, Marco and Nichols, Emily S. and Cavaliere, Carlo and Fiorenza, Salvatore and Masotta, Orsola and Borrelli, Pasquale and Owen, Adrian M. and Estraneo, Anna and Soddu, Andrea},
  date = {2020-05},
  journaltitle = {Journal of Clinical Medicine},
  volume = {9},
  number = {5},
  pages = {1342},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2077-0383},
  doi = {10.3390/jcm9051342},
  url = {https://www.mdpi.com/2077-0383/9/5/1342},
  urldate = {2023-10-10},
  abstract = {The data from patients with severe brain injuries show complex brain functions. Due to the difficulties associated with these complex data, computational modeling is an especially useful tool to examine the structure–function relationship in these populations. By using computational modeling for patients with a disorder of consciousness (DoC), not only we can understand the changes of information transfer, but we also can test changes to different states of consciousness by hypothetically changing the anatomical structure. The generalized Ising model (GIM), which specializes in using structural connectivity to simulate functional connectivity, has been proven to effectively capture the relationship between anatomical structures and the spontaneous fluctuations of healthy controls (HCs). In the present study we implemented the GIM in 25 HCs as well as in 13 DoC patients diagnosed at three different states of consciousness. Simulated data were analyzed and the criticality and dimensionality were calculated for both groups; together, those values capture the level of information transfer in the brain. Ratifying previous studies, criticality was observed in simulations of HCs. We were also able to observe criticality for DoC patients, concluding that the GIM is generalizable for DoC patients. Furthermore, dimensionality increased for the DoC group as compared to healthy controls, and could distinguish different diagnostic groups of DoC patients.},
  issue = {5},
  langid = {english},
  keywords = {dimensionality of the brain,disorder of consciousness,functional connectivity,generalized Ising model,structural connectome},
  file = {D:\Zotero Storage\Zotero\storage\NM7DHL39\Abeyasinghe 等 - 2020 - Consciousness and the Dimensionality of DOC Patien.pdf}
}

@article{amanSensitivityTemporalStructure2021,
  title = {Sensitivity to Temporal Structure Facilitates Perceptual Analysis of Complex Auditory Scenes},
  author = {Aman, L. and Picken, S. and Andreou, L. V. and Chait, M.},
  date = {2021-02},
  journaltitle = {Hear Res},
  volume = {400},
  pages = {108111},
  issn = {1878-5891 (Electronic) 0378-5955 (Print) 0378-5955 (Linking)},
  doi = {10.1016/j.heares.2020.108111},
  abstract = {The notion that sensitivity to the statistical structure of the environment is pivotal to perception has recently garnered considerable attention. Here we investigated this issue in the context of hearing. Building on previous work (Sohoglu and Chait, 2016a; elife), stimuli were artificial 'soundscapes' populated by multiple (up to 14) simultaneous streams ('auditory objects') comprised of tone-pip sequences, each with a distinct frequency and pattern of amplitude modulation. Sequences were either temporally regular or random. We show that listeners' ability to detect abrupt appearance or disappearance of a stream is facilitated when scene streams were characterized by a temporally regular fluctuation pattern. The regularity of the changing stream as well as that of the background (non-changing) streams contribute independently to this effect. Remarkably, listeners benefit from regularity even when they are not consciously aware of it. These findings establish that perception of complex acoustic scenes relies on the availability of detailed representations of the regularities automatically extracted from multiple concurrent streams.},
  pmcid = {PMC7812374},
  keywords = {*Auditory Perception,Acoustic Stimulation,Attention,Auditory scene analysis,Change deafness,Change detection,Hearing,Predictive coding,Temporal regularity,Time perception}
}

@article{auksztulewiczCumulativeEffectsPredictability2017,
  title = {The {{Cumulative Effects}} of {{Predictability}} on {{Synaptic Gain}} in the {{Auditory Processing Stream}}},
  author = {Auksztulewicz, R. and Barascud, N. and Cooray, G. and Nobre, A. C. and Chait, M. and Friston, K.},
  date = {2017-07-12},
  journaltitle = {J Neurosci},
  volume = {37},
  number = {28},
  pages = {6751--6760},
  issn = {1529-2401 (Electronic) 0270-6474 (Print) 0270-6474 (Linking)},
  doi = {10.1523/JNEUROSCI.0291-17.2017},
  abstract = {Stimulus predictability can lead to substantial modulations of brain activity, such as shifts in sustained magnetic field amplitude, measured with magnetoencephalography (MEG). Here, we provide a mechanistic explanation of these effects using MEG data acquired from healthy human volunteers (N = 13, 7 female). In a source-level analysis of induced responses, we established the effects of orthogonal predictability manipulations of rapid tone-pip sequences (namely, sequence regularity and alphabet size) along the auditory processing stream. In auditory cortex, regular sequences with smaller alphabets induced greater gamma activity. Furthermore, sequence regularity shifted induced activity in frontal regions toward higher frequencies. To model these effects in terms of the underlying neurophysiology, we used dynamic causal modeling for cross-spectral density and estimated slow fluctuations in neural (postsynaptic) gain. Using the model-based parameters, we accurately explain the sensor-level sustained field amplitude, demonstrating that slow changes in synaptic efficacy, combined with sustained sensory input, can result in profound and sustained effects on neural responses to predictable sensory streams.SIGNIFICANCE STATEMENT Brain activity can be strongly modulated by the predictability of stimuli it is currently processing. An example of such a modulation is a shift in sustained magnetic field amplitude, measured with magnetoencephalography. Here, we provide a mechanistic explanation of these effects. First, we establish the oscillatory neural correlates of independent predictability manipulations in hierarchically distinct areas of the auditory processing stream. Next, we use a biophysically realistic computational model to explain these effects in terms of the underlying neurophysiology. Finally, using the model-based parameters describing neural gain modulation, we can explain the previously unexplained effects observed at the sensor level. This demonstrates that slow modulations of synaptic gain can result in profound and sustained effects on neural activity.},
  pmcid = {PMC5508257},
  keywords = {Acoustic Stimulation,Adult,{Anticipation, Psychological/*physiology},Attention/physiology,Auditory Cortex/*physiology,Auditory Pathways/*physiology,Auditory Perception/*physiology,auditory processing,dynamic causal modeling,Female,gain modulation,Humans,Long-Term Potentiation/*physiology,magnetoencephalography,Male,neural oscillations,predictive coding,Synaptic Transmission/*physiology}
}

@article{baekenAcceleratedHFrTMSTreatmentresistant2014,
  title = {Accelerated {{HF-rTMS}} in Treatment-Resistant Unipolar Depression: {{Insights}} from Subgenual Anterior Cingulate Functional Connectivity},
  shorttitle = {Accelerated {{HF-rTMS}} in Treatment-Resistant Unipolar Depression},
  author = {Baeken, Chris and Marinazzo, Daniele and Wu, Guo-Rong and Van Schuerbeek, Peter and De Mey, Johan and Marchetti, Igor and Vanderhasselt, Marie-Anne and Remue, Jonathan and Luypaert, Robert and De Raedt, Rudi},
  date = {2014-05},
  journaltitle = {The World Journal of Biological Psychiatry},
  shortjournal = {The World Journal of Biological Psychiatry},
  volume = {15},
  number = {4},
  pages = {286--297},
  issn = {1562-2975, 1814-1412},
  doi = {10.3109/15622975.2013.872295},
  url = {http://www.tandfonline.com/doi/full/10.3109/15622975.2013.872295},
  urldate = {2023-09-05},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\XWYTWQ8B\Baeken et al. - 2014 - Accelerated HF-rTMS in treatment-resistant unipola.pdf}
}

@article{baekenRepetitiveTranscranialMagnetic2019,
  title = {Repetitive Transcranial Magnetic Stimulation Treatment for Depressive Disorders: Current Knowledge and Future Directions},
  shorttitle = {Repetitive Transcranial Magnetic Stimulation Treatment for Depressive Disorders},
  author = {Baeken, Chris and Brem, Anna-Katharine and Arns, Martijn and Brunoni, Andre R. and Filipčić, Igor and Ganho-Ávila, Ana and Langguth, Berthold and Padberg, Frank and Poulet, Emmanuel and Rachid, Fady and Sack, Alexander T. and Vanderhasselt, Marie-Anne and Bennabi, Djamila},
  date = {2019-09},
  journaltitle = {Current Opinion in Psychiatry},
  volume = {32},
  number = {5},
  pages = {409--415},
  issn = {0951-7367},
  doi = {10.1097/YCO.0000000000000533},
  url = {https://journals.lww.com/10.1097/YCO.0000000000000533},
  urldate = {2023-09-05},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@baekenRepetitiveTranscranialMagnetic2019.md;D\:\\Zotero Storage\\Zotero\\storage\\QDGURG9K\\Baeken et al. - 2019 - Repetitive transcranial magnetic stimulation treat.pdf}
}

@article{bailletMagnetoencephalographyBrainElectrophysiology2017,
  title = {Magnetoencephalography for Brain Electrophysiology and Imaging},
  author = {Baillet, Sylvain},
  date = {2017-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {3},
  pages = {327--339},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4504},
  url = {https://www.nature.com/articles/nn.4504},
  urldate = {2023-12-14},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\AZM9ICRX\Baillet - 2017 - Magnetoencephalography for brain electrophysiology.pdf}
}

@article{bailletMagnetoencephalographyBrainElectrophysiology2017a,
  title = {Magnetoencephalography for Brain Electrophysiology and Imaging},
  author = {Baillet, Sylvain},
  date = {2017-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {3},
  pages = {327--339},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4504},
  url = {https://www.nature.com/articles/nn.4504},
  urldate = {2023-12-18},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\23ZUUJ4X\Baillet - 2017 - Magnetoencephalography for brain electrophysiology.pdf}
}

@article{bakerDeepConvolutionalNetworks2018,
  title = {Deep Convolutional Networks Do Not Classify Based on Global Object Shape},
  author = {Baker, N. and Lu, H. and Erlikhman, G. and Kellman, P. J.},
  date = {2018-12},
  journaltitle = {PLoS Comput Biol},
  volume = {14},
  number = {12},
  pages = {e1006613},
  issn = {1553-7358 (Electronic) 1553-734X (Linking)},
  doi = {10.1371/journal.pcbi.1006613},
  abstract = {Deep convolutional networks (DCNNs) are achieving previously unseen performance in object classification, raising questions about whether DCNNs operate similarly to human vision. In biological vision, shape is arguably the most important cue for recognition. We tested the role of shape information in DCNNs trained to recognize objects. In Experiment 1, we presented a trained DCNN with object silhouettes that preserved overall shape but were filled with surface texture taken from other objects. Shape cues appeared to play some role in the classification of artifacts, but little or none for animals. In Experiments 2-4, DCNNs showed no ability to classify glass figurines or outlines but correctly classified some silhouettes. Aspects of these results led us to hypothesize that DCNNs do not distinguish object's bounding contours from other edges, and that DCNNs access some local shape features, but not global shape. In Experiment 5, we tested this hypothesis with displays that preserved local features but disrupted global shape, and vice versa. With disrupted global shape, which reduced human accuracy to 28\%, DCNNs gave the same classification labels as with ordinary shapes. Conversely, local contour changes eliminated accurate DCNN classification but caused no difficulty for human observers. These results provide evidence that DCNNs have access to some local shape information in the form of local edge relations, but they have no access to global object shapes.},
  pmcid = {PMC6306249},
  keywords = {*Form Perception,{*Neural Networks, Computer},Animals,Computational Biology,Deep Learning,Humans,{Pattern Recognition, Automated/*statistics \& numerical data},{Pattern Recognition, Visual},Photic Stimulation}
}

@article{barlowPossiblePrinciplesUnderlying1961,
  title = {Possible Principles Underlying the Transformation of Sensory Messages},
  author = {family=Barlow, given=Horace B. \%J Sensory, prefix=communication, useprefix=false},
  date = {1961},
  volume = {1},
  number = {01}
}

@article{batailNetworkEffectsStanford2023,
  title = {Network Effects of {{Stanford Neuromodulation Therapy}} ({{SNT}}) in Treatment-Resistant Major Depressive Disorder: A Randomized, Controlled Trial},
  shorttitle = {Network Effects of {{Stanford Neuromodulation Therapy}} ({{SNT}}) in Treatment-Resistant Major Depressive Disorder},
  author = {Batail, Jean-Marie and Xiao, Xiaoqian and Azeez, Azeezat and Tischler, Claudia and Kratter, Ian H. and Bishop, James H. and Saggar, Manish and Williams, Nolan R.},
  date = {2023-07-03},
  journaltitle = {Translational Psychiatry},
  shortjournal = {Transl Psychiatry},
  volume = {13},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {2158-3188},
  doi = {10.1038/s41398-023-02537-9},
  url = {https://www.nature.com/articles/s41398-023-02537-9},
  urldate = {2023-09-24},
  abstract = {Here, we investigated the brain functional connectivity (FC) changes following a novel accelerated theta burst stimulation protocol known as Stanford Neuromodulation Therapy (SNT) which demonstrated significant antidepressant efficacy in treatment-resistant depression (TRD). In a sample of 24 patients (12 active and 12 sham), active stimulation was associated with significant pre- and post-treatment modulation of three FC pairs, involving the default mode network (DMN), amygdala, salience network (SN) and striatum. The most robust finding was the SNT effect on amygdala-DMN FC (group*time interaction F(1,22)\,=\,14.89, p\,{$<$}\,0.001). This FC change correlated with improvement in depressive symptoms (rho (Spearman) = −0.45, df\,=\,22, p\,=\,0.026). The post-treatment FC pattern showed a change in the direction of the healthy control group and was sustained at the one-month follow-up. These results are consistent with amygdala-DMN connectivity dysfunction as an underlying mechanism of TRD and bring us closer to the goal of developing imaging biomarkers for TMS treatment optimization.},
  issue = {1},
  langid = {english},
  keywords = {Depression,Predictive markers},
  file = {D:\Zotero Storage\Zotero\storage\AY68MD6C\Batail 等 - 2023 - Network effects of Stanford Neuromodulation Therap.pdf}
}

@article{battistonNetworksPairwiseInteractions2020,
  title = {Networks beyond Pairwise Interactions: {{Structure}} and Dynamics},
  shorttitle = {Networks beyond Pairwise Interactions},
  author = {Battiston, Federico and Cencetti, Giulia and Iacopini, Iacopo and Latora, Vito and Lucas, Maxime and Patania, Alice and Young, Jean-Gabriel and Petri, Giovanni},
  date = {2020-08-25},
  journaltitle = {Physics Reports},
  shortjournal = {Physics Reports},
  series = {Networks beyond Pairwise Interactions: {{Structure}} and Dynamics},
  volume = {874},
  pages = {1--92},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2020.05.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0370157320302489},
  urldate = {2023-10-10},
  abstract = {The complexity of many biological, social and technological systems stems from the richness of the interactions among their units. Over the past decades, a variety of complex systems has been successfully described as networks whose interacting pairs of nodes are connected by links. Yet, from human communications to chemical reactions and ecological systems, interactions can often occur in groups of three or more nodes and cannot be described simply in terms of dyads. Until recently little attention has been devoted to the higher-order architecture of real complex systems. However, a mounting body of evidence is showing that taking the higher-order structure of these systems into account can enhance our modeling capacities and help us understand and predict their dynamical behavior. Here we present a complete overview of the emerging field of networks beyond pairwise interactions. We discuss how to represent higher-order interactions and introduce the different frameworks used to describe higher-order systems, highlighting the links between the existing concepts and representations. We review the measures designed to characterize the structure of these systems and the models proposed to generate synthetic structures, such as random and growing bipartite graphs, hypergraphs and simplicial complexes. We introduce the rapidly growing research on higher-order dynamical systems and dynamical topology, discussing the relations between higher-order interactions and collective behavior. We focus in particular on new emergent phenomena characterizing dynamical processes, such as diffusion, synchronization, spreading, social dynamics and games, when extended beyond pairwise interactions. We conclude with a summary of empirical applications, and an outlook on current modeling and conceptual frontiers.},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\battistonNetworksPairwiseInteractions2020 - 注释 (20231010 下午10510).md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\battistonNetworksPairwiseInteractions2020.md;D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Physics Reports2020Battiston et alNetworks beyond pairwise interactionsPhysics ReportsPhysics Reports8741-92CompNeuro_Literature\\IsingBattistonF et alFB et al期刊文章\\2020_-Networks beyond pairwise interactions.pdf;D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Physics Reports2020Battiston et alNetworks beyond pairwise interactionsPhysics ReportsPhysics Reports8741-92CompNeuro_Literature\\IsingBattistonF et alFB et al期刊文章\\2020_-Networks beyond pairwise interactions2.pdf}
}

@article{battistonNetworksPairwiseInteractions2020a,
  title = {Networks beyond Pairwise Interactions: {{Structure}} and Dynamics},
  shorttitle = {Networks beyond Pairwise Interactions},
  author = {Battiston, Federico and Cencetti, Giulia and Iacopini, Iacopo and Latora, Vito and Lucas, Maxime and Patania, Alice and Young, Jean-Gabriel and Petri, Giovanni},
  date = {2020-08-25},
  journaltitle = {Physics Reports},
  shortjournal = {Physics Reports},
  series = {Networks beyond Pairwise Interactions: {{Structure}} and Dynamics},
  volume = {874},
  pages = {1--92},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2020.05.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0370157320302489},
  urldate = {2023-10-10},
  abstract = {The complexity of many biological, social and technological systems stems from the richness of the interactions among their units. Over the past decades, a variety of complex systems has been successfully described as networks whose interacting pairs of nodes are connected by links. Yet, from human communications to chemical reactions and ecological systems, interactions can often occur in groups of three or more nodes and cannot be described simply in terms of dyads. Until recently little attention has been devoted to the higher-order architecture of real complex systems. However, a mounting body of evidence is showing that taking the higher-order structure of these systems into account can enhance our modeling capacities and help us understand and predict their dynamical behavior. Here we present a complete overview of the emerging field of networks beyond pairwise interactions. We discuss how to represent higher-order interactions and introduce the different frameworks used to describe higher-order systems, highlighting the links between the existing concepts and representations. We review the measures designed to characterize the structure of these systems and the models proposed to generate synthetic structures, such as random and growing bipartite graphs, hypergraphs and simplicial complexes. We introduce the rapidly growing research on higher-order dynamical systems and dynamical topology, discussing the relations between higher-order interactions and collective behavior. We focus in particular on new emergent phenomena characterizing dynamical processes, such as diffusion, synchronization, spreading, social dynamics and games, when extended beyond pairwise interactions. We conclude with a summary of empirical applications, and an outlook on current modeling and conceptual frontiers.},
  file = {D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Physics Reports2020Battiston et alNetworks beyond pairwise interactionsPhysics ReportsPhysics Reports8741-92CompNeuro_Literature\\IsingBattistonF et alFB et al期刊文章\\2020_-Networks beyond pairwise interactions3.pdf;D\:\\Zotero Storage\\Zotero\\storage\\GB9SX8KB\\S0370157320302489.html}
}

@article{berkesSpontaneousCorticalActivity2011,
  title = {Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment},
  author = {Berkes, Pietro and Orbán, Gergő and Lengyel, Máté and Fiser, József \%J Science},
  date = {2011},
  volume = {331},
  number = {6013},
  pages = {83--87},
  issn = {0036-8075},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\2006Schwartz et alSpike-triggered neural characterization6413-13CompNeuro_UncategorizedSchwartzO et alOS et alJournal Article\2006_-Spike-triggered neural characterization.pdf}
}

@article{berkesSpontaneousCorticalActivity2011a,
  title = {Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment},
  author = {Berkes, Pietro and Orbán, Gergo and Lengyel, Máté and Fiser, József},
  date = {2011-01-07},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {331},
  number = {6013},
  eprint = {21212356},
  eprinttype = {pmid},
  pages = {83--87},
  issn = {1095-9203},
  doi = {10.1126/science.1195870},
  abstract = {The brain maintains internal models of its environment to interpret sensory inputs and to prepare actions. Although behavioral studies have demonstrated that these internal models are optimally adapted to the statistics of the environment, the neural underpinning of this adaptation is unknown. Using a Bayesian model of sensory cortical processing, we related stimulus-evoked and spontaneous neural activities to inferences and prior expectations in an internal model and predicted that they should match if the model is statistically optimal. To test this prediction, we analyzed visual cortical activity of awake ferrets during development. Similarity between spontaneous and evoked activities increased with age and was specific to responses evoked by natural scenes. This demonstrates the progressive adaptation of internal models to the statistics of natural stimuli at the neural level.},
  langid = {english},
  pmcid = {PMC3065813},
  keywords = {Action Potentials,{Adaptation, Physiological},Aging,Animals,Bayes Theorem,Darkness,{Electrodes, Implanted},{Evoked Potentials, Visual},Ferrets,{Models, Neurological},Neurons,Photic Stimulation,Visual Cortex,Visual Perception},
  file = {D:\Zotero Storage\Zotero\storage\SR64GUL2\Berkes et al. - 2011 - Spontaneous cortical activity reveals hallmarks of.pdf}
}

@article{biUnderstandingComputationTime2020,
  title = {Understanding the Computation of Time Using Neural Network Models},
  author = {Bi, Z. and Zhou, C.},
  date = {2020-05-12},
  journaltitle = {Proc Natl Acad Sci U S A},
  volume = {117},
  number = {19},
  pages = {10530--10540},
  issn = {1091-6490 (Electronic) 0027-8424 (Print) 0027-8424 (Linking)},
  doi = {10.1073/pnas.1921609117},
  abstract = {To maximize future rewards in this ever-changing world, animals must be able to discover the temporal structure of stimuli and then anticipate or act correctly at the right time. How do animals perceive, maintain, and use time intervals ranging from hundreds of milliseconds to multiseconds in working memory? How is temporal information processed concurrently with spatial information and decision making? Why are there strong neuronal temporal signals in tasks in which temporal information is not required? A systematic understanding of the underlying neural mechanisms is still lacking. Here, we addressed these problems using supervised training of recurrent neural network models. We revealed that neural networks perceive elapsed time through state evolution along stereotypical trajectory, maintain time intervals in working memory in the monotonic increase or decrease of the firing rates of interval-tuned neurons, and compare or produce time intervals by scaling state evolution speed. Temporal and nontemporal information is coded in subspaces orthogonal with each other, and the state trajectories with time at different nontemporal information are quasiparallel and isomorphic. Such coding geometry facilitates the decoding generalizability of temporal and nontemporal information across each other. The network structure exhibits multiple feedforward sequences that mutually excite or inhibit depending on whether their preferences of nontemporal information are similar or not. We identified four factors that facilitate strong temporal signals in nontiming tasks, including the anticipation of coming events. Our work discloses fundamental computational principles of temporal processing, and it is supported by and gives predictions to a number of experimental phenomena.},
  pmcid = {PMC7229760},
  keywords = {interval timing,neural network model,population coding}
}

@article{biUnderstandingComputationTime2020a,
  title = {Understanding the Computation of Time Using Neural Network Models},
  author = {Bi, Zedong and Zhou, Changsong},
  date = {2020-05-12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {117},
  number = {19},
  pages = {10530--10540},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1921609117},
  url = {https://pnas.org/doi/full/10.1073/pnas.1921609117},
  urldate = {2023-08-21},
  abstract = {To maximize future rewards in this ever-changing world, animals must be able to discover the temporal structure of stimuli and then anticipate or act correctly at the right time. How do animals perceive, maintain, and use time intervals ranging from hundreds of milliseconds to multiseconds in working memory? How is temporal information processed concurrently with spatial information and decision making? Why are there strong neuronal temporal signals in tasks in which temporal information is not required? A systematic understanding of the underlying neural mechanisms is still lacking. Here, we addressed these problems using supervised training of recurrent neural network models. We revealed that neural networks perceive elapsed time through state evolution along stereotypical trajectory, maintain time intervals in working memory in the monotonic increase or decrease of the firing rates of interval-tuned neurons, and compare or produce time intervals by scaling state evolution speed. Temporal and nontemporal information is coded in subspaces orthogonal with each other, and the state trajectories with time at different nontemporal information are quasiparallel and isomorphic. Such coding geometry facilitates the decoding generalizability of temporal and nontemporal information across each other. The network structure exhibits multiple feedforward sequences that mutually excite or inhibit depending on whether their preferences of nontemporal information are similar or not. We identified four factors that facilitate strong temporal signals in nontiming tasks, including the anticipation of coming events. Our work discloses fundamental computational principles of temporal processing, and it is supported by and gives predictions to a number of experimental phenomena.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@biUnderstandingComputationTime2020a.md;D\:\\Zotero Storage\\Zotero\\storage\\QJLZWF6Q\\Bi and Zhou - 2020 - Understanding the computation of time using neural.pdf;D\:\\Zotero Storage\\Zotero\\storage\\XPLPQS2E\\10.1073@pnas.1921609117.pdf.pdf}
}

@online{BrainSciencesFree,
  title = {Brain {{Sciences}} | {{Free Full-Text}} | {{A Review}} of {{Issues Related}} to {{Data Acquisition}} and {{Analysis}} in {{EEG}}/{{MEG Studies}}},
  url = {https://www.mdpi.com/2076-3425/7/6/58},
  urldate = {2023-11-21}
}

@online{BrainSciencesFreea,
  title = {Brain {{Sciences}} | {{Free Full-Text}} | {{A Review}} of {{Issues Related}} to {{Data Acquisition}} and {{Analysis}} in {{EEG}}/{{MEG Studies}}},
  url = {https://www.mdpi.com/2076-3425/7/6/58},
  urldate = {2023-11-24},
  file = {D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Brain Sciences  Free Full-Text  A Review of Issues Related to DataCompNeuro_Literature\\Unread网页\\-Brain Sciences Free Full-Text A Review of Issues Related to Data.pdf;D\:\\Zotero Storage\\Zotero\\storage\\NVDMJR3V\\58.html}
}

@article{breakspearDynamicModelsLargescale2017,
  title = {Dynamic Models of Large-Scale Brain Activity},
  author = {Breakspear, Michael},
  date = {2017-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {3},
  pages = {340--352},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4497},
  url = {https://www.nature.com/articles/nn.4497},
  urldate = {2023-11-23},
  abstract = {Cognitive activity requires the collective behavior of cortical, thalamic and spinal neurons across large-scale systems of the CNS. This paper provides an illustrated introduction to dynamic models of large-scale brain activity, from the tenets of the underlying theory to challenges, controversies and recent breakthroughs.},
  issue = {3},
  langid = {english},
  keywords = {Computational models,Dynamical systems},
  file = {D:\Zotero Storage\Zotero\storage\XJ7ZGP96\Breakspear - 2017 - Dynamic models of large-scale brain activity.pdf}
}

@article{brownReinforcementLearningDisruptions2021,
  title = {Reinforcement {{Learning Disruptions}} in {{Individuals With Depression}} and {{Sensitivity}} to {{Symptom Change Following Cognitive Behavioral Therapy}}},
  author = {Brown, Vanessa M. and Zhu, Lusha and Solway, Alec and Wang, John M. and McCurry, Katherine L. and King-Casas, Brooks and Chiu, Pearl H.},
  date = {2021-10-01},
  journaltitle = {JAMA Psychiatry},
  shortjournal = {JAMA Psychiatry},
  volume = {78},
  number = {10},
  pages = {1113--1122},
  issn = {2168-622X},
  doi = {10.1001/jamapsychiatry.2021.1844},
  url = {https://doi.org/10.1001/jamapsychiatry.2021.1844},
  urldate = {2023-10-16},
  abstract = {Major depressive disorder is prevalent and impairing. Parsing neurocomputational substrates of reinforcement learning in individuals with depression may facilitate a mechanistic understanding of the disorder and suggest new cognitive therapeutic targets.To determine associations among computational model–derived reinforcement learning parameters, depression symptoms, and symptom changes after treatment.In this mixed cross-sectional–cohort study, individuals performed reward and loss variants of a probabilistic learning task during functional magnetic resonance imaging at baseline and follow-up. A volunteer sample with and without a depression diagnosis was recruited from the community. Participants were assessed from July 2011 to February 2017, and data were analyzed from May 2017 to May 2021.Computational model–based analyses of participants’ choices assessed a priori hypotheses about associations between components of reward-based and loss-based learning with depression symptoms. Changes in both learning parameters and symptoms were then assessed in a subset of participants who received cognitive behavioral therapy (CBT).Of 101 included adults, 69 (68.3\%) were female, and the mean (SD) age was 34.4 (11.2) years. A total of 69 participants with a depression diagnosis and 32 participants without a depression diagnosis were included at baseline; 48 participants (28 with depression who received CBT and 20 without depression) were included at follow-up (mean [SD] of 115.1 [15.6] days). Computational model–based analyses of behavioral choices and neural data identified associations of learning with symptoms during reward learning and loss learning, respectively. During reward learning only, anhedonia (and not negative affect or arousal) was associated with model-derived learning parameters (learning rate: posterior mean regression β\,=\,−0.14; 95\% credible interval [CrI], −0.12 to −0.03; outcome sensitivity: posterior mean regression β\,=\,0.18; 95\% CrI, 0.02 to 0.37) and neural learning signals (moderation of association between striatal prediction error and expected value signals: t97\,=\,−2.10; P\,=\,.04). During loss learning only, negative affect (and not anhedonia or arousal) was associated with learning parameters (outcome shift: posterior mean regression β\,=\,−0.11; 95\% CrI, −0.20 to −0.01) and disrupted neural encoding of learning signals (association with subgenual anterior cingulate prediction error signals: r\,=\,−0.28; P\,=\,.005). Symptom improvement following CBT was associated with normalization of learning parameters that were disrupted at baseline (reward learning rate: posterior mean regression β\,=\,0.15; 90\% CrI, 0.001 to 0.41; loss outcome shift: posterior mean regression β\,=\,0.42; 90\% CrI, 0.09 to 0.77).In this study, the mapping of reinforcement learning components to symptoms of major depression revealed mechanistic features associated with these symptoms and points to possible learning-based therapeutic processes and targets.},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\58GPLKTC\\Brown 等 - 2021 - Reinforcement Learning Disruptions in Individuals .pdf;D\:\\Zotero Storage\\Zotero\\storage\\Y6VHFGWB\\2782452.html}
}

@article{bruiningMeasurementExcitationinhibitionRatio2020,
  title = {Measurement of Excitation-Inhibition Ratio in Autism Spectrum Disorder Using Critical Brain Dynamics},
  author = {Bruining, Hilgo and Hardstone, Richard and Juarez-Martinez, Erika L. and Sprengers, Jan and Avramiea, Arthur-Ervin and Simpraga, Sonja and Houtman, Simon J. and Poil, Simon-Shlomo and Dallares, Eva and Palva, Satu and Oranje, Bob and Matias Palva, J. and Mansvelder, Huibert D. and Linkenkaer-Hansen, Klaus},
  date = {2020-06-08},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {10},
  number = {1},
  pages = {9195},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-65500-4},
  url = {https://www.nature.com/articles/s41598-020-65500-4},
  urldate = {2023-08-19},
  abstract = {Abstract                            Balance between excitation (E) and inhibition (I) is a key principle for neuronal network organization and information processing. Consistent with this notion, excitation-inhibition imbalances are considered a pathophysiological mechanism in many brain disorders including autism spectrum disorder (ASD). However, methods to measure E/I ratios in human brain networks are lacking. Here, we present a method to quantify a functional E/I ratio (               fE               /               I               ) from neuronal oscillations, and validate it in healthy subjects and children with ASD. We define structural E/I ratio in an               in silico               neuronal network, investigate how it relates to power and long-range temporal correlations (LRTC) of the network’s activity, and use these relationships to design the               fE               /               I               algorithm. Application of this algorithm to the EEGs of healthy adults showed that               fE               /               I               is balanced at the population level and is decreased through GABAergic enforcement. In children with ASD, we observed larger               fE               /               I               variability and stronger LRTC compared to typically developing children (TDC). Interestingly, visual grading for EEG abnormalities that are thought to reflect E/I imbalances revealed elevated               fE               /               I               and LRTC in ASD children with normal EEG compared to TDC or ASD with abnormal EEG. We speculate that our approach will help understand physiological heterogeneity also in other brain disorders.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@bruiningMeasurementExcitationinhibitionRatio2020.md;D\:\\Zotero Storage\\Zotero\\storage\\Q59PFVQW\\Bruining et al. - 2020 - Measurement of excitation-inhibition ratio in auti.pdf;D\:\\Zotero Storage\\Zotero\\storage\\RYNA3GCE\\10.1038@s41598-020-65500-4.pdf.pdf}
}

@article{brunoniRepetitiveTranscranialMagnetic2017,
  title = {Repetitive {{Transcranial Magnetic Stimulation}} for the {{Acute Treatment}} of {{Major Depressive Episodes}}: {{A Systematic Review With Network Meta-analysis}}},
  shorttitle = {Repetitive {{Transcranial Magnetic Stimulation}} for the {{Acute Treatment}} of {{Major Depressive Episodes}}},
  author = {Brunoni, Andre R. and Chaimani, Anna and Moffa, Adriano H. and Razza, Lais B. and Gattaz, Wagner F. and Daskalakis, Zafiris J. and Carvalho, Andre F.},
  date = {2017-02-01},
  journaltitle = {JAMA Psychiatry},
  shortjournal = {JAMA Psychiatry},
  volume = {74},
  number = {2},
  pages = {143},
  issn = {2168-622X},
  doi = {10.1001/jamapsychiatry.2016.3644},
  url = {http://archpsyc.jamanetwork.com/article.aspx?doi=10.1001/jamapsychiatry.2016.3644},
  urldate = {2023-09-05},
  langid = {english}
}

@article{brunoniRepetitiveTranscranialMagnetic2017a,
  title = {Repetitive {{Transcranial Magnetic Stimulation}} for the {{Acute Treatment}} of {{Major Depressive Episodes}}: {{A Systematic Review With Network Meta-analysis}}},
  shorttitle = {Repetitive {{Transcranial Magnetic Stimulation}} for the {{Acute Treatment}} of {{Major Depressive Episodes}}},
  author = {Brunoni, Andre R. and Chaimani, Anna and Moffa, Adriano H. and Razza, Lais B. and Gattaz, Wagner F. and Daskalakis, Zafiris J. and Carvalho, Andre F.},
  date = {2017-02-01},
  journaltitle = {JAMA Psychiatry},
  shortjournal = {JAMA Psychiatry},
  volume = {74},
  number = {2},
  pages = {143},
  issn = {2168-622X},
  doi = {10.1001/jamapsychiatry.2016.3644},
  url = {http://archpsyc.jamanetwork.com/article.aspx?doi=10.1001/jamapsychiatry.2016.3644},
  urldate = {2023-09-05},
  abstract = {OBJECTIVE To establish the relative efficacy and acceptability of the different modalities of rTMS used for MDD by performing a network meta-analysis, obtaining a clinically meaningful treatment hierarchy. DATA SOURCES PubMed/MEDLINE, EMBASE, PsycInfo, and Web of Science were searched up until October 1, 2016. STUDY SELECTION Randomized clinical trials that compared any rTMS intervention with sham or another rTMS intervention. Trials performing less than 10 sessions were excluded. DATA EXTRACTION AND SYNTHESIS Two independent reviewers used standard forms for data extraction and quality assessment. Random-effects, standard pairwise, and network meta-analyses were performed to synthesize data. MAIN OUTCOMES AND MEASURES Response rates and acceptability (dropout rate). Remission was the secondary outcome. Effect sizes were reported as odds ratios (ORs) with 95\% CIs. RESULTS Eighty-one studies (4233 patients, 59.1\% women, mean age of 46 years) were included. The interventions more effective than sham were priming low-frequency (OR, 4.66; 95\% CI, 1.70-12.77), bilateral (OR, 3.96; 95\% CI, 2.37-6.60), high-frequency (OR, 3.07; 95\% CI, 2.24-4.21), θ-burst stimulation (OR, 2.54; 95\% CI, 1.07-6.05), and low-frequency (OR, 2.37; 95\% CI, 1.52-3.68) rTMS. Novel rTMS interventions (accelerated, synchronized, and deep rTMS) were not more effective than sham. Except for θ-burst stimulation vs sham, similar results were obtained for remission. All interventions were at least as acceptable as sham. The estimated relative ranking of treatments suggested that priming low-frequency and bilateral rTMS might be the most efficacious and acceptable interventions among all rTMS strategies. However, results were imprecise and relatively few trials were available for interventions other than low-frequency, high-frequency, and bilateral rTMS. Supplemental content CONCLUSIONS AND RELEVANCE Few differences were found in clinical efficacy and acceptability between the different rTMS modalities, favoring to some extent bilateral rTMS and priming low-frequency rTMS respectively. These findings warrant the design of larger RCTs investigating the potential of these approaches in the short-term treatment of MDD. Current evidence cannot support novel rTMS interventions as a treatment for MDD.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\8HIXSRRU\Brunoni et al. - 2017 - Repetitive Transcranial Magnetic Stimulation for t.pdf}
}

@article{brunoniRepetitiveTranscranialMagnetic2017b,
  title = {Repetitive {{Transcranial Magnetic Stimulation}} for the {{Acute Treatment}} of {{Major Depressive Episodes}}: {{A Systematic Review With Network Meta-analysis}}},
  shorttitle = {Repetitive {{Transcranial Magnetic Stimulation}} for the {{Acute Treatment}} of {{Major Depressive Episodes}}},
  author = {Brunoni, Andre R. and Chaimani, Anna and Moffa, Adriano H. and Razza, Lais B. and Gattaz, Wagner F. and Daskalakis, Zafiris J. and Carvalho, Andre F.},
  date = {2017-02-01},
  journaltitle = {JAMA Psychiatry},
  shortjournal = {JAMA Psychiatry},
  volume = {74},
  number = {2},
  pages = {143},
  issn = {2168-622X},
  doi = {10.1001/jamapsychiatry.2016.3644},
  url = {http://archpsyc.jamanetwork.com/article.aspx?doi=10.1001/jamapsychiatry.2016.3644},
  urldate = {2023-09-05},
  abstract = {OBJECTIVE To establish the relative efficacy and acceptability of the different modalities of rTMS used for MDD by performing a network meta-analysis, obtaining a clinically meaningful treatment hierarchy. DATA SOURCES PubMed/MEDLINE, EMBASE, PsycInfo, and Web of Science were searched up until October 1, 2016. STUDY SELECTION Randomized clinical trials that compared any rTMS intervention with sham or another rTMS intervention. Trials performing less than 10 sessions were excluded. DATA EXTRACTION AND SYNTHESIS Two independent reviewers used standard forms for data extraction and quality assessment. Random-effects, standard pairwise, and network meta-analyses were performed to synthesize data. MAIN OUTCOMES AND MEASURES Response rates and acceptability (dropout rate). Remission was the secondary outcome. Effect sizes were reported as odds ratios (ORs) with 95\% CIs. RESULTS Eighty-one studies (4233 patients, 59.1\% women, mean age of 46 years) were included. The interventions more effective than sham were priming low-frequency (OR, 4.66; 95\% CI, 1.70-12.77), bilateral (OR, 3.96; 95\% CI, 2.37-6.60), high-frequency (OR, 3.07; 95\% CI, 2.24-4.21), θ-burst stimulation (OR, 2.54; 95\% CI, 1.07-6.05), and low-frequency (OR, 2.37; 95\% CI, 1.52-3.68) rTMS. Novel rTMS interventions (accelerated, synchronized, and deep rTMS) were not more effective than sham. Except for θ-burst stimulation vs sham, similar results were obtained for remission. All interventions were at least as acceptable as sham. The estimated relative ranking of treatments suggested that priming low-frequency and bilateral rTMS might be the most efficacious and acceptable interventions among all rTMS strategies. However, results were imprecise and relatively few trials were available for interventions other than low-frequency, high-frequency, and bilateral rTMS. Supplemental content CONCLUSIONS AND RELEVANCE Few differences were found in clinical efficacy and acceptability between the different rTMS modalities, favoring to some extent bilateral rTMS and priming low-frequency rTMS respectively. These findings warrant the design of larger RCTs investigating the potential of these approaches in the short-term treatment of MDD. Current evidence cannot support novel rTMS interventions as a treatment for MDD.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@brunoniRepetitiveTranscranialMagnetic2017b.md;D\:\\Zotero Storage\\Zotero\\storage\\MUD4WDBZ\\Brunoni et al. - 2017 - Repetitive Transcranial Magnetic Stimulation for t.pdf}
}

@article{bullmoreBrainGraphsGraphical2011,
  title = {Brain Graphs: Graphical Models of the Human Brain Connectome},
  author = {Bullmore, Edward T. and family=Bassett, given=Danielle S. \%J Annual, prefix=review of clinical psychology, useprefix=false},
  date = {2011},
  volume = {7},
  pages = {113--140},
  issn = {1548-5943}
}

@article{cadieuDeepNeuralNetworks2014,
  title = {Deep Neural Networks Rival the Representation of Primate {{IT}} Cortex for Core Visual Object Recognition},
  author = {Cadieu, Charles F. and Hong, Ha and Yamins, Daniel LK and Pinto, Nicolas and Ardila, Diego and Solomon, Ethan A. and Majaj, Najib J. and family=DiCarlo, given=James J. \%J PLoS, prefix=computational biology, useprefix=false},
  date = {2014},
  volume = {10},
  number = {12},
  pages = {e1003963},
  issn = {1553-734X}
}

@article{caoDynamicalNetworkModels2022,
  title = {Dynamical {{Network Models From EEG}} and {{MEG}} for {{Epilepsy Surgery}}—{{A Quantitative Approach}}},
  author = {Cao, Miao and Vogrin, Simon J. and Peterson, Andre D. H. and Woods, William and Cook, Mark J. and Plummer, Chris},
  date = {2022},
  journaltitle = {Frontiers in Neurology},
  volume = {13},
  issn = {1664-2295},
  url = {https://www.frontiersin.org/articles/10.3389/fneur.2022.837893},
  urldate = {2023-12-05},
  abstract = {There is an urgent need for more informative quantitative techniques that non-invasively and objectively assess strategies for epilepsy surgery. Invasive intracranial electroencephalography (iEEG) remains the clinical gold standard to investigate the nature of the epileptogenic zone (EZ) before surgical resection. However, there are major limitations of iEEG, such as the limited spatial sampling and the degree of subjectivity inherent in the analysis and clinical interpretation of iEEG data. Recent advances in network analysis and dynamical network modeling provide a novel aspect toward a more objective assessment of the EZ. The advantage of such approaches is that they are data-driven and require less or no human input. Multiple studies have demonstrated success using these approaches when applied to iEEG data in characterizing the EZ and predicting surgical outcomes. However, the limitations of iEEG recordings equally apply to these studies—limited spatial sampling and the implicit assumption that iEEG electrodes, whether strip, grid, depth or stereo EEG (sEEG) arrays, are placed in the correct location. Therefore, it is of interest to clinicians and scientists to see whether the same analysis and modeling techniques can be applied to whole-brain, non-invasive neuroimaging data (from MRI-based techniques) and neurophysiological data (from MEG and scalp EEG recordings), thus removing the limitation of spatial sampling, while safely and objectively characterizing the EZ. This review aims to summarize current state of the art non-invasive methods that inform epilepsy surgery using network analysis and dynamical network models. We also present perspectives on future directions and clinical applications of these promising approaches.},
  keywords = {Dynamical Network Model,EEG,EZ,MEG,Review},
  file = {D:\Zotero Storage\Zotero\storage\256AB2I7\Cao 等 - 2022 - Dynamical Network Models From EEG and MEG for Epil.pdf}
}

@article{cardinDrivingFastspikingCells2009,
  title = {Driving Fast-Spiking Cells Induces Gamma Rhythm and Controls Sensory Responses},
  author = {Cardin, J. A. and Carlen, M. and Meletis, K. and Knoblich, U. and Zhang, F. and Deisseroth, K. and Tsai, L. H. and Moore, C. I.},
  date = {2009-06-04},
  journaltitle = {Nature},
  volume = {459},
  number = {7247},
  pages = {663--7},
  issn = {1476-4687 (Electronic) 0028-0836 (Linking)},
  doi = {10.1038/nature08002},
  abstract = {Cortical gamma oscillations (20-80 Hz) predict increases in focused attention, and failure in gamma regulation is a hallmark of neurological and psychiatric disease. Current theory predicts that gamma oscillations are generated by synchronous activity of fast-spiking inhibitory interneurons, with the resulting rhythmic inhibition producing neural ensemble synchrony by generating a narrow window for effective excitation. We causally tested these hypotheses in barrel cortex in vivo by targeting optogenetic manipulation selectively to fast-spiking interneurons. Here we show that light-driven activation of fast-spiking interneurons at varied frequencies (8-200 Hz) selectively amplifies gamma oscillations. In contrast, pyramidal neuron activation amplifies only lower frequency oscillations, a cell-type-specific double dissociation. We found that the timing of a sensory input relative to a gamma cycle determined the amplitude and precision of evoked responses. Our data directly support the fast-spiking-gamma hypothesis and provide the first causal evidence that distinct network activity states can be induced in vivo by cell-type-specific activation.},
  pmcid = {PMC3655711},
  keywords = {Animals,Chlamydomonas reinhardtii,Electrophysiology,Gene Expression Regulation,Gene Knock-In Techniques,Interneurons/*physiology,Mice,Photic Stimulation,Pyramidal Cells/physiology,Rhodopsin/genetics/metabolism,Somatosensory Cortex/*cytology/*metabolism}
}

@article{cashPersonalizedConnectivityguidedDLPFCTMS2021,
  title = {Personalized Connectivity-Guided {{DLPFC-TMS}} for Depression: {{Advancing}} Computational Feasibility, Precision and Reproducibility},
  shorttitle = {Personalized Connectivity-Guided {{DLPFC-TMS}} for Depression},
  author = {Cash, Robin F. H. and Cocchi, Luca and Lv, Jinglei and Wu, Yumeng and Fitzgerald, Paul B. and Zalesky, Andrew},
  date = {2021-09},
  journaltitle = {Human Brain Mapping},
  shortjournal = {Hum Brain Mapp},
  volume = {42},
  number = {13},
  eprint = {33544411},
  eprinttype = {pmid},
  pages = {4155--4172},
  issn = {1097-0193},
  doi = {10.1002/hbm.25330},
  abstract = {Repetitive transcranial magnetic stimulation (rTMS) of the dorsolateral prefrontal cortex (DLPFC) is an established treatment for refractory depression, however, therapeutic outcomes vary. Mounting evidence suggests that clinical response relates to functional connectivity with the subgenual cingulate cortex (SGC) at the precise DLPFC stimulation site. Critically, SGC-related network architecture shows considerable interindividual variation across the spatial extent of the DLPFC, indicating that connectivity-based target personalization could potentially be necessary to improve treatment outcomes. However, to date accurate personalization has not appeared feasible, with recent work indicating that the intraindividual reproducibility of optimal targets is limited to 3.5~cm. Here we developed reliable and accurate methodologies to compute individualized connectivity-guided stimulation targets. In resting-state functional MRI scans acquired across 1,000 healthy adults, we demonstrate that, using this approach, personalized targets can be reliably and robustly pinpointed, with a median accuracy of \textasciitilde 2\,mm between scans repeated across separate days. These targets remained highly stable, even after 1\,year, with a median intraindividual distance between coordinates of only 2.7\,mm. Interindividual spatial variation in personalized targets exceeded intraindividual variation by a factor of up to 6.85, suggesting that personalized targets did not trivially converge to a group-average site. Moreover, personalized targets were heritable, suggesting that connectivity-guided rTMS personalization is stable over time and under genetic control. This computational framework provides capacity for personalized connectivity-guided TMS targets to be robustly computed with high precision and has the flexibly to advance research in other basic research and clinical applications.},
  langid = {english},
  pmcid = {PMC8357003},
  keywords = {Adult,connectivity,Connectome,depression,{Depressive Disorder, Treatment-Resistant},Dorsolateral Prefrontal Cortex,Feasibility Studies,Female,Humans,Magnetic Resonance Imaging,Male,neuroimaging,personalization,precision psychiatry,Reproducibility of Results,transcranial magnetic stimulation,Transcranial Magnetic Stimulation,Young Adult},
  file = {D:\Zotero Storage\Zotero\storage\DL8IZ8V5\Cash 等 - 2021 - Personalized connectivity-guided DLPFC-TMS for dep.pdf}
}

@online{CharacterizationRegionalDifferences,
  title = {Characterization of Regional Differences in Resting-State {{fMRI}} with a Data-Driven Network Model of Brain Dynamics | {{Science Advances}}},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abq7547},
  urldate = {2023-09-26},
  file = {D:\Zotero Storage\Zotero\storage\USVD786X\sciadv.html}
}

@article{chenDIRECTConsortiumRESTmetaMDD2022,
  title = {The {{DIRECT}} Consortium and the {{REST-meta-MDD}} Project: Towards Neuroimaging Biomarkers of Major Depressive Disorder},
  shorttitle = {The {{DIRECT}} Consortium and the {{REST-meta-MDD}} Project},
  author = {Chen, Xiao and Lu, Bin and Li, Hui-Xian and Li, Xue-Ying and Wang, Yu-Wei and Castellanos, Francisco Xavier and Cao, Li-Ping and Chen, Ning-Xuan and Chen, Wei and Cheng, Yu-Qi and Cui, Shi-Xian and Deng, Zhao-Yu and Fang, Yi-Ru and Gong, Qi-Yong and Guo, Wen-Bin and Hu, Zheng-Jia-Yi and Kuang, Li and Li, Bao-Juan and Li, Le and Li, Tao and Lian, Tao and Liao, Yi-Fan and Liu, Yan-Song and Liu, Zhe-Ning and Lu, Jian-Ping and Luo, Qing-Hua and Meng, Hua-Qing and Peng, Dai-Hui and Qiu, Jiang and Shen, Yue-Di and Si, Tian-Mei and Tang, Yan-Qing and Wang, Chuan-Yue and Wang, Fei and Wang, Hua-Ning and Wang, Kai and Wang, Xiang and Wang, Ying and Wang, Zi-Han and Wu, Xiao-Ping and Xie, Chun-Ming and Xie, Guang-Rong and Xie, Peng and Xu, Xiu-Feng and Yang, Hong and Yang, Jian and Yao, Shu-Qiao and Yu, Yong-Qiang and Yuan, Yong-Gui and Zhang, Ke-Rang and Zhang, Wei and Zhang, Zhi-Jun and Zhu, Jun-Juan and Zuo, Xi-Nian and Zhao, Jing-Ping and Zang, Yu-Feng and {the DIRECT consortium} and Yan, Chao-Gan},
  date = {2022-03-01},
  journaltitle = {Psychoradiology},
  shortjournal = {Psychoradiology},
  volume = {2},
  number = {1},
  pages = {32--42},
  issn = {2634-4416},
  doi = {10.1093/psyrad/kkac005},
  url = {https://doi.org/10.1093/psyrad/kkac005},
  urldate = {2023-11-15},
  abstract = {Despite a growing neuroimaging literature on the pathophysiology of major depressive disorder (MDD), reproducible findings are lacking, probably reflecting mostly small sample sizes and heterogeneity in analytic approaches. To address these issues, the Depression Imaging REsearch ConsorTium (DIRECT) was launched. The REST-meta-MDD project, pooling 2428 functional brain images processed with a standardized pipeline across all participating sites, has been the first effort from DIRECT. In this review, we present an overview of the motivations, rationale, and principal findings of the studies so far from the REST-meta-MDD project. Findings from the first round of analyses of the pooled repository have included alterations in functional connectivity within the default mode network, in whole-brain topological properties, in dynamic features, and in functional lateralization. These well-powered exploratory observations have also provided the basis for future longitudinal hypothesis-driven research. Following these fruitful explorations, DIRECT has proceeded to its second stage of data sharing that seeks to examine ethnicity in brain alterations in MDD by extending the exclusive Chinese original sample to other ethnic groups through international collaborations. A state-of-the-art, surface-based preprocessing pipeline has also been introduced to improve sensitivity. Functional images from patients with bipolar disorder and schizophrenia will be included to identify shared and unique abnormalities across diagnosis boundaries. In addition, large-scale longitudinal studies targeting brain network alterations following antidepressant treatment, aggregation of diffusion tensor images, and the development of functional magnetic resonance imaging-guided neuromodulation approaches are underway. Through these endeavours, we hope to accelerate the translation of functional neuroimaging findings to clinical use, such as evaluating longitudinal effects of antidepressant medications and developing individualized neuromodulation targets, while building an open repository for the scientific community.},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\JTQFYEM3\\Chen 等 - 2022 - The DIRECT consortium and the REST-meta-MDD projec.pdf;D\:\\Zotero Storage\\Zotero\\storage\\TJ2273N9\\6604754.html}
}

@article{chenNeurophysiologicalStratificationMajor2023,
  title = {Neurophysiological Stratification of Major Depressive Disorder by Distinct Trajectories},
  author = {Chen, Di and Wang, Xiang and Voon, Valerie and Jiang, Yuchao and Lo, Chun-Yi Zac and Wang, Linbo and Shen, Chun and Xiang, Shitong and Yao, Shuqiao and Zhang, Jie and {ZIB Consortium} and {DIRECT Consortium} and Jia, Tianye and Cheng, Wei and Feng, Jianfeng},
  date = {2023-10-23},
  journaltitle = {Nature Mental Health},
  shortjournal = {Nat. Mental Health},
  issn = {2731-6076},
  doi = {10.1038/s44220-023-00139-4},
  url = {https://www.nature.com/articles/s44220-023-00139-4},
  urldate = {2023-10-25},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\4VASQ2P6\Chen 等 - 2023 - Neurophysiological stratification of major depress.pdf}
}

@article{chiaEmergenceCorticalNetwork2023,
  title = {Emergence of Cortical Network Motifs for Short-Term Memory during Learning},
  author = {Chia, Xin Wei and Tan, Jian Kwang and Ang, Lee Fang and Kamigaki, Tsukasa and Makino, Hiroshi},
  date = {2023-10-28},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  eprint = {37898638},
  eprinttype = {pmid},
  pages = {6869},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-42609-4},
  abstract = {Learning of adaptive behaviors requires the refinement of coordinated activity across multiple brain regions. However, how neural communications develop during learning remains poorly understood. Here, using two-photon calcium imaging, we simultaneously recorded the activity of layer 2/3 excitatory neurons in eight regions of the mouse dorsal cortex during learning of a delayed-response task. Across learning, while global functional connectivity became sparser, there emerged a subnetwork comprising of neurons in the anterior lateral motor cortex (ALM) and posterior parietal cortex (PPC). Neurons in this subnetwork shared a similar choice code during action preparation and formed recurrent functional connectivity across learning. Suppression of PPC activity disrupted choice selectivity in ALM and impaired task performance. Recurrent neural networks reconstructed from ALM activity revealed that PPC-ALM interactions rendered choice-related attractor dynamics more stable. Thus, learning constructs cortical network motifs by recruiting specific inter-areal communication channels to promote efficient and robust sensorimotor transformation.},
  langid = {english},
  pmcid = {PMC10613236},
  keywords = {Animals,{Memory, Short-Term},Mice,Motor Cortex,{Neural Networks, Computer},Neurons,Parietal Lobe},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\7EJLD356\\free_energy.pdf;D\:\\Zotero Storage\\Zotero\\storage\\88NCVDDW\\Chia 等 - 2023 - Emergence of cortical network motifs for short-ter.pdf}
}

@article{chibUnderstandingMetropolisHastingsAlgorithm1995,
  title = {Understanding the {{Metropolis-Hastings Algorithm}}},
  author = {Chib, Siddhartha and Greenberg, Edward},
  date = {1995-11-01},
  journaltitle = {The American Statistician},
  volume = {49},
  number = {4},
  pages = {327--335},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1995.10476177},
  url = {https://www.tandfonline.com/doi/abs/10.1080/00031305.1995.10476177},
  urldate = {2023-08-24},
  abstract = {We provide a detailed, introductory exposition of the Metropolis-Hastings algorithm, a powerful Markov chain method to simulate multivariate distributions. A simple, intuitive derivation of this method is given along with guidance on implementation. Also discussed are two applications of the algorithm, one for implementing acceptance-rejection sampling when a blanketing function is not available and the other for implementing the algorithm with block-at-a-time scans. In the latter situation, many different algorithms, including the Gibbs sampler, are shown to be special cases of the Metropolis-Hastings algorithm. The methods are illustrated with examples.},
  keywords = {Gibbs sampling,Markov chain Monte Carlo,Multivariate density simulation,Reversible Markov chains},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@chibUnderstandingMetropolisHastingsAlgorithm1995.md;D\:\\Zotero Storage\\Zotero\\storage\\CCMTBXSN\\Chib and Greenberg - 1995 - Understanding the Metropolis-Hastings Algorithm.pdf}
}

@article{cohenMeasuringInterpretingNeuronal2011,
  title = {Measuring and Interpreting Neuronal Correlations},
  author = {Cohen, M. R. and Kohn, A.},
  date = {2011-06-27},
  journaltitle = {Nat Neurosci},
  volume = {14},
  number = {7},
  pages = {811--9},
  issn = {1546-1726 (Electronic) 1097-6256 (Linking)},
  doi = {10.1038/nn.2842},
  abstract = {Mounting evidence suggests that understanding how the brain encodes information and performs computations will require studying the correlations between neurons. The recent advent of recording techniques such as multielectrode arrays and two-photon imaging has made it easier to measure correlations, opening the door for detailed exploration of their properties and contributions to cortical processing. However, studies have reported discrepant findings, providing a confusing picture. Here we briefly review these studies and conduct simulations to explore the influence of several experimental and physiological factors on correlation measurements. Differences in response strength, the time window over which spikes are counted, spike sorting conventions and internal states can all markedly affect measured correlations and systematically bias estimates. Given these complicating factors, we offer guidelines for interpreting correlation data and a discussion of how best to evaluate the effect of correlations on cortical processing.},
  pmcid = {PMC3586814},
  keywords = {{*Models, Neurological},Action Potentials/*physiology,Animals,Cell Communication/physiology,Cerebral Cortex/*cytology,Humans,{Models, Statistical},Neurons/classification/*physiology}
}

@article{cohenMidfrontalConflictrelatedThetaband2013,
  title = {Midfrontal Conflict-Related Theta-Band Power Reflects Neural Oscillations That Predict Behavior},
  author = {Cohen, M. X. and Donner, T. H.},
  date = {2013-12},
  journaltitle = {J Neurophysiol},
  volume = {110},
  number = {12},
  pages = {2752--63},
  issn = {1522-1598 (Electronic) 0022-3077 (Linking)},
  doi = {10.1152/jn.00479.2013},
  abstract = {Action monitoring and conflict resolution require the rapid and flexible coordination of activity in multiple brain regions. Oscillatory neural population activity may be a key physiological mechanism underlying such rapid and flexible network coordination. EEG power modulations of theta-band (4-8 Hz) activity over the human midfrontal cortex during response conflict have been proposed to reflect neural oscillations that support conflict detection and resolution processes. However, it has remained unclear whether this frequency-band-specific activity reflects neural oscillations or nonoscillatory responses (i.e., event-related potentials). Here, we show that removing the phase-locked component of the EEG did not reduce the strength of the conflict-related modulation of the residual (i.e., non-phase-locked) theta power over midfrontal cortex. Furthermore, within-subject regression analyses revealed that the non-phase-locked theta power was a significantly better predictor of the conflict condition than was the time-domain phase-locked EEG component. Finally, non-phase-locked theta power showed robust and condition-specific (high- vs. low-conflict) cross-trial correlations with reaction time, whereas the phase-locked component did not. Taken together, our results indicate that most of the conflict-related and behaviorally relevant midfrontal EEG signal reflects a modulation of ongoing theta-band oscillations that occurs during the decision process but is not phase-locked to the stimulus or to the response.},
  keywords = {{*Conflict, Psychological},*Theta Rhythm,cognitive control,Decision Making,Frontal Lobe/*physiology,Humans,midfrontal,non-phase-locked,oscillations,theta,Young Adult}
}

@article{colginMechanismsFunctionsTheta2013,
  title = {Mechanisms and {{Functions}} of {{Theta Rhythms}}},
  author = {Colgin, Laura Lee},
  date = {2013},
  journaltitle = {Annual Review of Neuroscience},
  volume = {36},
  number = {1},
  eprint = {23724998},
  eprinttype = {pmid},
  pages = {295--312},
  doi = {10.1146/annurev-neuro-062012-170330},
  url = {https://doi.org/10.1146/annurev-neuro-062012-170330},
  urldate = {2023-11-03},
  abstract = {The theta rhythm is one of the largest and most sinusoidal activity patterns in the brain. Here I survey progress in the field of theta rhythms research. I present arguments supporting the hypothesis that theta rhythms emerge owing to intrinsic cellular properties yet can be entrained by several theta oscillators throughout the brain. I review behavioral correlates of theta rhythms and consider how these correlates inform our understanding of theta rhythms' functions. I discuss recent work suggesting that one function of theta is to package related information within individual theta cycles for more efficient spatial memory processing. Studies examining the role of theta phase precession in spatial memory, particularly sequence retrieval, are also summarized. Additionally, I discuss how interregional coupling of theta rhythms facilitates communication across brain regions. Finally, I conclude by summarizing how theta rhythms may support cognitive operations in the brain, including learning.},
  keywords = {CA1,hippocampus,memory,oscillations,phase precession,place cells}
}

@article{colginRhythmsHippocampalNetwork2016,
  title = {Rhythms of the Hippocampal Network},
  author = {Colgin, Laura Lee},
  date = {2016-04},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {17},
  number = {4},
  pages = {239--249},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn.2016.21},
  url = {https://www.nature.com/articles/nrn.2016.21},
  urldate = {2023-11-03},
  abstract = {The hippocampus shows three main classes of rhythms: theta (∼4–12 Hz), sharp wave–ripples (∼150–200 Hz ripples superimposed on ∼0.01–3 Hz sharp waves) and gamma (∼25–100 Hz).Theta rhythm generation involves a variety of mechanisms, including theta rhythmic firing in septal and hippocampal interneurons, excitatory inputs to hippocampus and intrinsic properties of hippocampal neurons.Theta rhythms are likely to be important for the formation of memories of sequences of events.Sharp wave–ripple complexes are composed of two distinct network patterns: sharp waves (excitatory events that propagate from CA3 to CA1) and ripples (which reflect high frequency firing in hippocampal interneurons).Accumulating evidence suggests that sharp wave–ripples are important for intrinsic hippocampal operations, including offline memory processing, retrieval of previously stored memories and planning of future behaviours.The class of brain rhythms traditionally defined as gamma probably contains at least two different variants of oscillatory activity.Recent findings suggest that slow (∼25–55 Hz) and fast (∼60–100 Hz) variants of gamma have different origins and may have different functions.},
  issue = {4},
  langid = {english},
  keywords = {Hippocampus,Learning and memory,Navigation},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\Nature Reviews Neuroscience2016ColginRhythms of the hippocampal networkNature Reviews NeuroscienceNat Rev Neurosci174239-249CompNeuro_Literature\UnreadColginLLC期刊文章\2016_-Rhythms of the hippocampal network.pdf}
}

@book{ComputationalBrain,
  title = {The {{Computational Brain}}},
  file = {D:\Zotero Storage\Zotero\storage\QGCYLNVA\The Computational Brain_Patricia S. Churchland; Terrence J. Sejnowski.pdf}
}

@article{croarkinHighfrequencyRepetitiveTMS2018,
  title = {High-Frequency Repetitive {{TMS}} for Suicidal Ideation in Adolescents with Depression},
  author = {Croarkin, Paul E. and Nakonezny, Paul A. and Deng, Zhi-De and Romanowicz, Magdalena and Voort, Jennifer L. Vande and Camsari, Deniz Doruk and Schak, Kathryn M. and Port, John D. and Lewis, Charles P.},
  date = {2018-10},
  journaltitle = {Journal of Affective Disorders},
  shortjournal = {Journal of Affective Disorders},
  volume = {239},
  pages = {282--290},
  issn = {01650327},
  doi = {10.1016/j.jad.2018.06.048},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165032717325375},
  urldate = {2023-09-05},
  langid = {english},
  keywords = {TMS Stimulation Frequency},
  file = {D:\Zotero Storage\Zotero\storage\FSVY9WAB\Croarkin et al. - 2018 - High-frequency repetitive TMS for suicidal ideatio.pdf}
}

@article{daieSpatialPatternsPersistent2015,
  title = {Spatial Patterns of Persistent Neural Activity Vary with the Behavioral Context of Short-Term Memory},
  author = {Daie, K. and Goldman, M. S. and Aksay, E. R.},
  date = {2015-02-18},
  journaltitle = {Neuron},
  volume = {85},
  number = {4},
  pages = {847--60},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2015.01.006},
  abstract = {A short-term memory can be evoked by different inputs and control separate targets in different behavioral contexts. To address the circuit mechanisms underlying context-dependent memory function, we determined through optical imaging how memory is encoded at the whole-network level in two behavioral settings. Persistent neural activity maintaining a memory of desired eye position was imaged throughout the oculomotor integrator after saccadic or optokinetic stimulation. While eye position was encoded by the amplitude of network activity, the spatial patterns of firing were context dependent: cells located caudally generally were most persistent following saccadic input, whereas cells located rostrally were most persistent following optokinetic input. To explain these data, we computationally identified four independent modes of network activity and found these were differentially accessed by saccadic and optokinetic inputs. These results show how a circuit can simultaneously encode memory value and behavioral context, respectively, in its amplitude and spatial pattern of persistent firing.},
  pmcid = {PMC4336549},
  keywords = {Action Potentials/genetics/*physiology,Animals,{Animals, Genetically Modified},Bacterial Proteins/genetics/metabolism,Computer Simulation,Eye Movements,Homeodomain Proteins/genetics/metabolism,Larva,Luminescent Proteins/genetics/metabolism,{Memory, Short-Term/*physiology},Microphthalmia-Associated Transcription Factor/genetics,{Models, Neurological},Mutation/genetics,Neurons/*physiology,Rhombencephalon/cytology,Zebrafish,Zebrafish Proteins/genetics/metabolism}
}

@article{dasHighlightingStructureFunctionRelationship2014,
  title = {Highlighting the {{Structure-Function Relationship}} of the {{Brain}} with the {{Ising Model}} and {{Graph Theory}}},
  author = {Das, T. K. and Abeyasinghe, P. M. and Crone, J. S. and Sosnowski, A. and Laureys, S. and Owen, A. M. and Soddu, A.},
  date = {2014-09-04},
  journaltitle = {BioMed Research International},
  volume = {2014},
  pages = {e237898},
  publisher = {{Hindawi}},
  issn = {2314-6133},
  doi = {10.1155/2014/237898},
  url = {https://www.hindawi.com/journals/bmri/2014/237898/},
  urldate = {2023-10-11},
  abstract = {With the advent of neuroimaging techniques, it becomes feasible to explore the structure-function relationships in the brain. When the brain is not involved in any cognitive task or stimulated by any external output, it preserves important activities which follow well-defined spatial distribution patterns. Understanding the self-organization of the brain from its anatomical structure, it has been recently suggested to model the observed functional pattern from the structure of white matter fiber bundles. Different models which study synchronization (e.g., the Kuramoto model) or global dynamics (e.g., the Ising model) have shown success in capturing fundamental properties of the brain. In particular, these models can explain the competition between modularity and specialization and the need for integration in the brain. Graphing the functional and structural brain organization supports the model and can also highlight the strategy used to process and organize large amount of information traveling between the different modules. How the flow of information can be prevented or partially destroyed in pathological states, like in severe brain injured patients with disorders of consciousness or by pharmacological induction like in anaesthesia, will also help us to better understand how global or integrated behavior can emerge from local and modular interactions.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\GI4S4FVM\Das 等 - 2014 - Highlighting the Structure-Function Relationship o.pdf}
}

@book{dayanTheoreticalNeuroscienceComputational2001,
  title = {Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems},
  shorttitle = {Theoretical Neuroscience},
  author = {Dayan, Peter and Abbott, L. F.},
  date = {2001},
  series = {Computational Neuroscience},
  publisher = {{Massachusetts Institute of Technology Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-04199-7},
  langid = {english},
  pagetotal = {460},
  keywords = {Computational neuroscience,Computer simulation,Human information processing,Neural networks (Neurobiology)},
  file = {D:\Zotero Storage\Zotero\storage\LV5H9BF2\Dayan and Abbott - 2001 - Theoretical neuroscience computational and mathem.pdf}
}

@article{decoEmergingConceptsDynamical2011,
  title = {Emerging Concepts for the Dynamical Organization of Resting-State Activity in the Brain},
  author = {Deco, G. and Jirsa, V. K. and McIntosh, A. R.},
  date = {2011-01},
  journaltitle = {Nat Rev Neurosci},
  volume = {12},
  number = {1},
  pages = {43--56},
  issn = {1471-0048 (Electronic) 1471-003X (Linking)},
  doi = {10.1038/nrn2961},
  abstract = {A broad body of experimental work has demonstrated that apparently spontaneous brain activity is not random. At the level of large-scale neural systems, as measured with functional MRI (fMRI), this ongoing activity reflects the organization of a series of highly coherent functional networks. These so-called resting-state networks (RSNs) closely relate to the underlying anatomical connectivity but cannot be understood in those terms alone. Here we review three large-scale neural system models of primate neocortex that emphasize the key contributions of local dynamics, signal transmission delays and noise to the emerging RSNs. We propose that the formation and dissolution of resting-state patterns reflects the exploration of possible functional network configurations around a stable anatomical skeleton.},
  keywords = {*Magnetic Resonance Imaging/methods,Animals,Brain/*physiology,Humans,Nerve Net/*physiology,Neural Pathways/physiology,Rest/*physiology}
}

@article{decoHowAnatomyShapes2012,
  title = {How Anatomy Shapes Dynamics: A Semi-Analytical Study of the Brain at Rest by a Simple Spin Model},
  shorttitle = {How Anatomy Shapes Dynamics},
  author = {Deco, Gustavo and Senden, Mario and Jirsa, Viktor},
  date = {2012},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {6},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2012.00068},
  urldate = {2023-11-03},
  abstract = {Resting state networks (RSNs) show a surprisingly coherent and robust spatiotemporal organization. Previous theoretical studies demonstrated that these patterns can be understood as emergent on the basis of the underlying neuroanatomical connectivity skeleton. Integrating the biologically realistic DTI/DSI-(Diffusion Tensor Imaging/Diffusion Spectrum Imaging)based neuroanatomical connectivity into a brain model of Ising spin dynamics, we found a system with multiple attractors, which can be studied analytically. The multistable attractor landscape thus defines a functionally meaningful dynamic repertoire of the brain network that is inherently present in the neuroanatomical connectivity. We demonstrate that the more entropy of attractors exists, the richer is the dynamical repertoire and consequently the brain network displays more capabilities of computation. We hypothesize therefore that human brain connectivity developed a scale free type of architecture in order to be able to store a large number of different and flexibly accessible brain functions.},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\Frontiers in Computational Neuroscience2012Deco et alHow anatomy shapes dynamicsFrontiers in Computational Neuroscience6CompNeuro_Literature\IsingDecoG et alGD et al期刊文章\2012_-How anatomy shapes dynamics.pdf}
}

@article{decoHowLocalExcitationinhibition2014,
  title = {How Local Excitation-Inhibition Ratio Impacts the Whole Brain Dynamics},
  author = {Deco, G. and Ponce-Alvarez, A. and Hagmann, P. and Romani, G. L. and Mantini, D. and Corbetta, M.},
  date = {2014-06-04},
  journaltitle = {J Neurosci},
  volume = {34},
  number = {23},
  pages = {7886--98},
  issn = {1529-2401 (Electronic) 0270-6474 (Print) 0270-6474 (Linking)},
  doi = {10.1523/JNEUROSCI.5068-13.2014},
  abstract = {The spontaneous activity of the brain shows different features at different scales. On one hand, neuroimaging studies show that long-range correlations are highly structured in spatiotemporal patterns, known as resting-state networks, on the other hand, neurophysiological reports show that short-range correlations between neighboring neurons are low, despite a large amount of shared presynaptic inputs. Different dynamical mechanisms of local decorrelation have been proposed, among which is feedback inhibition. Here, we investigated the effect of locally regulating the feedback inhibition on the global dynamics of a large-scale brain model, in which the long-range connections are given by diffusion imaging data of human subjects. We used simulations and analytical methods to show that locally constraining the feedback inhibition to compensate for the excess of long-range excitatory connectivity, to preserve the asynchronous state, crucially changes the characteristics of the emergent resting and evoked activity. First, it significantly improves the model's prediction of the empirical human functional connectivity. Second, relaxing this constraint leads to an unrealistic network evoked activity, with systematic coactivation of cortical areas which are components of the default-mode network, whereas regulation of feedback inhibition prevents this. Finally, information theoretic analysis shows that regulation of the local feedback inhibition increases both the entropy and the Fisher information of the network evoked responses. Hence, it enhances the information capacity and the discrimination accuracy of the global network. In conclusion, the local excitation-inhibition ratio impacts the structure of the spontaneous activity and the information transmission at the large-scale brain level.},
  pmcid = {PMC4044249},
  keywords = {{*Models, Neurological},*Nonlinear Dynamics,Action Potentials/physiology,anatomical connectivity,Brain/cytology/*physiology,Computer Simulation,Entropy,{Feedback, Physiological/physiology},functional connectivity,Humans,large-scale brain model,local feedback inhibition,Nerve Net/*physiology,Neural Inhibition/*physiology,Neural Pathways/physiology,Neurons/*physiology,resting-state activity},
  file = {D:\Zotero Storage\Zotero\storage\86REZFBK\deco2014.pdf.pdf}
}

@article{decoOngoingCorticalActivity2012,
  title = {Ongoing Cortical Activity at Rest: Criticality, Multistability, and Ghost Attractors},
  author = {Deco, G. and Jirsa, V. K.},
  date = {2012-03-07},
  journaltitle = {J Neurosci},
  volume = {32},
  number = {10},
  pages = {3366--75},
  issn = {1529-2401 (Electronic) 0270-6474 (Print) 0270-6474 (Linking)},
  doi = {10.1523/JNEUROSCI.2523-11.2012},
  abstract = {The ongoing activity of the brain at rest, i.e., under no stimulation and in absence of any task, is astonishingly highly structured into spatiotemporal patterns. These spatiotemporal patterns, called resting state networks, display low-frequency characteristics ({$<$}0.1 Hz) observed typically in the BOLD-fMRI signal of human subjects. We aim here to understand the origins of resting state activity through modeling via a global spiking attractor network of the brain. This approach offers a realistic mechanistic model at the level of each single brain area based on spiking neurons and realistic AMPA, NMDA, and GABA synapses. Integrating the biologically realistic diffusion tensor imaging/diffusion spectrum imaging-based neuroanatomical connectivity into the brain model, the resultant emerging resting state functional connectivity of the brain network fits quantitatively best the experimentally observed functional connectivity in humans when the brain network operates at the edge of instability. Under these conditions, the slow fluctuating ({$<$}0.1 Hz) resting state networks emerge as structured noise fluctuations around a stable low firing activity equilibrium state in the presence of latent "ghost" multistable attractors. The multistable attractor landscape defines a functionally meaningful dynamic repertoire of the brain network that is inherently present in the neuroanatomical connectivity.},
  pmcid = {PMC6621046},
  keywords = {Action Potentials/physiology/*radiation effects,Brain Mapping/methods,Cerebral Cortex/*physiology,Humans,Magnetic Resonance Imaging/methods,Male,Nerve Net/*physiology,Rest/*physiology}
}

@article{demirtasDynamicFunctionalConnectivity2016,
  title = {Dynamic Functional Connectivity Reveals Altered Variability in Functional Connectivity among Patients with Major Depressive Disorder},
  author = {Demirtaş, Murat and Tornador, Cristian and Falcón, Carles and López-Solà, Marina and Hernández-Ribas, Rosa and Pujol, Jesús and Menchón, José M. and Ritter, Petra and Cardoner, Narcis and Soriano-Mas, Carles and Deco, Gustavo},
  date = {2016},
  journaltitle = {Human Brain Mapping},
  volume = {37},
  number = {8},
  pages = {2918--2930},
  issn = {1097-0193},
  doi = {10.1002/hbm.23215},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23215},
  urldate = {2023-10-13},
  abstract = {Resting-state fMRI (RS-fMRI) has become a useful tool to investigate the connectivity structure of mental health disorders. In the case of major depressive disorder (MDD), recent studies regarding the RS-fMRI have found abnormal connectivity in several regions of the brain, particularly in the default mode network (DMN). Thus, the relevance of the DMN to self-referential thoughts and ruminations has made the use of the resting-state approach particularly important for MDD. The majority of such research has relied on the grand averaged functional connectivity measures based on the temporal correlations between the BOLD time series of various brain regions. We, in our study, investigated the variations in the functional connectivity over time at global and local level using RS-fMRI BOLD time series of 27 MDD patients and 27 healthy control subjects. We found that global synchronization and temporal stability were significantly increased in the MDD patients. Furthermore, the participants with MDD showed significantly increased overall average (static) functional connectivity (sFC) but decreased variability of functional connectivity (vFC) within specific networks. Static FC increased to predominance among the regions pertaining to the default mode network (DMN), while the decreased variability of FC was observed in the connections between the DMN and the frontoparietal network. Hum Brain Mapp 37:2918–2930, 2016. © 2016 Wiley Periodicals, Inc.},
  langid = {english},
  keywords = {dynamic functional connectivity,fMRI,major depressive disorder,mood disorders,resting state},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\UZDBCTIA\\Demirtaş 等 - 2016 - Dynamic functional connectivity reveals altered va.pdf;D\:\\Zotero Storage\\Zotero\\storage\\R35VCG6Z\\hbm.html}
}

@article{depasqualeTemporalDynamicsSpontaneous2010,
  title = {Temporal Dynamics of Spontaneous {{MEG}} Activity in Brain Networks},
  author = {family=Pasquale, given=Francesco, prefix=de, useprefix=true and Della Penna, Stefania and Snyder, Abraham Z. and Lewis, Christopher and Mantini, Dante and Marzetti, Laura and Belardinelli, Paolo and Ciancetta, Luca and Pizzella, Vittorio and Romani, Gian Luca and Corbetta, Maurizio},
  date = {2010-03-30},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {107},
  number = {13},
  pages = {6040--6045},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.0913863107},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.0913863107},
  urldate = {2023-12-06},
  abstract = {Functional MRI (fMRI) studies have shown that low-frequency ({$<$}0.1 Hz) spontaneous fluctuations of the blood oxygenation level dependent (BOLD) signal during restful wakefulness are coherent within distributed large-scale cortical and subcortical networks (resting state networks, RSNs). The neuronal mechanisms underlying RSNs remain poorly understood. Here, we describe magnetoencephalographic correspondents of two well-characterized RSNs: the dorsal attention and the default mode networks. Seed-based correlation mapping was performed using time-dependent MEG power reconstructed at each voxel within the brain. The topography of RSNs computed on the basis of extended (5 min) epochs was similar to that observed with fMRI but confined to the same hemisphere as the seed region. Analyses taking into account the nonstationarity of MEG activity showed transient formation of more complete RSNs, including nodes in the contralateral hemisphere. Spectral analysis indicated that RSNs manifest in MEG as synchronous modulation of band-limited power primarily within the theta, alpha, and beta bands—that is, in frequencies slower than those associated with the local electrophysiological correlates of event-related BOLD responses.},
  keywords = {fMRI,MEG,RSN},
  file = {D:\Zotero Storage\Zotero\storage\KY5YIPHL\de Pasquale 等 - 2010 - Temporal dynamics of spontaneous MEG activity in b.pdf}
}

@article{downarNewTargetsRTMS2013a,
  title = {New {{Targets}} for {{rTMS}} in {{Depression}}: {{A Review}} of {{Convergent Evidence}}},
  shorttitle = {New {{Targets}} for {{rTMS}} in {{Depression}}},
  author = {Downar, Jonathan and Daskalakis, Z. Jeff},
  date = {2013-05},
  journaltitle = {Brain Stimulation},
  shortjournal = {Brain Stimulation},
  volume = {6},
  number = {3},
  pages = {231--240},
  issn = {1935861X},
  doi = {10.1016/j.brs.2012.08.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1935861X12001544},
  urldate = {2023-09-24},
  abstract = {Although rTMS is moving steadily into the mainstream as a treatment for medically refractory depression, its efficacy continues to lag behind that of more invasive neuromodulation treatments such as ECT or DBS. Here we review evidence to suggest that a fruitful, but neglected, strategy for improving rTMS efficacy may be to explore alternatives to the conventional stimulation target in the dorsolateral prefrontal cortex (DLPFC). The convergent evidence of lesion, stimulation, connectivity, and correlative neuroimaging studies suggests that the DLPFC may have a relatively peripheral role in mood regulation, at least compared to several alternative areas within the prefrontal cortex. In particular, we consider the evidence base in support of four new potential targets for rTMS in depression: dorsomedial prefrontal cortex (DMPFC), frontopolar cortex (FPC), ventromedial prefrontal cortex (VMPFC), and ventrolateral prefrontal cortex (VLPFC). Each of these regions enjoys broader support, from a more diverse evidence base, than the DLPFC in terms of its role in emotion regulation in major depression. We discuss the relative merits of each of these novel targets, including potential obstacles to stimulation using currently available technologies, and potential strategies for overcoming these obstacles. It is hoped that this detailed review will spur a more vigorous exploration of new targets for rTMS in depression. The use of new targets may help to propel rTMS across the threshold of efficacy required of a first-line treatment, to assume a more widespread role in the treatment of depressed mood.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\downarNewTargetsRTMS2013a.md;D\:\\Zotero Storage\\Zotero\\storage\\2JAE5WRZ\\Downar 和 Daskalakis - 2013 - New Targets for rTMS in Depression A Review of Co.pdf}
}

@article{drysdaleRestingstateConnectivityBiomarkers2017,
  title = {Resting-State Connectivity Biomarkers Define Neurophysiological Subtypes of Depression},
  author = {Drysdale, Andrew T. and Grosenick, Logan and Downar, Jonathan and Dunlop, Katharine and Mansouri, Farrokh and Meng, Yue and Fetcho, Robert N. and Zebley, Benjamin and Oathes, Desmond J. and Etkin, Amit and Schatzberg, Alan F. and Sudheimer, Keith and Keller, Jennifer and Mayberg, Helen S. and Gunning, Faith M. and Alexopoulos, George S. and Fox, Michael D. and Pascual-Leone, Alvaro and Voss, Henning U. and Casey, B. J. and Dubin, Marc J. and Liston, Conor},
  date = {2017-01},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {23},
  number = {1},
  eprint = {27918562},
  eprinttype = {pmid},
  pages = {28--38},
  issn = {1546-170X},
  doi = {10.1038/nm.4246},
  abstract = {Biomarkers have transformed modern medicine but remain largely elusive in psychiatry, partly because there is a weak correspondence between diagnostic labels and their neurobiological substrates. Like other neuropsychiatric disorders, depression is not a unitary disease, but rather a heterogeneous syndrome that encompasses varied, co-occurring symptoms and divergent responses to treatment. By using functional magnetic resonance imaging (fMRI) in a large multisite sample (n = 1,188), we show here that patients with depression can be subdivided into four neurophysiological subtypes ('biotypes') defined by distinct patterns of dysfunctional connectivity in limbic and frontostriatal networks. Clustering patients on this basis enabled the development of diagnostic classifiers (biomarkers) with high (82-93\%) sensitivity and specificity for depression subtypes in multisite validation (n = 711) and out-of-sample replication (n = 477) data sets. These biotypes cannot be differentiated solely on the basis of clinical features, but they are associated with differing clinical-symptom profiles. They also predict responsiveness to transcranial magnetic stimulation therapy (n = 154). Our results define novel subtypes of depression that transcend current diagnostic boundaries and may be useful for identifying the individuals who are most likely to benefit from targeted neurostimulation therapies.},
  langid = {english},
  pmcid = {PMC5624035},
  keywords = {Adult,Brain,Cluster Analysis,{Depressive Disorder, Major},Female,Frontal Lobe,Functional Neuroimaging,Humans,Limbic System,Magnetic Resonance Imaging,Male,Neural Pathways,Ventral Striatum},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\Resting-state connectivity biomarkers define neurophysiological subtypes of depression.md;D\:\\Zotero Storage\\Zotero\\storage\\67EL3MFD\\Drysdale 等 - 2017 - Resting-state connectivity biomarkers define neuro.pdf}
}

@article{dubreuilRolePopulationStructure2022,
  title = {The Role of Population Structure in Computations through Neural Dynamics},
  author = {Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  date = {2022-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {25},
  number = {6},
  pages = {783--794},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01088-4},
  url = {https://www.nature.com/articles/s41593-022-01088-4},
  urldate = {2023-09-15},
  abstract = {Neural computations are currently investigated using two separate approaches: sorting neurons into functional subpopulations or examining the low-dimensional dynamics of collective activity. Whether and how these two aspects interact to shape computations is currently unclear. Using a novel approach to extract computational mechanisms from networks trained on neuroscience tasks, here we show that the dimensionality of the dynamics and subpopulation structure play fundamentally complementary roles. Although various tasks can be implemented by increasing the dimensionality in networks with fully random population structure, flexible input–output mappings instead require a non-random population structure that can be described in terms of multiple subpopulations. Our analyses revealed that such a subpopulation structure enables flexible computations through a mechanism based on gain-controlled modulations that flexibly shape the collective dynamics. Our results lead to task-specific predictions for the structure of neural selectivity, for inactivation experiments and for the implication of different neurons in multi-tasking.},
  issue = {6},
  langid = {english},
  keywords = {Dynamical systems,Network models},
  file = {D:\Zotero Storage\Zotero\storage\2VV7DBRB\Dubreuil et al. - 2022 - The role of population structure in computations t.pdf}
}

@article{dupratAcceleratedIntermittentTheta2016,
  title = {Accelerated Intermittent Theta Burst Stimulation Treatment in Medication-Resistant Major Depression: {{A}} Fast Road to Remission?},
  shorttitle = {Accelerated Intermittent Theta Burst Stimulation Treatment in Medication-Resistant Major Depression},
  author = {Duprat, Romain and Desmyter, Stefanie and Rudi, De Raedt and family=Heeringen, given=Kees, prefix=van, useprefix=true and Van den Abbeele, Dirk and Tandt, Hannelore and Bakic, Jasmina and Pourtois, Gilles and Dedoncker, Josefien and Vervaet, Myriam and Van Autreve, Sara and Lemmens, Gilbert M. D. and Baeken, Chris},
  date = {2016-08-01},
  journaltitle = {Journal of Affective Disorders},
  shortjournal = {Journal of Affective Disorders},
  volume = {200},
  pages = {6--14},
  issn = {0165-0327},
  doi = {10.1016/j.jad.2016.04.015},
  url = {https://www.sciencedirect.com/science/article/pii/S0165032715314440},
  urldate = {2023-09-24},
  abstract = {Although accelerated repetitive Transcranial Magnetic Stimulation (rTMS) paradigms and intermittent Theta-burst Stimulation (iTBS) may have the potency to result in superior clinical outcomes in Treatment Resistant Depression (TRD), accelerated iTBS treatment has not yet been studied. In this registered randomized double-blind sham-controlled crossover study, spread over four successive days, 50 TRD patients received 20 iTBS sessions applied to the left dorsolateral prefrontal cortex (DLPFC). The accelerated iTBS treatment procedure was found to be safe and resulted in immediate statistically significant decreases in depressive symptoms regardless of order/type of stimulation (real/sham). While only 28\% of the patients showed a 50\% reduction of their initial Hamilton Depression Rating Scale score at the end of the two-week procedure, this response rate increased to 38\% when assessed two weeks after the end of the sham-controlled iTBS protocol, indicating delayed clinical effects. Importantly, 30\% of the responders were considered in clinical remission. We found no demographic predictors for response. Our findings indicate that only four days of accelerated iTBS treatment applied to the left DLPFC in TRD may lead to meaningful clinical responses within two weeks post stimulation.},
  keywords = {Accelerated rTMS,Intermittent theta-burst stimulation,Left DLPFC,Major depression,Treatment resistance},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\iTBS\\dupratAcceleratedIntermittentTheta2016.md;D\:\\Zotero Storage\\Zotero\\storage\\IYIX3YES\\Duprat 等 - 2016 - Accelerated intermittent theta burst stimulation t.pdf;D\:\\Zotero Storage\\Zotero\\storage\\35HHG34G\\S0165032715314440.html}
}

@article{durstewitzReconstructingComputationalSystem2023,
  title = {Reconstructing Computational System Dynamics from Neural Data with Recurrent Neural Networks},
  author = {Durstewitz, Daniel and Koppe, Georgia and Thurm, Max Ingo},
  date = {2023-10-04},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat. Rev. Neurosci.},
  pages = {1--18},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-023-00740-7},
  url = {https://www.nature.com/articles/s41583-023-00740-7},
  urldate = {2023-10-10},
  abstract = {Computational models in neuroscience usually take the form of systems of differential equations. The behaviour of such systems is the subject of dynamical systems theory. Dynamical systems~theory provides a powerful mathematical toolbox for analysing neurobiological processes and has been a mainstay of computational neuroscience for decades. Recently, recurrent neural networks (RNNs) have become a popular machine learning tool for studying the non-linear dynamics of neural and behavioural processes by emulating an underlying system of differential equations. RNNs have been routinely trained on similar behavioural tasks to those used for animal subjects to generate hypotheses about the underlying computational mechanisms. By contrast, RNNs can also be trained on the measured physiological and behavioural data, thereby directly inheriting their temporal and geometrical properties. In this way they become a formal surrogate for the experimentally probed system that can be further analysed, perturbed and simulated. This powerful approach is called dynamical system reconstruction. In this Perspective, we focus on recent trends in artificial intelligence and machine learning in this exciting and rapidly expanding field, which may be less well known in neuroscience. We discuss formal prerequisites, different model architectures and training approaches for RNN-based dynamical system reconstructions, ways to evaluate and validate model performance, how to interpret trained models in a neuroscience context, and current challenges.},
  langid = {english},
  keywords = {Dynamical systems,Learning algorithms}
}

@article{dushanovaEffectAgingEEG2014,
  title = {The Effect of Aging on {{EEG}} Brain Oscillations Related to Sensory and Sensorimotor Functions},
  author = {Dushanova, J. and Christov, M.},
  date = {2014-03},
  journaltitle = {Adv Med Sci},
  volume = {59},
  number = {1},
  pages = {61--7},
  issn = {1898-4002 (Electronic) 1896-1126 (Linking)},
  doi = {10.1016/j.advms.2013.08.002},
  abstract = {PURPOSE: The question of the present study is whether the brain as a system with gradually decreasing resources maximizes its performance by reorganizing neural networks for greater efficiency. MATERIAL/METHODS: Auditory event-related low frequency oscillations (delta delta - [2, 4]Hz; theta theta - [4.5, 7]Hz; alpha alpha - [7.5, 12]Hz) were examined during an auditory discrimination motor task (low-frequency tone - right hand movement, high-frequency tone - left hand movement) between two groups with mean age 26.3 and 55 years. RESULTS: The amplitudes of the phase-locked delta, theta and alpha activity were more pronounced with a progressive increase in age during the sensory processing, independent of tone type. The difference between the groups with respect to scalp distribution was tone-independent for delta/theta oscillations, but not for the alpha activity. Age-related and tone-dependent changes in alpha band activity were focused at frontal and sensorimotor areas. Neither functional brain specificity was observed for the amplitudes of the low-frequency (delta, theta, alpha) oscillations during the cognitive processing, which diminished with increasing age. CONCLUSION: The cognitive brain oscillatory specificity diminished with increasing age.},
  keywords = {*Aging,*Electroencephalography,Adult,Age effect,Auditory event-related low frequency oscillations,Brain/*physiology,Cognition/*physiology,Female,Follow-Up Studies,Humans,Male,Middle Aged,Movement/*physiology,Psychomotor Performance/*physiology,Sensation/*physiology,Sensory-motor task}
}

@online{EmergenceCorticalNetwork,
  title = {Emergence of Cortical Network Motifs for Short-Term Memory during Learning | {{Nature Communications}}},
  url = {https://www.nature.com/articles/s41467-023-42609-4},
  urldate = {2023-11-20},
  file = {D:\Zotero Storage\Zotero\storage\MCI7A46A\s41467-023-42609-4.html}
}

@article{ermentroutFoundationsMathematicalNeuroscience,
  title = {Foundations of {{Mathematical Neuroscience}}},
  author = {Ermentrout, Bard and Terman, David},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\UW4J9DYM\Ermentrout and Terman - Foundations of Mathematical Neuroscience.pdf}
}

@article{eschmannImprovingCognitiveControl2022,
  title = {Improving Cognitive Control: {{Is}} Theta Neurofeedback Training Associated with Proactive Rather than Reactive Control Enhancement?},
  author = {Eschmann, K. C. J. and Mecklinger, A.},
  date = {2022-05},
  journaltitle = {Psychophysiology},
  volume = {59},
  number = {5},
  pages = {e13873},
  issn = {1540-5958 (Electronic) 0048-5772 (Linking)},
  doi = {10.1111/psyp.13873},
  abstract = {Frontal-midline (FM) theta activity (4-8 Hz) is proposed to reflect a mechanism for cognitive control that is needed for working memory retention, manipulation, and interference resolution. Modulation of FM theta activity via neurofeedback training (NFT) demonstrated transfer to some but not all types of cognitive control. Therefore, the present study investigated whether FM theta NFT enhances performance and modulates underlying EEG characteristics in a delayed match to sample (DMTS) task requiring mainly proactive control and a color Stroop task requiring mainly reactive control. Moreover, temporal characteristics of transfer were explored over two posttests. Across seven 30-min NFT sessions, an FM theta training group exhibited a larger FM theta increase compared to an active control group who upregulated randomly chosen frequency bands. In a posttest performed 13 days after the last training session, the training group showed better retention performance in the DMTS task. Furthermore, manipulation performance was associated with NFT theta increase for the training but not the control group. Contrarily, behavioral group differences and their relation to FM theta change were not significant in the Stroop task, suggesting that NFT is associated with proactive but not reactive control enhancement. Transfer to both tasks at a posttest one day after training was not significant. Behavioral improvements were not accompanied by changes in FM theta activity, indicating no training-induced modulation of EEG characteristics. Together, these findings suggest that NFT supports transfer to cognitive control that manifests late after training but that other training-unspecific factors may also contribute to performance enhancement.},
  keywords = {*cognitive control,*executive functions,*frontal-midline theta,*Neurofeedback,*training,*working memory,Cognition,Electroencephalography,Humans,{Memory, Short-Term},Stroop Test,Theta Rhythm},
  file = {D:\Zotero Storage\Web Storage\Psychophysiology2022Eschmann_MecklingerImproving cognitive controlPsychophysiology595e13873CompNeuro_Uncategorized\Givenby_GuoEschmannK_MecklingerAKE_AMJournal Article\Eschmann_Mecklinger_2022_Improving cognitive control.pdf}
}

@article{ezakiCloserCriticalRestingstate2020,
  title = {Closer to Critical Resting-State Neural Dynamics in Individuals with Higher Fluid Intelligence},
  author = {Ezaki, Takahiro and Fonseca Dos Reis, Elohim and Watanabe, Takamitsu and Sakaki, Michiko and Masuda, Naoki},
  date = {2020-02-03},
  journaltitle = {Communications Biology},
  shortjournal = {Commun Biol},
  volume = {3},
  number = {1},
  pages = {52},
  issn = {2399-3642},
  doi = {10.1038/s42003-020-0774-y},
  url = {https://www.nature.com/articles/s42003-020-0774-y},
  urldate = {2023-08-22},
  abstract = {Abstract             According to the critical brain hypothesis, the brain is considered to operate near criticality and realize efficient neural computations. Despite the prior theoretical and empirical evidence in favor of the hypothesis, no direct link has been provided between human cognitive performance and the neural criticality. Here we provide such a key link by analyzing resting-state dynamics of functional magnetic resonance imaging (fMRI) networks at a whole-brain level. We develop a data-driven analysis method, inspired from statistical physics theory of spin systems, to map out the whole-brain neural dynamics onto a phase diagram. Using this tool, we show evidence that neural dynamics of human participants with higher fluid intelligence quotient scores are closer to a critical state, i.e., the boundary between the paramagnetic phase and the spin-glass (SG) phase. The present results are consistent with the notion of “edge-of-chaos” neural computation.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\ezakiCloserCriticalRestingstate2020 - Annotations (8242023, 44946 PM).md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@ezakiCloserCriticalRestingstate2020.md;D\:\\Zotero Storage\\Zotero\\storage\\9RXZLKNM\\Ezaki et al. - 2020 - Closer to critical resting-state neural dynamics i.pdf;D\:\\Zotero Storage\\Zotero\\storage\\WV83T2AR\\10.1038@s42003-020-0774-y.pdf.pdf}
}

@article{ezakiEnergyLandscapeAnalysis2017,
  title = {Energy Landscape Analysis of Neuroimaging Data},
  author = {Ezaki, Takahiro and Watanabe, Takamitsu and Ohzeki, Masayuki and Masuda, Naoki},
  date = {2017-05-15},
  journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {375},
  number = {2096},
  pages = {20160287},
  publisher = {{Royal Society}},
  doi = {10.1098/rsta.2016.0287},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rsta.2016.0287},
  urldate = {2023-08-23},
  abstract = {Computational neuroscience models have been used for understanding neural dynamics in the brain and how they may be altered when physiological or other conditions change. We review and develop a data-driven approach to neuroimaging data called the energy landscape analysis. The methods are rooted in statistical physics theory, in particular the Ising model, also known as the (pairwise) maximum entropy model and Boltzmann machine. The methods have been applied to fitting electrophysiological data in neuroscience for a decade, but their use in neuroimaging data is still in its infancy. We first review the methods and discuss some algorithms and technical aspects. Then, we apply the methods to functional magnetic resonance imaging data recorded from healthy individuals to inspect the relationship between the accuracy of fitting, the size of the brain system to be analysed and the data length. This article is part of the themed issue ‘Mathematical methods in medicine: neuroscience, cardiology and pathology’.},
  keywords = {Boltzmann machine,functional magnetic resonance imaging,Ising model,statistical physics},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@ezakiEnergyLandscapeAnalysis2017.md;D\:\\Zotero Storage\\Zotero\\storage\\3PPXDL6U\\Ezaki et al. - 2017 - Energy landscape analysis of neuroimaging data.pdf;D\:\\Zotero Storage\\Zotero\\storage\\PQ3KHZ8N\\ezaki2017.pdf.pdf}
}

@article{fangPredictiveNeuromodulationCingulofrontal2023,
  title = {Predictive Neuromodulation of Cingulo-Frontal Neural Dynamics in Major Depressive Disorder Using a Brain-Computer Interface System: {{A}} Simulation Study},
  shorttitle = {Predictive Neuromodulation of Cingulo-Frontal Neural Dynamics in Major Depressive Disorder Using a Brain-Computer Interface System},
  author = {Fang, Hao and Yang, Yuxiao},
  date = {2023},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {17},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2023.1119685},
  urldate = {2023-10-26},
  abstract = {IntroductionDeep brain stimulation (DBS) is a promising therapy for treatment-resistant major depressive disorder (MDD). MDD involves the dysfunction of a brain network that can exhibit complex nonlinear neural dynamics in multiple frequency bands. However, current open-loop and responsive DBS methods cannot track the complex multiband neural dynamics in MDD, leading to imprecise regulation of symptoms, variable treatment effects among patients, and high battery power consumption.MethodsHere, we develop a closed-loop brain-computer interface (BCI) system of predictive neuromodulation for treating MDD. We first use a biophysically plausible ventral anterior cingulate cortex (vACC)-dorsolateral prefrontal cortex (dlPFC) neural mass model of MDD to simulate nonlinear and multiband neural dynamics in response to DBS. We then use offline system identification to build a dynamic model that predicts the DBS effect on neural activity. We next use the offline identified model to design an online BCI system of predictive neuromodulation. The online BCI system consists of a dynamic brain state estimator and a model predictive controller. The brain state estimator estimates the MDD brain state from the history of neural activity and previously delivered DBS patterns. The predictive controller takes the estimated MDD brain state as the feedback signal and optimally adjusts DBS to regulate the MDD neural dynamics to therapeutic targets. We use the vACC-dlPFC neural mass model as a simulation testbed to test the BCI system and compare it with state-of-the-art open-loop and responsive DBS treatments of MDD.ResultsWe demonstrate that our dynamic model accurately predicts nonlinear and multiband neural activity. Consequently, the predictive neuromodulation system accurately regulates the neural dynamics in MDD, resulting in significantly smaller control errors and lower DBS battery power consumption than open-loop and responsive DBS.DiscussionOur results have implications for developing future precisely-tailored clinical closed-loop DBS treatments for MDD.},
  file = {D:\Zotero Storage\Zotero\storage\F5XRKVER\Fang 和 Yang - 2023 - Predictive neuromodulation of cingulo-frontal neur.pdf}
}

@article{fitzgeraldAcceleratedRepetitiveTranscranial2018,
  title = {Accelerated Repetitive Transcranial Magnetic Stimulation in the Treatment of Depression},
  author = {Fitzgerald, Paul B. and Hoy, Kate E. and Elliot, David and Susan McQueen, R. N. and Wambeek, Lenore E. and Daskalakis, Zafiris J.},
  date = {2018-06},
  journaltitle = {Neuropsychopharmacology},
  shortjournal = {Neuropsychopharmacol},
  volume = {43},
  number = {7},
  pages = {1565--1572},
  publisher = {{Nature Publishing Group}},
  issn = {1740-634X},
  doi = {10.1038/s41386-018-0009-9},
  url = {https://www.nature.com/articles/s41386-018-0009-9},
  urldate = {2023-09-24},
  abstract = {Repetitive transcranial magnetic stimulation (rTMS) is increasingly used clinically in the treatment of patients with major depressive disorder (MDD). However, rTMS treatment response can be slow. Early research suggests that accelerated forms of rTMS may be effective but no research has directly evaluated a schedule of accelerated rTMS compared to standard rTMS. To assess the efficacy of accelerated rTMS compared to standard daily rTMS., 115 outpatients with MDD received either accelerated rTMS (n\,=\,58) (i.e., 63,000 high frequency rTMS pulses delivered as 3 treatments per day over 3 days in week 1, 3 treatments over 2 days in week 2 and 3 treatments on a single day in week 3) or standard rTMS (n\,=\,57) (i.e., 63,000 total high frequency rTMS pulses delivered over 5 days per week for 4 weeks) following randomization. There were no significant differences in remission or response rates (p\,{$>$}\,0.05 for all analyses) or reduction in depression scores (Time by group interaction (F (5, 489.452)\,=\,1.711, p\,=\,0.130) between the accelerated and standard rTMS treatment groups. Accelerated treatment was associated with a higher rate of reported treatment discomfort. It is feasible to provide accelerated rTMS treatment for outpatients with depression and this is likely to produce meaningful antidepressant effects.},
  issue = {7},
  langid = {english},
  keywords = {Outcomes research,Translational research},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\aTMS\\scangosStatedependentResponsesIntracranial2021.md;D\:\\Zotero Storage\\Zotero\\storage\\8EDTNX6T\\Fitzgerald 等 - 2018 - Accelerated repetitive transcranial magnetic stimu.pdf}
}

@article{fitzgeraldExploringAlternativeRTMS2018a,
  title = {Exploring Alternative {{rTMS}} Strategies in Non-Responders to Standard High Frequency Left-Sided Treatment: {{A}} Switching Study},
  shorttitle = {Exploring Alternative {{rTMS}} Strategies in Non-Responders to Standard High Frequency Left-Sided Treatment},
  author = {Fitzgerald, Paul B. and Hoy, Kate E. and Elliot, David and McQueen, Susan and Wambeek, Lenore E. and Daskalakis, Zafiris J.},
  date = {2018-05},
  journaltitle = {Journal of Affective Disorders},
  shortjournal = {Journal of Affective Disorders},
  volume = {232},
  pages = {79--82},
  issn = {01650327},
  doi = {10.1016/j.jad.2018.02.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016503271731755X},
  urldate = {2023-09-05},
  abstract = {Background: High-frequency left-sided repetitive transcranial magnetic stimulation (rTMS) is now commonly used treatment for patients with depression. However, there are several other forms of rTMS (low-frequency right-sided and sequential bilateral rTMS) which have also been shown to be effective. No information has been systematically gathered on the likelihood of response to alternative forms of rTMS in patients who do not improve after an initial course of left-sided treatment. Objective: To evaluate whether there are differences in antidepressant response between switching to either lowfrequency right sided or sequential bilateral stimulation or continuing high-frequency left-sided TMS following non-response to an initial course of high-frequency left-sided rTMS. Methods: 113 rTMS naïve patients were provided with an initial three-week course of high-frequency left-sided rTMS. Non-responders were then randomised to receive another three weeks of left-sided treatment (n = 21), right-sided low frequency stimulation (n = 18) or sequential bilateral rTMS (n = 20). Results: Although there was an overall improvement in depressive symptoms in the randomised phase of the study, no significant differences in response was seen between the three treatment groups on Montgomery Asberg Depression Rating Scale or Hamilton Depression Rating Scale scores. Limitations: The main limitation of the study was the duration of treatment provided in both the lead in and random treatment phases. Conclusion: This study does not provide evidence for differences in response to different forms of rTMS in initial non-responders to left-sided stimulation. However, further studies with longer periods of treatment and a larger sample size are required to definitively establish or exclude between group differences in rTMS response in initial non-responders to treatment.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\T5UUZG3B\Fitzgerald et al. - 2018 - Exploring alternative rTMS strategies in non-respo.pdf}
}

@article{foxEfficacyTranscranialMagnetic2012,
  title = {Efficacy of {{Transcranial Magnetic Stimulation Targets}} for {{Depression Is Related}} to {{Intrinsic Functional Connectivity}} with the {{Subgenual Cingulate}}},
  author = {Fox, Michael D. and Buckner, Randy L. and White, Matthew P. and Greicius, Michael D. and Pascual-Leone, Alvaro},
  date = {2012-10-01},
  journaltitle = {Biological Psychiatry},
  shortjournal = {Biological Psychiatry},
  series = {Novel {{Pharmacotherapies}} for {{Depression}}},
  volume = {72},
  number = {7},
  pages = {595--603},
  issn = {0006-3223},
  doi = {10.1016/j.biopsych.2012.04.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0006322312004118},
  urldate = {2023-09-25},
  abstract = {Background Transcranial magnetic stimulation (TMS) to the left dorsolateral prefrontal cortex (DLPFC) is used clinically for the treatment of depression. However, the antidepressant mechanism remains unknown and its therapeutic efficacy remains limited. Recent data suggest that some left DLPFC targets are more effective than others; however, the reasons for this heterogeneity and how to capitalize on this information remain unclear. Methods Intrinsic (resting state) functional magnetic resonance imaging data from 98 normal subjects were used to compute functional connectivity with various left DLPFC TMS targets employed in the literature. Differences in functional connectivity related to differences in previously reported clinical efficacy were identified. This information was translated into a connectivity-based targeting strategy to identify optimized left DLPFC TMS coordinates. Results in normal subjects were tested for reproducibility in an independent cohort of 13 patients with depression. Results Differences in functional connectivity were related to previously reported differences in clinical efficacy across a distributed set of cortical and limbic regions. Dorsolateral prefrontal cortex TMS sites with better clinical efficacy were more negatively correlated (anticorrelated) with the subgenual cingulate. Optimum connectivity-based stimulation coordinates were identified in Brodmann area 46. Results were reproducible in patients with depression. Conclusions Reported antidepressant efficacy of different left DLPFC TMS sites is related to the anticorrelation of each site with the subgenual cingulate, potentially lending insight into the antidepressant mechanism of TMS and suggesting a role for intrinsically anticorrelated networks in depression. These results can be translated into a connectivity-based targeting strategy for focal brain stimulation that might be used to optimize clinical response.},
  keywords = {Depression,dorsolateral prefrontal cortex,intrinsic connectivity,MRI,resting state functional connectivity,subgenual,TMS,transcranial magnetic stimulation},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\2RIS42V3\\Fox 等 - 2012 - Efficacy of Transcranial Magnetic Stimulation Targ.pdf;D\:\\Zotero Storage\\Zotero\\storage\\KTD4W5WJ\\S0006322312004118.html}
}

@article{fraimanIsinglikeDynamicsLargescale2009,
  title = {Ising-like Dynamics in Large-Scale Functional Brain Networks},
  author = {Fraiman, Daniel and Balenzuela, Pablo and Foss, Jennifer and Chialvo, Dante R.},
  date = {2009-06-23},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {79},
  number = {6},
  pages = {061922},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.79.061922},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.79.061922},
  urldate = {2023-11-03},
  abstract = {Brain “rest” is defined—more or less unsuccessfully—as the state in which there is no explicit brain input or output. This work focuses on the question of whether such state can be comparable to any known dynamical state. For that purpose, correlation networks from human brain functional magnetic resonance imaging are contrasted with correlation networks extracted from numerical simulations of the Ising model in two dimensions at different temperatures. For the critical temperature Tc, striking similarities appear in the most relevant statistical properties, making the two networks indistinguishable from each other. These results are interpreted here as lending support to the conjecture that the dynamics of the functioning brain is near a critical point.},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\DKFL7GB4\\Fraiman 等 - 2009 - Ising-like dynamics in large-scale functional brai.pdf;D\:\\Zotero Storage\\Zotero\\storage\\M8PIF39Z\\PhysRevE.79.html}
}

@article{friesNeuronalGammaBandSynchronization2009,
  title = {Neuronal {{Gamma-Band Synchronization}} as a {{Fundamental Process}} in {{Cortical Computation}}},
  author = {Fries, Pascal},
  date = {2009-06-01},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu. Rev. Neurosci.},
  volume = {32},
  number = {1},
  pages = {209--224},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev.neuro.051508.135603},
  url = {https://www.annualreviews.org/doi/10.1146/annurev.neuro.051508.135603},
  urldate = {2023-12-11},
  abstract = {Neuronal gamma-band synchronization is found in many cortical areas, is induced by different stimuli or tasks, and is related to several cognitive capacities. Thus, it appears as if many different gamma-band synchronization phenomena subserve many different functions. I argue that gamma-band synchronization is a fundamental process that subserves an elemental operation of cortical computation. Cortical computation unfolds in the interplay between neuronal dynamics and structural neuronal connectivity. A core motif of neuronal connectivity is convergence, which brings about both selectivity and invariance of neuronal responses. However, those core functions can be achieved simultaneously only if converging neuronal inputs are functionally segmented and if only one segment is selected at a time. This segmentation and selection can be elegantly achieved if structural connectivity interacts with neuronal synchronization. I propose that this process is at least one of the fundamental functions of gamma-band synchronization, which then subserves numerous higher cognitive functions.},
  langid = {english},
  keywords = {gmma band,oscillations,Review},
  file = {D:\Zotero Storage\Zotero\storage\U7NXKUXG\Fries - 2009 - Neuronal Gamma-Band Synchronization as a Fundament.pdf}
}

@article{fristonActiveInferenceProcess2017,
  title = {Active {{Inference}}: {{A Process Theory}}},
  author = {Friston, K. and FitzGerald, T. and Rigoli, F. and Schwartenbeck, P. and Pezzulo, G.},
  date = {2017-01},
  journaltitle = {Neural Comput},
  volume = {29},
  number = {1},
  pages = {1--49},
  issn = {1530-888X (Electronic) 0899-7667 (Linking)},
  doi = {10.1162/NECO_a_00912},
  abstract = {This article describes a process theory based on active inference and belief propagation. Starting from the premise that all neuronal processing (and action selection) can be explained by maximizing Bayesian model evidence-or minimizing variational free energy-we ask whether neuronal responses can be described as a gradient descent on variational free energy. Using a standard (Markov decision process) generative model, we derive the neuronal dynamics implicit in this description and reproduce a remarkable range of well-characterized neuronal phenomena. These include repetition suppression, mismatch negativity, violation responses, place-cell activity, phase precession, theta sequences, theta-gamma coupling, evidence accumulation, race-to-bound dynamics, and transfer of dopamine responses. Furthermore, the (approximately Bayes' optimal) behavior prescribed by these dynamics has a degree of face validity, providing a formal explanation for reward seeking, context learning, and epistemic foraging. Technically, the fact that a gradient descent appears to be a valid description of neuronal activity means that variational free energy is a Lyapunov function for neuronal dynamics, which therefore conform to Hamilton's principle of least action.}
}

@book{gallweyInnerGameTennis,
  title = {The Inner Game of Tennis},
  author = {Gallwey, W.Timothy},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\GallweyThe inner game of tennisBooksGallweyWWGBook\-The inner game of tennis.pdf}
}

@article{gershmanWhatDoesFree2019,
  title = {What Does the Free Energy Principle Tell Us about the Brain?},
  author = {Gershman, Samuel J},
  date = {2019-10-25},
  journaltitle = {Neurons, Behavior, Data analysis, and Theory},
  volume = {2},
  number = {3},
  issn = {2690-2664},
  doi = {10.51628/001c.10839},
  url = {https://nbdt.scholasticahq.com/article/10839-what-does-the-free-energy-principle-tell-us-about-the-brain},
  urldate = {2023-11-28},
  abstract = {The free energy principle has been proposed as a unifying account of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\A4WNPI5T\Gershman - 2019 - What does the free energy principle tell us about .pdf}
}

@book{gerstnerNeuronalDynamicsSingle2014,
  title = {Neuronal {{Dynamics}}: {{From Single Neurons}} to {{Networks}} and {{Models}} of {{Cognition}}},
  shorttitle = {Neuronal {{Dynamics}}},
  author = {Gerstner, Wulfram and Kistler, Werner M. and Naud, Richard and Paninski, Liam},
  date = {2014-07-24},
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9781107447615},
  url = {https://www.cambridge.org/core/product/identifier/9781107447615/type/book},
  urldate = {2023-08-22},
  abstract = {What happens in our brain when we make a decision? What triggers a neuron to send out a signal? What is the neural code? This textbook for advanced undergraduate and beginning graduate students provides a thorough and up-to-date introduction to the fields of computational and theoretical neuroscience. It covers classical topics, including the Hodgkin-Huxley equations and Hopfield model, as well as modern developments in the field such as Generalized Linear Models and decision theory. Concepts are introduced using clear step-by-step explanations suitable for readers with only a basic knowledge of differential equations and probabilities, and are richly illustrated by figures and worked-out examples. End-of-chapter summaries and classroom-tested exercises make the book ideal for courses or for self-study. The authors also give pointers to the literature and an extensive bibliography, which will prove invaluable to readers interested in further study.},
  isbn = {978-1-107-06083-8 978-1-107-63519-7 978-1-107-44761-5},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\Y2427SGI\Gerstner et al. - 2014 - Neuronal Dynamics From Single Neurons to Networks.pdf}
}

@article{gokcenDisentanglingFlowSignals2022,
  title = {Disentangling the Flow of Signals between Populations of Neurons},
  author = {Gokcen, Evren and Jasper, Anna I. and Semedo, João D. and Zandvakili, Amin and Kohn, Adam and Machens, Christian K. and Yu, Byron M.},
  date = {2022},
  journaltitle = {Nature Computational Science},
  volume = {2},
  number = {8},
  pages = {512--525},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00282-5}
}

@article{goldmanComputationalTrainingNext2017,
  title = {Computational Training for the next Generation of Neuroscientists},
  author = {Goldman, M. S. and Fee, M. S.},
  date = {2017-10},
  journaltitle = {Curr Opin Neurobiol},
  volume = {46},
  pages = {25--30},
  issn = {1873-6882 (Electronic) 0959-4388 (Linking)},
  doi = {10.1016/j.conb.2017.06.007},
  abstract = {Neuroscience research has become increasingly reliant upon quantitative and computational data analysis and modeling techniques. However, the vast majority of neuroscientists are still trained within the traditional biology curriculum, in which computational and quantitative approaches beyond elementary statistics may be given little emphasis. Here we provide the results of an informal poll of computational and other neuroscientists that sought to identify critical needs, areas for improvement, and educational resources for computational neuroscience training. Motivated by this survey, we suggest steps to facilitate quantitative and computational training for future neuroscientists.},
  keywords = {Computational Biology/*education,Humans,Neurosciences/*education,Surveys and Questionnaires}
}

@article{goldNeuralBasisDecision2007,
  title = {The Neural Basis of Decision Making},
  author = {Gold, Joshua I. and family=Shadlen, given=Michael N. \%J Annual, prefix=review of neuroscience, useprefix=false},
  date = {2007},
  volume = {30},
  number = {1},
  pages = {535--574}
}

@online{hajimolahoseiniTrainingAccelerationLowRank2023,
  title = {Training {{Acceleration}} of {{Low-Rank Decomposed Networks}} Using {{Sequential Freezing}} and {{Rank Quantization}}},
  author = {Hajimolahoseini, Habib and Ahmed, Walid and Liu, Yang},
  date = {2023-09-07},
  eprint = {2309.03824},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.03824},
  urldate = {2023-09-13},
  abstract = {Low Rank Decomposition (LRD) is a model compression technique applied to the weight tensors of deep learning models in order to reduce the number of trainable parameters and computational complexity. However, due to high number of new layers added to the architecture after applying LRD, it may not lead to a high training/inference acceleration if the decomposition ranks are not small enough. The issue is that using small ranks increases the risk of significant accuracy drop after decomposition. In this paper, we propose two techniques for accelerating low rank decomposed models without requiring to use small ranks for decomposition. These methods include rank optimization and sequential freezing of decomposed layers. We perform experiments on both convolutional and transformer-based models. Experiments show that these techniques can improve the model throughput up to 60\% during training and 37\% during inference when combined together while preserving the accuracy close to that of the original models.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@hajimolahoseiniTrainingAccelerationLowRank2023.md;D\:\\Zotero Storage\\Zotero\\storage\\3875PJ8W\\Hajimolahoseini et al. - 2023 - Training Acceleration of Low-Rank Decomposed Netwo.pdf}
}

@article{hanslmayrEntrainmentPrefrontalBeta2014,
  title = {Entrainment of Prefrontal Beta Oscillations Induces an Endogenous Echo and Impairs Memory Formation},
  author = {Hanslmayr, S. and Matuschek, J. and Fellner, M. C.},
  date = {2014-04-14},
  journaltitle = {Curr Biol},
  volume = {24},
  number = {8},
  pages = {904--9},
  issn = {1879-0445 (Electronic) 0960-9822 (Linking)},
  doi = {10.1016/j.cub.2014.03.007},
  abstract = {Brain oscillations across all frequency bands play a key role for memory formation. Specifically, desynchronization of local neuronal assemblies in the left inferior prefrontal cortex (PFC) in the beta frequency ( approximately 18 Hz) has been shown to be central for encoding of verbal memories. However, it remains elusive whether prefrontal beta desynchronization is causally relevant for memory formation and whether these endogenous beta oscillations can be entrained by external stimulation. By using combined EEG-TMS (transcranial magnetic stimulation), we here address these fundamental questions in human participants performing a word-list learning task. Confirming our predictions, memory encoding was selectively impaired when the left inferior frontal gyrus (IFG) was driven at beta (18.7 Hz) compared to stimulation at other frequencies (6.8 Hz and 10.7 Hz) and to ineffective sham stimulation (18.7 Hz). Furthermore, a sustained oscillatory "echo" in the left IFG, which outlasted the stimulation period by approximately 1.5 s, was observed solely after beta stimulation. The strength of this beta echo was related to memory impairment on a between-subjects level. These results show endogenous oscillatory entrainment effects and behavioral impairment selectively in beta frequency for stimulation of the left IFG, demonstrating an intimate causal relationship between prefrontal beta desynchronization and memory formation.},
  keywords = {{*Models, Psychological},Adult,Beta Rhythm/*physiology,Biological Clocks/*physiology,Electroencephalography,Female,Humans,Learning/physiology,Male,Memory/*physiology,Prefrontal Cortex/*physiology,Transcranial Magnetic Stimulation}
}

@article{harperThetaDeltaBand2014,
  title = {Theta and Delta Band Activity Explain {{N2}} and {{P3 ERP}} Component Activity in a Go/No-Go Task},
  author = {Harper, J. and Malone, S. M. and Bernat, E. M.},
  date = {2014-01},
  journaltitle = {Clin Neurophysiol},
  volume = {125},
  number = {1},
  pages = {124--32},
  issn = {1872-8952 (Electronic) 1388-2457 (Linking)},
  doi = {10.1016/j.clinph.2013.06.025},
  abstract = {OBJECTIVES: Recent work indicates that the feedback negativity and P3 components from gambling feedback tasks can be understood as mixtures of functionally distinct processes occurring separately in theta and delta frequency bands. The current study was conducted to assess whether dissociable processes occurring in the theta and delta bands would similarly account for activity underlying N2 and P3 components in a go/no-go task. METHODS: The current study measured EEG signals from 66 participants during a go/no-go task, and a time-frequency principal components analysis decomposition approach was used to extract theta and delta measures from condition averages. RESULTS: Theta and delta measures separately increased in relation to response inhibition, and were uniquely related to the N2 and P3 components, as predicted. CONCLUSIONS: Findings support the view that the theta and delta measures indexed separable processes related to response inhibition, and better indexed the processes underlying N2 and P3 components in this go/no-go task. SIGNIFICANCE: Theta and delta measures may index separable functional processes across other common ERP tasks, and may represent an improved target for research relative to standard time-domain components.},
  pmcid = {PMC4312493},
  keywords = {*Delta Rhythm,*Neuropsychological Tests,*Theta Rhythm,Adult,Behavior,Cognition/*physiology,Delta,Eeg,Evoked Potentials/*physiology,{Feedback, Physiological},Female,Gambling,Humans,Male,Principal Component Analysis,Reaction Time,Response inhibition,Theta,Time-frequency,Young Adult}
}

@article{harrisonPPMDecayComputationalModel2020,
  title = {{{PPM-Decay}}: {{A}} Computational Model of Auditory Prediction with Memory Decay},
  author = {Harrison, P. M. C. and Bianco, R. and Chait, M. and Pearce, M. T.},
  date = {2020-11},
  journaltitle = {PLoS Comput Biol},
  volume = {16},
  number = {11},
  pages = {e1008304},
  issn = {1553-7358 (Electronic) 1553-734X (Print) 1553-734X (Linking)},
  doi = {10.1371/journal.pcbi.1008304},
  abstract = {Statistical learning and probabilistic prediction are fundamental processes in auditory cognition. A prominent computational model of these processes is Prediction by Partial Matching (PPM), a variable-order Markov model that learns by internalizing n-grams from training sequences. However, PPM has limitations as a cognitive model: in particular, it has a perfect memory that weights all historic observations equally, which is inconsistent with memory capacity constraints and recency effects observed in human cognition. We address these limitations with PPM-Decay, a new variant of PPM that introduces a customizable memory decay kernel. In three studies-one with artificially generated sequences, one with chord sequences from Western music, and one with new behavioral data from an auditory pattern detection experiment-we show how this decay kernel improves the model's predictive performance for sequences whose underlying statistics change over time, and enables the model to capture effects of memory constraints on auditory pattern detection. The resulting model is available in our new open-source R package, ppm (https://github.com/pmcharrison/ppm).},
  pmcid = {PMC7668605},
  keywords = {*Auditory Perception,*Computer Simulation,*Memory,Algorithms,Humans,Music}
}

@article{heilbronGreatExpectationsThere2018,
  title = {Great {{Expectations}}: {{Is}} There {{Evidence}} for {{Predictive Coding}} in {{Auditory Cortex}}?},
  author = {Heilbron, M. and Chait, M.},
  date = {2018-10-01},
  journaltitle = {Neuroscience},
  volume = {389},
  pages = {54--73},
  issn = {1873-7544 (Electronic) 0306-4522 (Linking)},
  doi = {10.1016/j.neuroscience.2017.07.061},
  abstract = {Predictive coding is possibly one of the most influential, comprehensive, and controversial theories of neural function. While proponents praise its explanatory potential, critics object that key tenets of the theory are untested or even untestable. The present article critically examines existing evidence for predictive coding in the auditory modality. Specifically, we identify five key assumptions of the theory and evaluate each in the light of animal, human and modeling studies of auditory pattern processing. For the first two assumptions - that neural responses are shaped by expectations and that these expectations are hierarchically organized - animal and human studies provide compelling evidence. The anticipatory, predictive nature of these expectations also enjoys empirical support, especially from studies on unexpected stimulus omission. However, for the existence of separate error and prediction neurons, a key assumption of the theory, evidence is lacking. More work exists on the proposed oscillatory signatures of predictive coding, and on the relation between attention and precision. However, results on these latter two assumptions are mixed or contradictory. Looking to the future, more collaboration between human and animal studies, aided by model-based analyses will be needed to test specific assumptions and implementations of predictive coding - and, as such, help determine whether this popular grand theory can fulfill its expectations.},
  keywords = {Animals,auditory,Auditory Cortex/*physiology,bayesian brain,Humans,Mmn,{Models, Neurological},Motivation/*physiology,Neurons/*physiology,predictive coding,Psychoacoustics,Ssa}
}

@article{hennigHowLearningUnfolds2021,
  title = {How Learning Unfolds in the Brain: Toward an Optimization View},
  author = {Hennig, J. A. and Oby, E. R. and Losey, D. M. and Batista, A. P. and Yu, B. M. and Chase, S. M.},
  date = {2021-12-01},
  journaltitle = {Neuron},
  volume = {109},
  number = {23},
  pages = {3720--3735},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2021.09.005},
  abstract = {How do changes in the brain lead to learning? To answer this question, consider an artificial neural network (ANN), where learning proceeds by optimizing a given objective or cost function. This "optimization framework" may provide new insights into how the brain learns, as many idiosyncratic features of neural activity can be recapitulated by an ANN trained to perform the same task. Nevertheless, there are key features of how neural population activity changes throughout learning that cannot be readily explained in terms of optimization and are not typically features of ANNs. Here we detail three of these features: (1) the inflexibility of neural variability throughout learning, (2) the use of multiple learning processes even during simple tasks, and (3) the presence of large task-nonspecific activity changes. We propose that understanding the role of these features in the brain will be key to describing biological learning using an optimization framework.},
  pmcid = {PMC8639641},
  keywords = {*Brain,*Learning,Algorithms,{Neural Networks, Computer},Problem Solving}
}

@article{hitchcockComputationalPsychiatryNeeds2022,
  title = {Computational {{Psychiatry Needs Time}} and {{Context}}},
  author = {Hitchcock, Peter F. and Fried, Eiko I. and Frank, Michael J.},
  date = {2022},
  journaltitle = {Annual Review of Psychology},
  volume = {73},
  number = {1},
  eprint = {34579545},
  eprinttype = {pmid},
  pages = {243--270},
  doi = {10.1146/annurev-psych-021621-124910},
  url = {https://doi.org/10.1146/annurev-psych-021621-124910},
  urldate = {2023-10-17},
  abstract = {Why has computational psychiatry yet to influence routine clinical practice? One reason may be that it has neglected context and temporal dynamics in the models of certain mental health problems. We develop three heuristics for estimating whether time and context are important to a mental health problem: Is it characterized by a core neurobiological mechanism? Does it follow a straightforward natural trajectory? And is intentional mental content peripheral to the problem? For many problems the answers are no, suggesting that modeling time and context is critical. We review computational psychiatry advances toward this end, including modeling state variation, using domain-specific stimuli, and interpreting differences in context. We discuss complementary network and complex systems approaches. Novel methods and unification with adjacent fields may inspire a new generation of computational psychiatry.},
  keywords = {computational psychiatry,domain specificity,functional analysis,network approach,state versus trait,temporal dynamics},
  file = {D:\Zotero Storage\Zotero\storage\KAAKC4QJ\Hitchcock 等 - 2022 - Computational Psychiatry Needs Time and Context.pdf}
}

@article{hoAgerelatedChangesTaskspecific2012,
  title = {Age-Related Changes of Task-Specific Brain Activity in Normal Aging},
  author = {Ho, M. C. and Chou, C. Y. and Huang, C. F. and Lin, Y. T. and Shih, C. S. and Han, S. Y. and Shen, M. H. and Chen, T. C. and Liang, C. L. and Lu, M. C. and Liu, C. J.},
  date = {2012-01-17},
  journaltitle = {Neurosci Lett},
  volume = {507},
  number = {1},
  pages = {78--83},
  issn = {1872-7972 (Electronic) 0304-3940 (Linking)},
  doi = {10.1016/j.neulet.2011.11.057},
  abstract = {An important question in healthcare for older patients is whether age-related changes in cortical reorganization can be measured with advancing age. This study investigated the factors behind such age-related changes, using time-frequency analysis of event-related potentials (ERPs). We hypothesized that brain rhythms was affected by age-related changes, which could be reflected in the ERP indices. An oddball task was conducted in two experimental groups, namely young participants (N=15; mean age 23.7+/-2.8 years) and older participants (N=15; mean age 70.1+/-7.9 years). Two types of stimuli were used: the target (1 kHz frequency) and standard (2 kHz frequency). We scrutinized three ERP indices: event-related spectral power (ERPSP), inter-trial phase-locking (ITPL), and event-related cross-phase coherence (ERPCOH). Both groups performed equally well for correct response rate. However, the results revealed a statistically significant age difference for inter-trial comparison. Compared with the young, the older participants showed the following age-related changes: (a) power activity decreased; however, an increase was found only in the late (P3, 280-450 ms) theta (4-7 Hz) component over the bilateral frontal and temporo-frontal areas; (b) low phase-locking in the early (N1, 80-140 ms) theta band over the parietal/frontal (right) regions appeared; (c) the functional connections decreased in the alpha (7-13 Hz) and beta (13-30 Hz) bands, but no difference emerged in the theta band between the two groups. These results indicate that age-related changes in task-specific brain activity for a normal aging population can be depicted using the three ERP indices.},
  keywords = {*Psychomotor Performance,Acoustic Stimulation/methods,Aged,Aging/*physiology,Auditory Cortex/*physiology,Electroencephalography/*methods,{Evoked Potentials, Auditory/*physiology},Female,Humans,Male,Pitch Perception/*physiology,Young Adult}
}

@online{HopfieldNeuralNetwork,
  title = {Hopfield {{Neural Network}} and {{Anisotropic Ising Model}} | {{SpringerLink}}},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-60577-3_45},
  urldate = {2023-10-11}
}

@article{huangCircuitModelsLowDimensional2019,
  title = {Circuit {{Models}} of {{Low-Dimensional Shared Variability}} in {{Cortical Networks}}},
  author = {Huang, C. and Ruff, D. A. and Pyle, R. and Rosenbaum, R. and Cohen, M. R. and Doiron, B.},
  date = {2019-01-16},
  journaltitle = {Neuron},
  volume = {101},
  number = {2},
  pages = {337-348 e4},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2018.11.034},
  abstract = {Trial-to-trial variability is a reflection of the circuitry and cellular physiology that make up a neuronal network. A pervasive yet puzzling feature of cortical circuits is that despite their complex wiring, population-wide shared spiking variability is low dimensional. Previous model cortical networks cannot explain this global variability, and rather assume it is from external sources. We show that if the spatial and temporal scales of inhibitory coupling match known physiology, networks of model spiking neurons internally generate low-dimensional shared variability that captures population activity recorded in vivo. Shifting spatial attention into the receptive field of visual neurons has been shown to differentially modulate shared variability within and between brain areas. A top-down modulation of inhibitory neurons in our network provides a parsimonious mechanism for this attentional modulation. Our work provides a critical link between observed cortical circuit structure and realistic shared neuronal variability and its modulation.},
  pmcid = {PMC8238668},
  keywords = {*attention,*cortical model,*excitatory/inhibitory balance,*low dimensional,{*Models, Neurological},*neuronal variability,*noise correlations,Action Potentials/physiology,Animals,Attention/*physiology,Computer Simulation,{Factor Analysis, Statistical},Humans,Nerve Net/*physiology,Neural Inhibition/physiology,Neurons/*physiology,Photic Stimulation,Visual Cortex/*cytology}
}

@article{huangMEGSourceImaging2014,
  title = {{{MEG Source Imaging Method}} Using {{Fast L1 Minimum-norm}} and Its {{Applications}} to {{Signals}} with {{Brain Noise}} and {{Human Resting-state Source Amplitude Images}}},
  author = {Huang, Ming-Xiong and Huang, Charles W. and Robb, Ashley and Angeles, AnneMarie and Nichols, Sharon L. and Baker, Dewleen G. and Song, Tao and Harrington, Deborah L. and Theilmann, Rebecca J. and Srinivasan, Ramesh and Heister, David and Diwakar, Mithun and Canive, Jose M. and Edgar, J. Christopher and Chen, Yu-Han and Ji, Zhengwei and Shen, Max and El-Gabalawy, Fady and Levy, Michael and McLay, Robert and Webb-Murphy, Jennifer and Liu, Thomas T. and Drake, Angela and Lee, Roland R.},
  date = {2014-01-01},
  journaltitle = {NeuroImage},
  shortjournal = {Neuroimage},
  volume = {84},
  eprint = {24055704},
  eprinttype = {pmid},
  pages = {585--604},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2013.09.022},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4096863/},
  urldate = {2023-12-05},
  abstract = {The present study developed a fast MEG source imaging technique based on Fast Vector-based Spatio-Temporal Analysis using a L1-minimum-norm (Fast-VESTAL) and then used the method to obtain the source amplitude images of resting-state magnetoencephalography (MEG) signals for different frequency bands. The Fast-VESTAL technique consists of two steps. First, L1-minimum-norm MEG source images were obtained for the dominant spatial modes of sensor-waveform covariance matrix. Next, accurate source time-courses with millisecond temporal resolution were obtained using an inverse operator constructed from the spatial source images of Step 1. Using simulations, Fast-VESTAL’s performance of was assessed for its 1) ability to localize multiple correlated sources; 2) ability to faithfully recover source time-courses; 3) robustness to different SNR conditions including SNR with negative dB levels; 4) capability to handle correlated brain noise; and 5) statistical maps of MEG source images. An objective pre-whitening method was also developed and integrated with Fast-VESTAL to remove correlated brain noise. Fast-VESTAL’s performance was then examined in the analysis of human mediannerve MEG responses. The results demonstrated that this method easily distinguished sources in the entire somatosensory network. Next, Fast-VESTAL was applied to obtain the first whole-head MEG source-amplitude images from resting-state signals in 41 healthy control subjects, for all standard frequency bands. Comparisons between resting-state MEG sources images and known neurophysiology were provided. Additionally, in simulations and cases with MEG human responses, the results obtained from using conventional beamformer technique were compared with those from Fast-VESTAL, which highlighted the beamformer’s problems of signal leaking and distorted source time-courses.},
  pmcid = {PMC4096863},
  keywords = {Beamformer,MEG,Source Localization},
  file = {D:\Zotero Storage\Zotero\storage\NFDCJPR9\Huang 等 - 2014 - MEG Source Imaging Method using Fast L1 Minimum-no.pdf}
}

@book{huangStatisticalMechanicsNeural2021,
  title = {Statistical {{Mechanics}} of {{Neural Networks}}},
  author = {Huang, Haiping},
  date = {2021},
  publisher = {{Springer Nature Singapore}},
  location = {{Singapore}},
  doi = {10.1007/978-981-16-7570-6},
  url = {https://link.springer.com/10.1007/978-981-16-7570-6},
  urldate = {2023-12-04},
  isbn = {9789811675690 9789811675706},
  langid = {english},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\Springer Nature Singapore2021HuangStatistical Mechanics of Neural NetworksSpringer Nature SingaporeBooksHuangHHH图书\2021_-Statistical Mechanics of Neural Networks.pdf}
}

@article{huysComputationalPsychiatryBridge2016,
  title = {Computational Psychiatry as a Bridge from Neuroscience to Clinical Applications},
  author = {Huys, Quentin JM and Maia, Tiago V. and Frank, Michael J.},
  date = {2016},
  journaltitle = {Nature neuroscience},
  volume = {19},
  number = {3},
  pages = {404--413},
  publisher = {{Nature Publishing Group US New York}},
  url = {https://www.nature.com/articles/nn.4238},
  urldate = {2023-10-14},
  file = {D:\Zotero Storage\Zotero\storage\BP87SFQQ\PMC5443409.html}
}

@article{huysDepressionDecisiontheoreticAnalysis2015,
  title = {Depression: A Decision-Theoretic Analysis},
  shorttitle = {Depression},
  author = {Huys, Quentin J. M. and Daw, Nathaniel D. and Dayan, Peter},
  date = {2015-07-08},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu Rev Neurosci},
  volume = {38},
  eprint = {25705929},
  eprinttype = {pmid},
  pages = {1--23},
  issn = {1545-4126},
  doi = {10.1146/annurev-neuro-071714-033928},
  abstract = {The manifold symptoms of depression are common and often transient features of healthy life that are likely to be adaptive in difficult circumstances. It is when these symptoms enter a seemingly self-propelling spiral that the maladaptive features of a disorder emerge. We examine this malignant transformation from the perspective of the computational neuroscience of decision making, investigating how dysfunction of the brain's mechanisms of evaluation might lie at its heart. We start by considering the behavioral implications of pessimistic evaluations of decision variables. We then provide a selective review of work suggesting how such pessimism might arise via specific failures of the mechanisms of evaluation or state estimation. Finally, we analyze ways that miscalibration between the subject and environment may be self-perpetuating. We employ the formal framework of Bayesian decision theory as a foundation for this study, showing how most of the problems arise from one of its broad algorithmic facets, namely model-based reasoning.},
  langid = {english},
  keywords = {Bayes Theorem,Decision Making,decision theory,Decision Theory,depression,Depression,Humans,model-based control,model-free control,reinforcement learning},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\model\\Depression a decision-theoretic analysis.md;D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Annual Review of Neuroscience2015Huys et alDepressionAnnual Review of NeuroscienceAnnu Rev Neurosci381-23Depression\\Computational ModelHuysQ et alQH et al期刊文章\\2015_-Depression.pdf}
}

@article{ingramErrortunedModelSensorimotor2017,
  title = {An Error-Tuned Model for Sensorimotor Learning},
  author = {Ingram, James N. and Sadeghi, Mohsen and Flanagan, J. Randall and Wolpert, Daniel M.},
  date = {2017-12},
  journaltitle = {PLoS computational biology},
  shortjournal = {PLoS Comput Biol},
  volume = {13},
  number = {12},
  eprint = {29253869},
  eprinttype = {pmid},
  pages = {e1005883},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005883},
  abstract = {Current models of sensorimotor control posit that motor commands are generated by combining multiple modules which may consist of internal models, motor primitives or motor synergies. The mechanisms which select modules based on task requirements and modify their output during learning are therefore critical to our understanding of sensorimotor control. Here we develop a novel modular architecture for multi-dimensional tasks in which a set of fixed primitives are each able to compensate for errors in a single direction in the task space. The contribution of the primitives to the motor output is determined by both top-down contextual information and bottom-up error information. We implement this model for a task in which subjects learn to manipulate a dynamic object whose orientation can vary. In the model, visual information regarding the context (the orientation of the object) allows the appropriate primitives to be engaged. This top-down module selection is implemented by a Gaussian function tuned for the visual orientation of the object. Second, each module's contribution adapts across trials in proportion to its ability to decrease the current kinematic error. Specifically, adaptation is implemented by cosine tuning of primitives to the current direction of the error, which we show to be theoretically optimal for reducing error. This error-tuned model makes two novel predictions. First, interference should occur between alternating dynamics only when the kinematic errors associated with each oppose one another. In contrast, dynamics which lead to orthogonal errors should not interfere. Second, kinematic errors alone should be sufficient to engage the appropriate modules, even in the absence of contextual information normally provided by vision. We confirm both these predictions experimentally and show that the model can also account for data from previous experiments. Our results suggest that two interacting processes account for module selection during sensorimotor control and learning.},
  langid = {english},
  pmcid = {PMC5749863},
  keywords = {{Adaptation, Physiological},Biomechanical Phenomena,Computational Biology,Humans,Learning,Memory,{Models, Neurological},{Models, Psychological},Motor Skills,Psychomotor Performance,Sensorimotor Cortex,Task Performance and Analysis,Visual Perception},
  file = {D:\Zotero Storage\Zotero\storage\I789TSFI\Ingram 等 - 2017 - An error-tuned model for sensorimotor learning.pdf}
}

@article{ishiiHealthyPathologicalBrain2017,
  title = {Healthy and {{Pathological Brain Aging}}: {{From}} the {{Perspective}} of {{Oscillations}}, {{Functional Connectivity}}, and {{Signal Complexity}}},
  author = {Ishii, R. and Canuet, L. and Aoki, Y. and Hata, M. and Iwase, M. and Ikeda, S. and Nishida, K. and Ikeda, M.},
  date = {2017},
  journaltitle = {Neuropsychobiology},
  volume = {75},
  number = {4},
  pages = {151--161},
  issn = {1423-0224 (Electronic) 0302-282X (Linking)},
  doi = {10.1159/000486870},
  abstract = {Healthy aging is associated with impairment in cognitive information processing. Several neuroimaging methods such as functional magnetic resonance imaging, positron emission tomography and near-infrared spectroscopy have been used to explore healthy and pathological aging by relying on hemodynamic or metabolic changes that occur in response to brain activity. Since electroencephalography (EEG) and magnetoencephalography (MEG) are able to measure neural activity directly with a high temporal resolution of milliseconds, these neurophysiological techniques are particularly important to investigate the dynamics of brain activity underlying neurocognitive aging. It is well known that age is a major risk factor for Alzheimer's disease (AD), and that synaptic dysfunction represents an early sign of this disease associated with hallmark neuropathological findings. However, the neurophysiological mechanisms underlying AD are not fully elucidated. This review addresses healthy and pathological brain aging from a neurophysiological perspective, focusing on oscillatory activity changes during the resting state, event-related potentials and stimulus-induced oscillatory responses during cognitive or motor tasks, functional connectivity between brain regions, and changes in signal complexity. We also highlight the accumulating evidence on age-related EEG/MEG changes and biological markers of brain neurodegeneration, including genetic factors, structural abnormalities on magnetic resonance images, and the biochemical changes associated with Abeta deposition and tau pathology.},
  keywords = {Aging,Aging/*physiology,Biomarkers,Brain Waves,Brain/*physiology/*physiopathology,Cognition,Cognition/physiology,Electroencephalography,Event-related potentials,Functional connectivity,Humans,Magnetoencephalography,Motor Activity/physiology,Neural Pathways/physiology/physiopathology,Oscillatory activity,Signal complexity}
}

@article{jagielloRapidBrainResponses2019,
  title = {Rapid {{Brain Responses}} to {{Familiar}} vs. {{Unfamiliar Music}} - an {{EEG}} and {{Pupillometry}} Study},
  author = {Jagiello, R. and Pomper, U. and Yoneya, M. and Zhao, S. and Chait, M.},
  date = {2019-10-30},
  journaltitle = {Sci Rep},
  volume = {9},
  number = {1},
  pages = {15570},
  issn = {2045-2322 (Electronic) 2045-2322 (Linking)},
  doi = {10.1038/s41598-019-51759-9},
  abstract = {Human listeners exhibit marked sensitivity to familiar music, perhaps most readily revealed by popular "name that tune" games, in which listeners often succeed in recognizing a familiar song based on extremely brief presentation. In this work, we used electroencephalography (EEG) and pupillometry to reveal the temporal signatures of the brain processes that allow differentiation between a familiar, well liked, and unfamiliar piece of music. In contrast to previous work, which has quantified gradual changes in pupil diameter (the so-called "pupil dilation response"), here we focus on the occurrence of pupil dilation events. This approach is substantially more sensitive in the temporal domain and allowed us to tap early activity with the putative salience network. Participants (N = 10) passively listened to snippets (750 ms) of a familiar, personally relevant and, an acoustically matched, unfamiliar song, presented in random order. A group of control participants (N = 12), who were unfamiliar with all of the songs, was also tested. We reveal a rapid differentiation between snippets from familiar and unfamiliar songs: Pupil responses showed greater dilation rate to familiar music from 100-300 ms post-stimulus-onset, consistent with a faster activation of the autonomic salience network. Brain responses measured with EEG showed a later differentiation between familiar and unfamiliar music from 350 ms post onset. Remarkably, the cluster pattern identified in the EEG response is very similar to that commonly found in the classic old/new memory retrieval paradigms, suggesting that the recognition of brief, randomly presented, music snippets, draws on similar processes.},
  pmcid = {PMC6821741},
  keywords = {*Electroencephalography,{*Recognition, Psychology},Auditory Perception,Brain/*physiology,Female,Humans,Male,Music/*psychology,Pupil/*physiology,Young Adult}
}

@article{jiangTimevaryingDynamicNetwork2022,
  title = {Time-Varying Dynamic Network Model for Dynamic Resting State Functional Connectivity in {{fMRI}} and {{MEG}} Imaging},
  author = {Jiang, Fei and Jin, Huaqing and Gao, Yijing and Xie, Xihe and Cummings, Jennifer and Raj, Ashish and Nagarajan, Srikantan},
  date = {2022-07-01},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {254},
  pages = {119131},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2022.119131},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811922002592},
  urldate = {2023-12-09},
  abstract = {Dynamic resting state functional connectivity (RSFC) characterizes fluctuations that occur over time in functional brain networks. Existing methods to extract dynamic RSFCs, such as sliding-window and clustering methods that are inherently non-adaptive, have various limitations such as high-dimensionality, an inability to reconstruct brain signals, insufficiency of data for reliable estimation, insensitivity to rapid changes in dynamics, and a lack of generalizability across multiply functional imaging modalities. To overcome these deficiencies, we develop a novel and unifying time-varying dynamic network (TVDN) framework for examining dynamic resting state functional connectivity. TVDN includes a generative model that describes the relation between a low-dimensional dynamic RSFC and the brain signals, and an inference algorithm that automatically and adaptively learns the low-dimensional manifold of dynamic RSFC and detects dynamic state transitions in data. TVDN is applicable to multiple modalities of functional neuroimaging such as fMRI and MEG/EEG. The estimated low-dimensional dynamic RSFCs manifold directly links to the frequency content of brain signals. Hence we can evaluate TVDN performance by examining whether learnt features can reconstruct observed brain signals. We conduct comprehensive simulations to evaluate TVDN under hypothetical settings. We then demonstrate the application of TVDN with real fMRI and MEG data, and compare the results with existing benchmarks. Results demonstrate that TVDN is able to correctly capture the dynamics of brain activity and more robustly detect brain state switching both in resting state fMRI and MEG data.},
  keywords = {Brain state switch,Change point detection,Dynamic resting state functional connectivity,Functional magnetic resonance,Magnetoencephalography,Multi-modality imaging},
  file = {D:\Zotero Storage\Zotero\storage\M2NUK8VG\Jiang 等 - 2022 - Time-varying dynamic network model for dynamic res.pdf}
}

@article{kandeepanModelingAuditoryStimulated2020,
  title = {Modeling an Auditory Stimulated Brain under Altered States of Consciousness Using the Generalized {{Ising}} Model},
  author = {Kandeepan, Sivayini and Rudas, Jorge and Gomez, Francisco and Stojanoski, Bobby and Valluri, Sreeram and Owen, Adrian Mark and Naci, Lorina and Nichols, Emily Sophia and Soddu, Andrea},
  date = {2020-12-01},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {223},
  pages = {117367},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2020.117367},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811920308533},
  urldate = {2023-10-11},
  abstract = {Propofol is a short-acting medication that results in decreased levels of consciousness and is used for general anesthesia. Although it is the most commonly used anesthetic in the world, much remains unknown about the mechanisms by which it induces a loss of consciousness. Characterizing anesthesia-induced alterations to brain network activity might provide a powerful framework for understanding the neural mechanisms of unconsciousness. The aim of this work was to model brain activity in healthy brains during various stages of consciousness, as induced by propofol, in the auditory paradigm. We used the generalized Ising model (GIM) to fit the empirical fMRI data of healthy subjects while they listened to an audio clip from a movie. The external stimulus (audio clip) is believed to be at least partially driving a synchronization process of the brain activity and provides a similar conscious experience in different subjects. In order to observe the common synchronization among the subjects, a novel technique called the inter subject correlation (ISC) was implemented. We showed that the GIM—modified to incorporate the naturalistic external field—was able to fit the empirical task fMRI data in the awake state, in mild sedation, in deep sedation, and in recovery, at a temperature T* which is well above the critical temperature. To our knowledge this is the first study that captures human brain activity in response to real-life external stimuli at different levels of conscious awareness using mathematical modeling. This study might be helpful in the future to assess the level of consciousness of patients with disorders of consciousness and help in regaining their consciousness.},
  keywords = {Consciousness,Inter-subject correlation,Naturalistic stimuli,The generalized Ising model},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Ising\\kandeepanModelingAuditoryStimulated2020.md;D\:\\Zotero Storage\\Zotero\\storage\\SUAPCKCT\\Kandeepan 等 - 2020 - Modeling an auditory stimulated brain under altere.pdf;D\:\\Zotero Storage\\Zotero\\storage\\Z3Z6KVQF\\S1053811920308533.html}
}

@article{kantorSolvingConformalField2022,
  title = {Solving {{Conformal Field Theories}} with {{Artificial Intelligence}}},
  author = {Kántor, Gergely and Papageorgakis, Constantinos and Niarchos, Vasilis},
  date = {2022-01-24},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {128},
  number = {4},
  pages = {041601},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.128.041601},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.128.041601},
  urldate = {2023-10-11},
  abstract = {In this Letter, we deploy for the first time reinforcement-learning algorithms in the context of the conformal-bootstrap program to obtain numerical solutions of conformal field theories (CFTs). As an illustration, we use a soft actor-critic algorithm and find approximate solutions to the truncated crossing equations of two-dimensional CFTs, successfully identifying well-known theories like the 2D Ising model and the 2D CFT of a compactified scalar. Our methods can perform efficient high-dimensional searches that can be used to study arbitrary (unitary or nonunitary) CFTs in any spacetime dimension.},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\GNHZ3WFE\\EasyChair-Preprint-4355.pdf;D\:\\Zotero Storage\\Zotero\\storage\\S3S9J4VY\\Kántor 等 - 2022 - Solving Conformal Field Theories with Artificial I.pdf;D\:\\Zotero Storage\\Zotero\\storage\\33TX7RCB\\PhysRevLett.128.html}
}

@article{kaoSingletrialDynamicsMotor2015,
  title = {Single-Trial Dynamics of Motor Cortex and Their Applications to Brain-Machine Interfaces},
  author = {Kao, J. C. and Nuyujukian, P. and Ryu, S. I. and Churchland, M. M. and Cunningham, J. P. and Shenoy, K. V.},
  date = {2015-07-29},
  journaltitle = {Nat Commun},
  volume = {6},
  pages = {7759},
  issn = {2041-1723 (Electronic) 2041-1723 (Linking)},
  doi = {10.1038/ncomms8759},
  abstract = {Increasing evidence suggests that neural population responses have their own internal drive, or dynamics, that describe how the neural population evolves through time. An important prediction of neural dynamical models is that previously observed neural activity is informative of noisy yet-to-be-observed activity on single-trials, and may thus have a denoising effect. To investigate this prediction, we built and characterized dynamical models of single-trial motor cortical activity. We find these models capture salient dynamical features of the neural population and are informative of future neural activity on single trials. To assess how neural dynamics may beneficially denoise single-trial neural activity, we incorporate neural dynamics into a brain-machine interface (BMI). In online experiments, we find that a neural dynamical BMI achieves substantially higher performance than its non-dynamical counterpart. These results provide evidence that neural dynamics beneficially inform the temporal evolution of neural activity on single trials and may directly impact the performance of BMIs.},
  pmcid = {PMC4532790},
  keywords = {*Brain-Computer Interfaces,Animals,Brain/physiology,Macaca mulatta,Male,{Models, Neurological},Motor Cortex/*physiology}
}

@article{kassComputationalNeuroscienceMathematical2018,
  title = {Computational {{Neuroscience}}: {{Mathematical}} and {{Statistical Perspectives}}},
  shorttitle = {Computational {{Neuroscience}}},
  author = {Kass, Robert E. and Amari, Shun-Ichi and Arai, Kensuke and Brown, Emery N. and Diekman, Casey O. and Diesmann, Markus and Doiron, Brent and Eden, Uri T. and Fairhall, Adrienne L. and Fiddyment, Grant M. and Fukai, Tomoki and Grün, Sonja and Harrison, Matthew T. and Helias, Moritz and Nakahara, Hiroyuki and Teramae, Jun-nosuke and Thomas, Peter J. and Reimers, Mark and Rodu, Jordan and Rotstein, Horacio G. and Shea-Brown, Eric and Shimazaki, Hideaki and Shinomoto, Shigeru and Yu, Byron M. and Kramer, Mark A.},
  date = {2018},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {5},
  number = {1},
  pages = {183--214},
  doi = {10.1146/annurev-statistics-041715-033733},
  url = {https://doi.org/10.1146/annurev-statistics-041715-033733},
  urldate = {2023-11-24},
  abstract = {Mathematical and statistical models have played important roles in neuroscience, especially by describing the electrical activity of neurons recorded individually, or collectively across large networks. As the field moves forward rapidly, new challenges are emerging. For maximal effectiveness, those working to advance computational neuroscience will need to appreciate and exploit the complementary strengths of mechanistic theory and the statistical paradigm.},
  keywords = {neural data analysis,neural modeling,neural networks,theoretical neuroscience},
  file = {D:\Zotero Storage\Zotero\storage\FTA5YWA9\Kass 等 - 2018 - Computational Neuroscience Mathematical and Stati.pdf}
}

@article{kerestesFunctionalBrainImaging2013,
  title = {Functional Brain Imaging Studies of Youth Depression: {{A}} Systematic Review},
  shorttitle = {Functional Brain Imaging Studies of Youth Depression},
  author = {Kerestes, Rebecca and Davey, Christopher G. and Stephanou, Katerina and Whittle, Sarah and Harrison, Ben J.},
  date = {2013-12-11},
  journaltitle = {NeuroImage : Clinical},
  shortjournal = {Neuroimage Clin},
  volume = {4},
  eprint = {24455472},
  eprinttype = {pmid},
  pages = {209--231},
  issn = {2213-1582},
  doi = {10.1016/j.nicl.2013.11.009},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3895619/},
  urldate = {2023-10-14},
  abstract = {•               We provide a systematic review of fMRI studies in youth MDD.                                         •               Abnormal function is found in regions of the extended medial prefrontal network.                                         •               Findings in youth MDD show some important differences compared to adult MDD.                                         •               Future studies need to focus on the effects of puberty on medial network activity.                                         •               Longitudinal studies will help inform neurobiological models of youth MDD.},
  pmcid = {PMC3895619},
  file = {D:\Zotero Storage\Zotero\storage\ZLLUXGCH\Kerestes 等 - 2013 - Functional brain imaging studies of youth depressi.pdf}
}

@book{KillMockingbird,
  title = {To Kill a Mockingbird},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\To kill a mockingbirdBooks图书\-To kill a mockingbird.pdf}
}

@article{kirkbyAmygdalaHippocampusSubnetworkThat2018,
  title = {An {{Amygdala-Hippocampus Subnetwork}} That {{Encodes Variation}} in {{Human Mood}}},
  author = {Kirkby, Lowry A. and Luongo, Francisco J. and Lee, Morgan B. and Nahum, Mor and Van Vleet, Thomas M. and Rao, Vikram R. and Dawes, Heather E. and Chang, Edward F. and Sohal, Vikaas S.},
  date = {2018-11},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {175},
  number = {6},
  pages = {1688-1700.e14},
  issn = {00928674},
  doi = {10.1016/j.cell.2018.10.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867418313138},
  urldate = {2023-09-20},
  abstract = {Human brain networks that encode variation in mood on naturalistic timescales remain largely unexplored. Here we combine multi-site, semi-chronic, intracranial electroencephalography recordings from the human limbic system with machine learning methods to discover a brain subnetwork that correlates with variation in individual subjects’ self-reported mood over days. First we defined the subnetworks that influence intrinsic brain dynamics by identifying regions that showed coordinated changes in spectral coherence. The most common subnetwork, found in 13 of 21 subjects, was characterized by b-frequency coherence (13-30 Hz) between the amygdala and hippocampus. Increased variability of this subnetwork correlated with worsening mood across these 13 subjects. Moreover, these subjects had significantly higher trait anxiety than the 8 of 21 for whom this amygdala-hippocampus subnetwork was absent. These results demonstrate an approach for extracting network-behavior relationships from complex datasets, and they reveal a conserved subnetwork associated with a psychological trait that significantly influences intrinsic brain dynamics and encodes fluctuations in mood.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@kirkbyAmygdalaHippocampusSubnetworkThat2018.md;D\:\\Zotero Storage\\Zotero\\storage\\GT85XANZ\\Kirkby et al. - 2018 - An Amygdala-Hippocampus Subnetwork that Encodes Va.pdf}
}

@article{konakaDecodingRewardCuriosity2023,
  title = {Decoding Reward–Curiosity Conflict in Decision-Making from Irrational Behaviors},
  author = {Konaka, Yuki and Naoki, Honda},
  date = {2023-05-15},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  volume = {3},
  number = {5},
  pages = {418--432},
  issn = {2662-8457},
  doi = {10.1038/s43588-023-00439-w},
  url = {https://www.nature.com/articles/s43588-023-00439-w},
  urldate = {2023-11-28},
  abstract = {Abstract             Humans and animals are not always rational. They not only rationally exploit rewards but also explore an environment owing to their curiosity. However, the mechanism of such curiosity-driven irrational behavior is largely unknown. Here, we developed a decision-making model for a two-choice task based on the free energy principle, which is a theory integrating recognition and action selection. The model describes irrational behaviors depending on the curiosity level. We also proposed a machine learning method to decode temporal curiosity from behavioral data. By applying it to rat behavioral data, we found that the rat had negative curiosity, reflecting conservative selection sticking to more certain options and that the level of curiosity was upregulated by the expected future information obtained from an uncertain environment. Our decoding approach can be a fundamental tool for identifying the neural basis for reward–curiosity conflicts. Furthermore, it could be effective in diagnosing mental disorders.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\9RDG37DB\Konaka 和 Naoki - 2023 - Decoding reward–curiosity conflict in decision-mak.pdf}
}

@article{kreuzerComprehensiveReviewDorsomedial2019,
  title = {A {{Comprehensive Review}} of {{Dorsomedial Prefrontal Cortex rTMS Utilizing}} a {{Double Cone Coil}}},
  author = {Kreuzer, Peter M. and Downar, Jonathan and family=Ridder, given=Dirk, prefix=de, useprefix=true and Schwarzbach, Jens and Schecklmann, Martin and Langguth, Berthold},
  date = {2019-12-01},
  journaltitle = {Neuromodulation: Technology at the Neural Interface},
  shortjournal = {Neuromodulation: Technology at the Neural Interface},
  volume = {22},
  number = {8},
  pages = {851--866},
  issn = {1094-7159},
  doi = {10.1111/ner.12874},
  url = {https://www.sciencedirect.com/science/article/pii/S0002822321070267},
  urldate = {2023-09-24},
  abstract = {Background Repetitive transcranial magnetic stimulation (rTMS) has become increasingly popular during the last decades mainly driven by the antidepressant effects of dorsolateral prefrontal cortex stimulation with “butterfly” coils. Only recently, alternative targets such as the dorsomedial prefrontal cortex (dmPFC) have been brought into focus and innovative coil designs such as the angled geometry of the double cone coil (DCC) have raised hope to reach even deeper located targets. Objective To provide a systematic and comprehensive review on the application of rTMS stimulation of the dmPFC using the DCC in neuropathological and healthy samples. Methods We systematically searched the MEDLINE® database (http://www.ncbi.nlm.nih.gov/pubmed/). Due to the heterogeneous naming of DCC stimulation over the dmPFC a variety of search terms was applied resulting in a numeral quantity of 340 hits. Results DCC stimulation over the dmPFC has been proven to be safe and feasible in various neuropsychiatric disorders and in healthy subjects. Clinical results are encouraging, but have to be considered as preliminary as data from sham-controlled clinical trials and knowledge about the neurobiological underpinnings are still scarce. Conclusion DCC stimulation over the dmPFC represents a promising approach in the fast evolving noninvasive brain stimulation techniques aiming at the functional modulation of brain areas vitally involved in affect, sensory autonomic, cognitive, and salience regulation. This may hold potential for both neuroscientific research and clinical applications in the treatment of psychiatric disorders.},
  keywords = {ACDC anterior cingulate cortex dm-PFC dorsomedial prefrontal cortex double cone coil repetitive transcranial magnetic stimulation},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\DBT6TZBR\\Kreuzer 等 - 2019 - A Comprehensive Review of Dorsomedial Prefrontal C.pdf;D\:\\Zotero Storage\\Zotero\\storage\\7333MPI8\\S0002822321070267.html}
}

@article{kriegeskorteCognitiveComputationalNeuroscience2018,
  title = {Cognitive Computational Neuroscience},
  author = {Kriegeskorte, Nikolaus and Douglas, Pamela K.},
  date = {2018-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {9},
  pages = {1148--1160},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0210-5},
  url = {https://www.nature.com/articles/s41593-018-0210-5},
  urldate = {2023-10-16},
  abstract = {To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments. Cognitive science has developed computational models that decompose cognition into functional components. Computational neuroscience has modeled how interacting neurons can implement elementary components of cognition. It is time to assemble the pieces of the puzzle of brain computation and to better integrate these separate disciplines. Modern technologies enable us to measure and manipulate brain activity in unprecedentedly rich ways in animals and humans. However, experiments will yield theoretical insight only when employed to test brain-computational models. Here we review recent work in the intersection of cognitive science, computational neuroscience and artificial intelligence. Computational models that mimic brain information processing during perceptual, cognitive and control tasks are beginning to be developed and tested with brain and behavioral data.},
  issue = {9},
  langid = {english},
  keywords = {Cognitive neuroscience,Computational neuroscience},
  file = {D:\Zotero Storage\Zotero\storage\J4CUDKDB\Kriegeskorte 和 Douglas - 2018 - Cognitive computational neuroscience.pdf}
}

@article{liAbnormalCoreFunctional2022,
  title = {Abnormal Core Functional Connectivity on the Pathology of {{MDD}} and Antidepressant Treatment: {{A}} Systematic Review},
  shorttitle = {Abnormal Core Functional Connectivity on the Pathology of {{MDD}} and Antidepressant Treatment},
  author = {Li, Jianxiu and Chen, Junhao and Kong, Wenwen and Li, Xiaowei and Hu, Bin},
  date = {2022-01-01},
  journaltitle = {Journal of Affective Disorders},
  shortjournal = {Journal of Affective Disorders},
  volume = {296},
  pages = {622--634},
  issn = {0165-0327},
  doi = {10.1016/j.jad.2021.09.074},
  url = {https://www.sciencedirect.com/science/article/pii/S0165032721010338},
  urldate = {2023-11-01},
  abstract = {Rationale/importance Researches have highlighted communication deficits between resting-state brain networks in major depressive disorder (MDD), as reflected in abnormal functional connectivity (FC). However, it is unclear whether impaired FC is associated with MDD pathology or is simply incidental to MDD symptoms. Moreover, there is no generalized theory to analyze the impact of treatment modalities on MDD. Objectives To address the issues, we conducted a systematic review of 49 eligible papers to provide insight into the pathological mechanisms of MDD patients by summarizing resting-state FC alterations involving mood and cognitive abnormalities and the effects of medications on them. Results Mood disorders in MDD were characterized by abnormal FC between the amygdala, insula, anterior cingulate cortex (ACC), and prefrontal cortex (PFC). Cognitive impairment manifests as deficits in executive function, attention, memory, and rumination, primarily modulated by dysfunction between the fronto-parietal network and default mode network. Especially, we proposed the set of core abnormal FC (CA-FC) contributing to mood and cognitive impairment in MDD, currently including ACC-left precuneus/amygdala, rostral ACC-left dorsolateral PFC, left subgenual ACC-left cerebellar, left PFC- anterior subcallosal, and left precuneus-left pulvinar. After treatment, patients with normalized CA-FC showed remission of depressive symptoms. Conclusions We propose a CA-FC set for possible causative principle of MDD, which unifies the FC results from specific, difficult-to-analyze conditions into one outcome set for screening. Furthermore, CA-FC varies from person to person, and the low success rate of a single treatment may be due to the inability to cover too many CA-FC.},
  keywords = {CA-FC,MDD,Mood and cognitive,Resting-state FC,Treatment}
}

@article{lopesdasilvaEEGMEGRelevance2013,
  title = {{{EEG}} and {{MEG}}: {{Relevance}} to {{Neuroscience}}},
  shorttitle = {{{EEG}} and {{MEG}}},
  author = {Lopes~da~Silva, Fernando},
  date = {2013-12},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {80},
  number = {5},
  pages = {1112--1128},
  issn = {08966273},
  doi = {10.1016/j.neuron.2013.10.017},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627313009203},
  urldate = {2023-12-08},
  langid = {english},
  keywords = {EEG,MEG,Review},
  file = {D:\Zotero Storage\Zotero\storage\6T25NVQF\Lopes da Silva - 2013 - EEG and MEG Relevance to Neuroscience.pdf}
}

@online{luoMappingWholebrainEffective2023,
  title = {Mapping the Whole-Brain Effective Connectome with Excitatory-Inhibitory Causal Relationship},
  author = {Luo, Zixiang and Liang, Zhichao and Xu, Chenyu and Zhou, Changsong and Liu, Quanying},
  date = {2023-03-21},
  eprint = {2301.00148},
  eprinttype = {arxiv},
  eprintclass = {q-bio},
  url = {http://arxiv.org/abs/2301.00148},
  urldate = {2023-08-18},
  abstract = {Understanding the large-scale causal relationship among brain regions is crucial for elucidating the information flow that the brain integrates external stimuli and generates behaviors. Despite the availability of neurostimulation and computational methods to infer causal relationships among a limited number of regions, these approaches are not capable of mapping the causal network of the entire brain, also known as the effective brain connectome (EBC). To address this gap, we propose a data-driven framework called Neural Perturbational Inference (NPI) and map the human EBC for the first time. NPI uses an artificial neural network trained to learn large-scale neural dynamics as a surrogate brain. By perturbing each region of the surrogate brain and observing the resulting responses in all other regions, the human EBC is obtained. This connectome captures the directionality, strength, and excitatory-inhibitory distinction of brain-wide causal relationships, offering mechanistic insights into cognitive processes. EBC provides a complete picture of information flow both within and across brain functional networks as well as reveals the large-scale hierarchy of the organization of excitatory and inhibitory ECs. As EBC captures the neurostimulation transmission pathways in the brain, it has great potential to guide the target selection in personalized neurostimulation of neurological disorders.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {D:\Zotero Storage\Zotero\storage\M39T4GRL\Luo et al. - 2023 - Mapping the whole-brain effective connectome with .pdf}
}

@article{maravallMoreSumIts2018,
  title = {More than the {{Sum}} of Its {{Parts}}: {{Perception}} and {{Neuronal Underpinnings}} of {{Sequence Processing}}},
  author = {Maravall, M. and Ostojic, S. and Pressnitzer, D. and Chait, M.},
  date = {2018-10-01},
  journaltitle = {Neuroscience},
  volume = {389},
  pages = {1--3},
  issn = {1873-7544 (Electronic) 0306-4522 (Linking)},
  doi = {10.1016/j.neuroscience.2018.07.043},
  keywords = {Animals,Humans,Neurons/*physiology,Perception/*physiology,Time Factors}
}

@article{mastrogiuseppeLinkingConnectivityDynamics2018,
  title = {Linking {{Connectivity}}, {{Dynamics}}, and {{Computations}} in {{Low-Rank Recurrent Neural Networks}}},
  author = {Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  date = {2018-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {99},
  number = {3},
  pages = {609-623.e29},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.07.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627318305439},
  urldate = {2023-09-07},
  abstract = {Large-scale neural recordings have established that the transformation of sensory stimuli into motor outputs relies on low-dimensional dynamics at the population level, while individual neurons exhibit complex selectivity. Understanding how low-dimensional computations on mixed, distributed representations emerge from the structure of the recurrent connectivity and inputs to cortical networks is a major challenge. Here, we study a class of recurrent network models in which the connectivity is a sum of a random part and a minimal, low-dimensional structure. We show that, in such networks, the dynamics are low dimensional and can be directly inferred from connectivity using a geometrical approach. We exploit this understanding to determine minimal connectivity required to implement specific computations and find that the dynamical range and computational capacity quickly increase with the dimensionality of the connectivity structure. This framework produces testable experimental predictions for the relationship between connectivity, low-dimensional dynamics, and computational features of recorded neurons.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@mastrogiuseppeLinkingConnectivityDynamics2018.md;D\:\\Zotero Storage\\Zotero\\storage\\ZPBAZPJ6\\Mastrogiuseppe and Ostojic - 2018 - Linking Connectivity, Dynamics, and Computations i.pdf}
}

@article{mastrogiuseppeLinkingConnectivityDynamics2018a,
  title = {Linking {{Connectivity}}, {{Dynamics}}, and {{Computations}} in {{Low-Rank Recurrent Neural Networks}}},
  author = {Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  date = {2018-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {99},
  number = {3},
  pages = {609-623.e29},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.07.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627318305439},
  urldate = {2023-09-12},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\A7TUUDIF\Mastrogiuseppe and Ostojic - 2018 - Linking Connectivity, Dynamics, and Computations i.pdf}
}

@article{mastrogiuseppeLinkingConnectivityDynamics2018b,
  title = {Linking {{Connectivity}}, {{Dynamics}}, and {{Computations}} in {{Low-Rank Recurrent Neural Networks}}},
  author = {Mastrogiuseppe, Francesca and Ostojic, Srdjan},
  date = {2018-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {99},
  number = {3},
  pages = {609-623.e29},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.07.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627318305439},
  urldate = {2023-09-12},
  abstract = {Large-scale neural recordings have established that the transformation of sensory stimuli into motor outputs relies on low-dimensional dynamics at the population level, while individual neurons exhibit complex selectivity. Understanding how low-dimensional computations on mixed, distributed representations emerge from the structure of the recurrent connectivity and inputs to cortical networks is a major challenge. Here, we study a class of recurrent network models in which the connectivity is a sum of a random part and a minimal, low-dimensional structure. We show that, in such networks, the dynamics are low dimensional and can be directly inferred from connectivity using a geometrical approach. We exploit this understanding to determine minimal connectivity required to implement specific computations and find that the dynamical range and computational capacity quickly increase with the dimensionality of the connectivity structure. This framework produces testable experimental predictions for the relationship between connectivity, low-dimensional dynamics, and computational features of recorded neurons.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\F4FYBYKF\Mastrogiuseppe and Ostojic - 2018 - Linking Connectivity, Dynamics, and Computations i.pdf}
}

@article{mattarPrioritizedMemoryAccess2018,
  title = {Prioritized Memory Access Explains Planning and Hippocampal Replay},
  author = {Mattar, M. G. and Daw, N. D.},
  date = {2018-11},
  journaltitle = {Nat Neurosci},
  volume = {21},
  number = {11},
  pages = {1609--1617},
  issn = {1546-1726 (Electronic) 1097-6256 (Linking)},
  doi = {10.1038/s41593-018-0232-z},
  abstract = {To make decisions, animals must evaluate candidate choices by accessing memories of relevant experiences. Yet little is known about which experiences are considered or ignored during deliberation, which ultimately governs choice. We propose a normative theory predicting which memories should be accessed at each moment to optimize future decisions. Using nonlocal 'replay' of spatial locations in hippocampus as a window into memory access, we simulate a spatial navigation task in which an agent accesses memories of locations sequentially, ordered by utility: how much extra reward would be earned due to better choices. This prioritization balances two desiderata: the need to evaluate imminent choices versus the gain from propagating newly encountered information to preceding locations. Our theory offers a simple explanation for numerous findings about place cells; unifies seemingly disparate proposed functions of replay including planning, learning, and consolidation; and posits a mechanism whose dysfunction may underlie pathologies like rumination and craving.},
  pmcid = {PMC6203620},
  keywords = {Animals,{Behavior, Animal/*physiology},Decision Making/*physiology,Hippocampus/*physiology,Memory/*physiology,Neurons/physiology,Rats,Reward,Spatial Navigation/*physiology}
}

@article{maukNeuralBasisTemporal2004,
  title = {The Neural Basis of Temporal Processing},
  author = {Mauk, M. D. and Buonomano, D. V.},
  date = {2004},
  journaltitle = {Annu Rev Neurosci},
  volume = {27},
  pages = {307--40},
  issn = {0147-006X (Print) 0147-006X (Linking)},
  doi = {10.1146/annurev.neuro.27.070203.144247},
  abstract = {A complete understanding of sensory and motor processing requires characterization of how the nervous system processes time in the range of tens to hundreds of milliseconds (ms). Temporal processing on this scale is required for simple sensory problems, such as interval, duration, and motion discrimination, as well as complex forms of sensory processing, such as speech recognition. Timing is also required for a wide range of motor tasks from eyelid conditioning to playing the piano. Here we review the behavioral, electrophysiological, and theoretical literature on the neural basis of temporal processing. These data suggest that temporal processing is likely to be distributed among different structures, rather than relying on a centralized timing area, as has been suggested in internal clock models. We also discuss whether temporal processing relies on specialized neural mechanisms, which perform temporal computations independent of spatial ones. We suggest that, given the intricate link between temporal and spatial information in most sensory and motor tasks, timing and spatial processing are intrinsic properties of neural function, and specialized timing mechanisms such as delay lines, oscillators, or a spectrum of different time constants are not required. Rather temporal processing may rely on state-dependent changes in network dynamics.},
  keywords = {Animals,Biological Clocks/physiology,Brain/anatomy \& histology/*physiology,Humans,{Models, Neurological},Motor Skills/physiology,Nerve Net/anatomy \& histology/*physiology,Neural Pathways/anatomy \& histology/*physiology,Perception/physiology,Space Perception/physiology,Time Perception/*physiology}
}

@article{maybergDeepBrainStimulation2005,
  title = {Deep {{Brain Stimulation}} for {{Treatment-Resistant Depression}}},
  author = {Mayberg, Helen S. and Lozano, Andres M. and Voon, Valerie and McNeely, Heather E. and Seminowicz, David and Hamani, Clement and Schwalb, Jason M. and Kennedy, Sidney H.},
  date = {2005-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {45},
  number = {5},
  pages = {651--660},
  issn = {08966273},
  doi = {10.1016/j.neuron.2005.02.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S089662730500156X},
  urldate = {2023-09-20},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@maybergDeepBrainStimulation2005.md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\maybergDeepBrainStimulation2005 - Annotations (9212023, 43349 PM).md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\maybergDeepBrainStimulation2005-zotero.md;D\:\\Zotero Storage\\Zotero\\storage\\BINLIE3X\\Mayberg et al. - 2005 - Deep Brain Stimulation for Treatment-Resistant Dep.pdf}
}

@article{meadNeuromorphicElectronicSystems1990,
  title = {Neuromorphic Electronic Systems},
  author = {Mead, C.},
  date = {1990-10},
  journaltitle = {Proceedings of the IEEE},
  volume = {78},
  number = {10},
  pages = {1629--1636},
  issn = {1558-2256},
  doi = {10.1109/5.58356},
  url = {https://ieeexplore.ieee.org/document/58356},
  urldate = {2023-10-25},
  abstract = {It is shown that for many problems, particularly those in which the input data are ill-conditioned and the computation can be specified in a relative manner, biological solutions are many orders of magnitude more effective than those using digital methods. This advantage can be attributed principally to the use of elementary physical phenomena as computational primitives, and to the representation of information by the relative values of analog signals rather than by the absolute values of digital signals. This approach requires adaptive techniques to mitigate the effects of component differences. This kind of adaptation leads naturally to systems that learn about their environment. Large-scale adaptive analog systems are more robust to component degradation and failure than are more conventional systems, and they use far less power. For this reason, adaptive analog technology can be expected to utilize the full potential of wafer-scale silicon fabrication.{$<>$}},
  eventtitle = {Proceedings of the {{IEEE}}},
  file = {D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Proceedings of the IEEE1990MeadNeuromorphic electronic systemsProceedings of the IEEE78101629-1636CompNeuro_Literature\\UnreadMeadCCM期刊文章\\1990_-Neuromorphic electronic systems.pdf;D\:\\Zotero Storage\\Zotero\\storage\\VILZZ6IY\\58356.html}
}

@article{mendoza-ruizDynamicsCorticalActivity2020,
  title = {Dynamics in Cortical Activity Revealed by Resting-State {{MEG}} Rhythms},
  author = {Mendoza-Ruiz, J. and Alonso-Malaver, C. E. and Valderrama, M. and Rosso, O. A. and Martinez, J. H.},
  date = {2020-12-01},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume = {30},
  number = {12},
  pages = {123138},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0025189},
  url = {https://pubs.aip.org/cha/article/30/12/123138/282774/Dynamics-in-cortical-activity-revealed-by-resting},
  urldate = {2023-12-08},
  abstract = {The brain is a biophysical system subject to information flows that may be thought of as a many-body architecture with a spatiotemporal dynamics described by its neuronal structures. The oscillatory nature of brain activity allows these structures (nodes) to be described as a set of coupled oscillators forming a network where the node dynamics and that of the network topology can be studied. Quantifying its dynamics at various scales is an issue that claims to be explored for several brain activities, e.g., activity at rest. The resting-state (RS) associates the underlying brain dynamics of healthy subjects that are not actively compromised with sensory or cognitive processes. Studying its dynamics is highly non-trivial but opens the door to understand the general principles of brain functioning, as well as to contrast a passive null condition vs the dynamics of pathologies or non-resting activities. Here, we hypothesize about how the spatiotemporal dynamics of cortical fluctuations could be for healthy subjects at RS. To do that, we retrieve the alphabet that reconstructs the dynamics (entropy–complexity) of magnetoencephalography (MEG) signals. We assemble the cortical connectivity to elicit the dynamics in the network topology. We depict an order relation between entropy and complexity for frequency bands that is ubiquitous for different temporal scales. We unveiled that the posterior cortex conglomerates nodes with both stronger dynamics and high clustering for α band. The existence of an order relation between dynamic properties suggests an emergent phenomenon characteristic of each band. Interestingly, we find the posterior cortex as a domain of dual character that plays a cardinal role in both the dynamics and structure regarding the activity at rest. To the best of our knowledge, this is the first study with MEG involving information theory and network science to better understand the dynamics and structure of brain activity at rest for different bands and scales.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\9ZXDDYV5\Mendoza-Ruiz 等 - 2020 - Dynamics in cortical activity revealed by resting-.pdf}
}

@article{metzgerHighperformanceNeuroprosthesisSpeech2023,
  title = {A High-Performance Neuroprosthesis for Speech Decoding and Avatar Control},
  author = {Metzger, Sean L. and Littlejohn, Kaylo T. and Silva, Alexander B. and Moses, David A. and Seaton, Margaret P. and Wang, Ran and Dougherty, Maximilian E. and Liu, Jessie R. and Wu, Peter and Berger, Michael A. and Zhuravleva, Inga and Tu-Chan, Adelyn and Ganguly, Karunesh and Anumanchipalli, Gopala K. and Chang, Edward F.},
  date = {2023-08},
  journaltitle = {Nature},
  volume = {620},
  number = {7976},
  pages = {1037--1046},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06443-4},
  url = {https://www.nature.com/articles/s41586-023-06443-4},
  urldate = {2023-08-31},
  abstract = {Speech neuroprostheses have the potential to restore communication to people living with paralysis, but naturalistic speed and expressivity are elusive1. Here we use high-density surface recordings of the speech cortex in a clinical-trial participant with severe limb and vocal paralysis to achieve high-performance real-time decoding across three complementary speech-related output modalities: text, speech audio and facial-avatar animation. We trained and evaluated deep-learning models using neural data collected as the participant attempted to silently speak sentences. For text, we demonstrate accurate and rapid large-vocabulary decoding with a median rate of 78 words per minute and median word error rate of 25\%. For speech audio, we demonstrate intelligible and rapid speech synthesis and~personalization~to the participant’s pre-injury voice. For facial-avatar animation, we demonstrate the control of virtual orofacial movements for speech and non-speech communicative gestures. The decoders reached high performance with less than two weeks of training. Our findings introduce a multimodal speech-neuroprosthetic approach that has substantial promise to restore full, embodied communication to people living with severe paralysis.},
  issue = {7976},
  langid = {english},
  keywords = {Brain–machine interface,Electrical and electronic engineering,Motor cortex,Neurophysiology,Stroke}
}

@book{millerIntroductoryCourseComputational2018,
  title = {An Introductory Course in Computational Neuroscience},
  author = {Miller, Paul},
  date = {2018},
  series = {Computational Neuroscience},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Masachusetts}},
  isbn = {978-0-262-03825-6},
  langid = {english},
  pagetotal = {383},
  keywords = {Computational neuroscience,Mathematics,Neurosciences,Textbooks},
  file = {D:\Zotero Storage\Zotero\storage\J2XE66CW\Miller - 2018 - An introductory course in computational neuroscien.pdf}
}

@article{milneOnlineHeadphoneScreening2021,
  title = {An Online Headphone Screening Test Based on Dichotic Pitch},
  author = {Milne, A. E. and Bianco, R. and Poole, K. C. and Zhao, S. and Oxenham, A. J. and Billig, A. J. and Chait, M.},
  date = {2021-08},
  journaltitle = {Behav Res Methods},
  volume = {53},
  number = {4},
  pages = {1551--1562},
  issn = {1554-3528 (Electronic) 1554-351X (Print) 1554-351X (Linking)},
  doi = {10.3758/s13428-020-01514-0},
  abstract = {Online experimental platforms can be used as an alternative to, or complement, lab-based research. However, when conducting auditory experiments via online methods, the researcher has limited control over the participants' listening environment. We offer a new method to probe one aspect of that environment, headphone use. Headphones not only provide better control of sound presentation but can also "shield" the listener from background noise. Here we present a rapid ({$<$} 3 min) headphone screening test based on Huggins Pitch (HP), a perceptual phenomenon that can only be detected when stimuli are presented dichotically. We validate this test using a cohort of "Trusted" online participants who completed the test using both headphones and loudspeakers. The same participants were also used to test an existing headphone test (AP test; Woods et al., 2017, Attention Perception Psychophysics). We demonstrate that compared to the AP test, the HP test has a higher selectivity for headphone users, rendering it as a compelling alternative to existing methods. Overall, the new HP test correctly detects 80\% of headphone users and has a false-positive rate of 20\%. Moreover, we demonstrate that combining the HP test with an additional test-either the AP test or an alternative based on a beat test (BT)-can lower the false-positive rate to \textasciitilde{} 7\%. This should be useful in situations where headphone use is particularly critical (e.g., dichotic or spatial manipulations). Code for implementing the new tests is publicly available in JavaScript and through Gorilla (gorilla.sc).},
  pmcid = {PMC7725427},
  keywords = {*Auditory Perception,*Noise,Acoustic Stimulation,Audition,Auditory online experiments,Crowd-sourcing,Humans,Psychophysics,Sound,Web-based testing}
}

@article{mitraTargetedNeurostimulationReverses2023,
  title = {Targeted Neurostimulation Reverses a Spatiotemporal Biomarker of Treatment-Resistant Depression},
  author = {Mitra, Anish and Raichle, Marcus E. and Geoly, Andrew D. and Kratter, Ian H. and Williams, Nolan R.},
  date = {2023-05-23},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {120},
  number = {21},
  eprint = {37186863},
  eprinttype = {pmid},
  pages = {e2218958120},
  issn = {1091-6490},
  doi = {10.1073/pnas.2218958120},
  abstract = {Major depressive disorder (MDD) is widely hypothesized to result from disordered communication across brain-wide networks. Yet, prior resting-state-functional MRI (rs-fMRI) studies of MDD have studied zero-lag temporal synchrony (functional connectivity) in brain activity absent directional information. We utilize the recent discovery of stereotyped brain-wide directed signaling patterns in humans to investigate the relationship between directed rs-fMRI activity, MDD, and treatment response to FDA-approved neurostimulation paradigm termed Stanford neuromodulation therapy (SNT). We find that SNT over the left dorsolateral prefrontal cortex (DLPFC) induces directed signaling shifts in the left DLPFC and bilateral anterior cingulate cortex (ACC). Directional signaling shifts in the ACC, but not the DLPFC, predict improvement in depression symptoms, and moreover, pretreatment ACC signaling predicts both depression severity and the likelihood of SNT treatment response. Taken together, our findings suggest that ACC-based directed signaling patterns in rs-fMRI are a potential biomarker of MDD.},
  langid = {english},
  pmcid = {PMC10214160},
  keywords = {Brain,brain stimulation,depression,Depression,{Depressive Disorder, Major},functional MRI,Gyrus Cinguli,Humans,Magnetic Resonance Imaging,Prefrontal Cortex},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@mitraTargetedNeurostimulationReverses2023.md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\mitraTargetedNeurostimulationReverses2023-zotero.md;D\:\\Zotero Storage\\Zotero\\storage\\R7Q665J4\\Mitra et al. - 2023 - Targeted neurostimulation reverses a spatiotempora.pdf}
}

@article{miyazawaEffectTryptophanAdministration1975,
  title = {The Effect of Tryptophan Administration on Fatty Acid Synthesis in the Livers of Rats under Various Nutritional Conditions},
  author = {Miyazawa, S. and Sakurai, T. and Shindo, Y. and Imura, M. and Hashimoto, T.},
  date = {1975-07},
  journaltitle = {Journal of Biochemistry},
  shortjournal = {J Biochem},
  volume = {78},
  number = {1},
  eprint = {375},
  eprinttype = {pmid},
  pages = {139--147},
  issn = {0021-924X},
  abstract = {1. Tryptophan was administered to rats under various nutritional conditions: fasted for 24 hr, fasted and refed with glucose or corn-oil, fasted and administered glycerol intramuscularly, and nonfasted. 2. The changes in the contents of glycolytic intermediates in the livers indicated that the phosphoenolpyruvate carboxykinase [EC 4.1.1.32] reaction is inhibited by tryptophan administration in all groups of rats. The inversely related changes in the contents of malate and phosphoenolpyruvate were associated with the accumulation of quinolinate in the livers. The content of quinolinate which exhibited the half-maximal effect on the contents of both metabolites was 0.1-0.2 mumole per g liver. 3. The rate of incorporation of 3H from 3H2O into the total hepatic fatty acids was increased about 2-fold by the administration of this amino acid to the fasted rats. The enhancement of the rate was closely related to the increase in the citrate content. The hyperlipogenesis was also related to the decrease of acetyl-CoA and the increase of malonyl-CoA. The content of long-chain acyl-CoA was not affected. These effects of tryptophan administration on the hepatic fatty acid metabolism were found in all groups of rats. The liver content of glycerol 3-phosphate was decreased by tryptophan administration was markedly increased by glycerol injection. The injection of glycerol into the control and the tryptophan-treated rats produced a marked increase of glycerol 3-phosphate but did not affect the rate of fatty acid synthesis in the livers of either group. 4. It may be concluded that, in the livers of rats under various nutritional conditions, the short-term control of fatty acid synthesis by tryptophan administration is most likely due to the activation of acetyl-coenzyme A carboxylase [EC 6.4.1.2] by citrate.},
  langid = {english},
  keywords = {Acetyl Coenzyme A,Acetyl-CoA Carboxylase,Animals,Carbohydrate Metabolism,Citrates,Enzyme Activation,Fasting,Fatty Acids,Fructosephosphates,Gluconeogenesis,Glycerol,Glycerophosphates,Ketone Bodies,Lactates,Liver,Malates,Male,Malonates,Phosphoenolpyruvate Carboxykinase (GTP),Quinolinic Acids,Rats,Tryptophan}
}

@book{MonteCarloStrategiesinScientific,
  title = {Monte-{{Carlo-Strategies-in-Scientific}}},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\Monte-Carlo-Strategies-in-ScientificBooks图书\-Monte-Carlo-Strategies-in-Scientific.pdf}
}

@article{mudarEventrelatedNeuralOscillation2019,
  title = {Event-Related Neural Oscillation Changes Following Reasoning Training in Individuals with {{Mild Cognitive Impairment}}},
  author = {Mudar, R. A. and Nguyen, L. T. and Eroh, J. and Chiang, H. S. and Rackley, A. and Chapman, S. B.},
  date = {2019-02-01},
  journaltitle = {Brain Res},
  volume = {1704},
  pages = {229--240},
  issn = {1872-6240 (Electronic) 0006-8993 (Linking)},
  doi = {10.1016/j.brainres.2018.10.017},
  abstract = {Emerging evidence suggests cognitive training programs targeting higher-order reasoning may strengthen not only cognitive, but also neural functions in individuals with Mild Cognitive Impairment (MCI). However, research on direct measures of training-induced neural changes, derivable from electroencephalography (EEG), is limited. The current pilot study examined effects of Gist Reasoning training (n=16) compared to New Learning training (n=16) in older adults with amnestic MCI on measures of event-related neural oscillations (theta and alpha band power) corresponding to Go/NoGo tasks during basic and superordinate semantic categorization. EEG data were recorded while participants performed the Go/NoGo task pre- and post-training, and power in theta and alpha frequency bands was examined. Both groups were comparable at pre-training on all measures and both groups showed greater event-related theta synchronization post-training. Furthermore, the Gist Reasoning group had enhanced event-related desynchronization in low-frequency alpha band (8-10Hz) on response inhibition (NoGo) trials and high-frequency alpha band (11-13Hz) on response execution (Go) trials during superordinate categorization, relative to the New Learning group. These findings suggest that Gist Reasoning training in MCI impacted neural processing linked to strategic processing of Go and NoGo trials during the more complex superordinate categorization task. Targeting higher-order top-down cognitive processing seems to better harness residual neuroplastic potential in MCI. ClinicalTrials.gov ID: NCT02588209.},
  keywords = {*Alpha,*Cognitive training,*eeg,*Go/NoGo,*Mild Cognitive Impairment,*Theta,Aged,{Aged, 80 and over},Brain/*physiopathology,Cognition/*physiology,Cognitive Dysfunction/*physiopathology/psychology,Electroencephalography,Evoked Potentials/*physiology,Female,Humans,Male,Middle Aged,Neuropsychological Tests,Pilot Projects,Problem Solving/*physiology,Reaction Time/physiology}
}

@article{mullerContinualLearningMultiLayer2019,
  title = {Continual {{Learning}} in a {{Multi-Layer Network}} of an {{Electric Fish}}},
  author = {Muller, Salomon Z. and Zadina, Abigail N. and Abbott, L.F. and Sawtell, Nathaniel B.},
  date = {2019-11},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {179},
  number = {6},
  pages = {1382-1392.e10},
  issn = {00928674},
  doi = {10.1016/j.cell.2019.10.020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0092867419311705},
  urldate = {2023-10-05},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Continual Learning\\mullerContinualLearningMultiLayer2019.md;D\:\\Zotero Storage\\Zotero\\storage\\MSYXJLRE\\Muller 等 - 2019 - Continual Learning in a Multi-Layer Network of an .pdf}
}

@article{NaoCiTu,
  title = {脑磁图},
  file = {D:\Zotero Storage\Zotero\storage\IJXZP82J\脑磁图仪的前世今生与未来.pdf}
}

@article{nicolaSupervisedLearningSpiking2017,
  title = {Supervised Learning in Spiking Neural Networks with {{FORCE}} Training},
  author = {Nicola, Wilten and Clopath, Claudia},
  date = {2017-12-20},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {2208},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-01827-3},
  url = {https://www.nature.com/articles/s41467-017-01827-3},
  urldate = {2023-08-20},
  abstract = {Abstract             Populations of neurons display an extraordinary diversity in the behaviors they affect and display. Machine learning techniques have recently emerged that allow us to create networks of model neurons that display behaviors of similar complexity. Here we demonstrate the direct applicability of one such technique, the FORCE method, to spiking neural networks. We train these networks to mimic dynamical systems, classify inputs, and store discrete sequences that correspond to the notes of a song. Finally, we use FORCE training to create two biologically motivated model circuits. One is inspired by the zebra finch and successfully reproduces songbird singing. The second network is motivated by the hippocampus and is trained to store and replay a movie scene. FORCE trained networks reproduce behaviors comparable in complexity to their inspired circuits and yield information not easily obtainable with other techniques, such as behavioral responses to pharmacological manipulations and spike timing statistics.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\29TYSTXB\\Nicola and Clopath - 2017 - Supervised learning in spiking neural networks wit.pdf;D\:\\Zotero Storage\\Zotero\\storage\\LNMQ4JYM\\nicola2017.pdf.pdf}
}

@article{nicolaSupervisedLearningSpiking2017a,
  title = {Supervised Learning in Spiking Neural Networks with {{FORCE}} Training},
  author = {Nicola, Wilten and Clopath, Claudia},
  date = {2017-12-20},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {2208},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-01827-3},
  url = {https://www.nature.com/articles/s41467-017-01827-3},
  urldate = {2023-08-20},
  abstract = {Populations of neurons display an extraordinary diversity in the behaviors they affect and display. Machine learning techniques have recently emerged that allow us to create networks of model neurons that display behaviors of similar complexity. Here we demonstrate the direct applicability of one such technique, the FORCE method, to spiking neural networks. We train these networks to mimic dynamical systems, classify inputs, and store discrete sequences that correspond to the notes of a song. Finally, we use FORCE training to create two biologically motivated model circuits. One is inspired by the zebra finch and successfully reproduces songbird singing. The second network is motivated by the hippocampus and is trained to store and replay a movie scene. FORCE trained networks reproduce behaviors comparable in complexity to their inspired circuits and yield information not easily obtainable with other techniques, such as behavioral responses to pharmacological manipulations and spike timing statistics.},
  issue = {1},
  langid = {english},
  keywords = {Dynamical systems,Learning algorithms,Network models,Neural encoding},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@nicolaSupervisedLearningSpiking2017a.md;D\:\\Zotero Storage\\Zotero\\storage\\K44PJ5IU\\Nicola and Clopath - 2017 - Supervised learning in spiking neural networks wit.pdf;D\:\\Zotero Storage\\Zotero\\storage\\MHSRVS5J\\nicola2017.pdf.pdf}
}

@article{nigburThetaPowerMarker2011,
  title = {Theta Power as a Marker for Cognitive Interference},
  author = {Nigbur, R. and Ivanova, G. and Sturmer, B.},
  date = {2011-11},
  journaltitle = {Clin Neurophysiol},
  volume = {122},
  number = {11},
  pages = {2185--94},
  issn = {1872-8952 (Electronic) 1388-2457 (Linking)},
  doi = {10.1016/j.clinph.2011.03.030},
  abstract = {OBJECTIVE: The present study aimed at investigating whether theta activity within medio-frontal cortex (MFC) serves as a marker for increased cognitive control demands such as performance monitoring. METHODS: We confronted participants with at least two incompatible sources of information in a Simon task, a flanker task, and a NoGo task to assess whether changes in EEG theta activity correspond to executive control demands across different sources of cognitive interference. RESULTS: Overall, increases of theta power were to a different extent observed in all interference situations: (1) differences in theta power were largest between successful response inhibition in NoGo events compared to Go responses, (2) incongruent and congruent events in the flanker task differed to a lesser extent, and (3) differences in theta power were smallest comparing incompatible and compatible Simon events. Scalp-topographies and dipole modeling of theta activity pointed to different sources across interference conditions that encompassed various MFC areas within anterior cingulate cortex and (pre-) supplementary motor areas. CONCLUSIONS: Our results indicate that theta power amplitude is sensitive to the recruitment of executive control in interference situations, whereas the MFC sources of theta power varied across different interference situations. SIGNIFICANCE: This study shows for the first time theta power enhancement related to the recruitment of cognitive control across different types of conflicts in the stream of information processing.},
  keywords = {{*Conflict, Psychological},Adult,Biomarkers,Cognition/*physiology,Electroencephalography/methods,Executive Function/*physiology,Female,Frontal Lobe/physiology,Humans,Male,Mental Processes/physiology,Perceptual Masking/physiology,{Signal Processing, Computer-Assisted},Theta Rhythm/*physiology,Young Adult}
}

@article{niGeneralDecodingStrategy2022,
  title = {A General Decoding Strategy Explains the Relationship between Behavior and Correlated Variability},
  author = {Ni, A. M. and Huang, C. and Doiron, B. and Cohen, M. R.},
  date = {2022-06-06},
  journaltitle = {Elife},
  volume = {11},
  issn = {2050-084X (Electronic) 2050-084X (Linking)},
  doi = {10.7554/eLife.67258},
  abstract = {Improvements in perception are frequently accompanied by decreases in correlated variability in sensory cortex. This relationship is puzzling because overall changes in correlated variability should minimally affect optimal information coding. We hypothesize that this relationship arises because instead of using optimal strategies for decoding the specific stimuli at hand, observers prioritize generality: a single set of neuronal weights to decode any stimuli. We tested this using a combination of multineuron recordings in the visual cortex of behaving rhesus monkeys and a cortical circuit model. We found that general decoders optimized for broad rather than narrow sets of visual stimuli better matched the animals' decoding strategy, and that their performance was more related to the magnitude of correlated variability. In conclusion, the inverse relationship between perceptual performance and correlated variability can be explained by observers using a general decoding strategy, capable of decoding neuronal responses to the variety of stimuli encountered in natural vision.},
  pmcid = {PMC9170243},
  keywords = {*neural coding,*neuroscience,*noise correlations,*perception,*rhesus macaque,*visual attention,*Visual Cortex/physiology,Animals,Macaca mulatta,Neurons/physiology,Photic Stimulation,Visual Perception}
}

@online{NonlinearDynamicsComputational,
  title = {Nonlinear {{Dynamics}} in {{Computational Neuroscience}} | {{SpringerLink}}},
  url = {https://link.springer.com/book/10.1007/978-3-319-71048-8},
  urldate = {2023-10-16},
  file = {D:\Zotero Storage\Zotero\storage\Y6LTWDEL\978-3-319-71048-8.html}
}

@article{normanMindreadingMultivoxelPattern2006,
  title = {Beyond Mind-Reading: Multi-Voxel Pattern Analysis of {{fMRI}} Data},
  author = {Norman, Kenneth A. and Polyn, Sean M. and Detre, Greg J. and family=Haxby, given=James V. \%J Trends, prefix=in cognitive sciences, useprefix=false},
  date = {2006},
  volume = {10},
  number = {9},
  pages = {424--430},
  issn = {1364-6613}
}

@article{nyhusIncreasesThetaOscillatory2019,
  title = {Increases in {{Theta Oscillatory Activity During Episodic Memory Retrieval Following Mindfulness Meditation Training}}},
  author = {Nyhus, E. and Engel, W. A. and Pitfield, T. D. and Vakkur, I. M. W.},
  date = {2019},
  journaltitle = {Front Hum Neurosci},
  volume = {13},
  pages = {311},
  issn = {1662-5161 (Print) 1662-5161 (Linking)},
  doi = {10.3389/fnhum.2019.00311},
  abstract = {Mindfulness meditation has been shown to improve episodic memory and increase theta oscillations which are known to play a role in episodic memory retrieval. The present study examined the effect of mindfulness meditation on episodic memory retrieval and theta oscillations. Using a longitudinal design, subjects in the mindfulness meditation experimental group who underwent 4 weeks of mindfulness meditation training and practice were compared to a waitlist control group. During the pre-training and post-training experimental sessions, subjects completed the Five Facet Mindfulness Questionnaire (FFMQ) and studied adjectives and either imagined a scene (Place Task) or judged its pleasantness (Pleasant Task). During the recognition test, subjects decided which task was performed with each word ("Old Place Task" or "Old Pleasant Task") or "New." FFMQ scores and source discrimination were greater post-training than pre-training in the mindfulness meditation experimental group. Electroencephalography (EEG) results revealed that for the mindfulness meditation experimental group theta power was greater post-training than pre-training in right frontal and left parietal channels and changes in FFMQ scores correlated with changes in theta oscillations in right frontal channels (n = 20). The present results suggest that mindfulness meditation increases source memory retrieval and theta oscillations in a fronto-parietal network.},
  pmcid = {PMC6738165},
  keywords = {Eeg,episodic memory,memory retrieval,mindfulness meditation,theta oscillations}
}

@article{olsenArtificialIntelligenceThat2021,
  title = {An Artificial Intelligence That Increases Simulated Brain-Computer Interface Performance},
  author = {Olsen, S. and Zhang, J. and Liang, K. F. and Lam, M. and Riaz, U. and Kao, J. C.},
  date = {2021-05-13},
  journaltitle = {J Neural Eng},
  volume = {18},
  number = {4},
  issn = {1741-2552 (Electronic) 1741-2552 (Linking)},
  doi = {10.1088/1741-2552/abfaaa},
  abstract = {Objective.Brain-computer interfaces (BCIs) translate neural activity into control signals for assistive devices in order to help people with motor disabilities communicate effectively. In this work, we introduce a new BCI architecture that improves control of a BCI computer cursor to type on a virtual keyboard.Approach.Our BCI architecture incorporates an external artificial intelligence (AI) that beneficially augments the movement trajectories of the BCI. This AI-BCI leverages past user actions, at both long (100 s of seconds ago) and short (100 s of milliseconds ago) timescales, to modify the BCI's trajectories.Main results.We tested our AI-BCI in a closed-loop BCI simulator with nine human subjects performing a typing task. We demonstrate that our AI-BCI achieves: (1) categorically higher information communication rates, (2) quicker ballistic movements between targets, (3) improved precision control to 'dial in' on targets, and (4) more efficient movement trajectories. We further show that our AI-BCI increases performance across a wide control quality spectrum from poor to proficient control.Significance.This AI-BCI architecture, by increasing BCI performance across all key metrics evaluated, may increase the clinical viability of BCI systems.},
  keywords = {*artificial intelligence,*brain-computer interface,*Brain-Computer Interfaces,*brain-machine interface,*decoder,*motor cortex,*Self-Help Devices,*shared control,Artificial Intelligence,Computers,Electroencephalography,Humans,Movement,User-Computer Interface}
}

@article{ostojicComputationalRoleStructure,
  title = {The Computational Role of Structure in Neural Activity and Connectivity},
  author = {Ostojic, Srdjan and Fusi, Stefano},
  abstract = {One major challenge of neuroscience is finding interesting structures in a seemingly disorganized neural activity. Often these structures have computational implications that help to understand the functional role of a particular brain area. Here we outline a unified approach to characterize these structures by inspecting the representational geometry and the modularity properties of the recorded activity, and show that this approach can also reveal structures in connectivity. We start by setting up a general framework for determining geometry and modularity in activity and connectivity and relating these properties with computations performed by the network. We then use this framework to review the types of structure found in recent works on model networks performing three classes of computations.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@ostojicComputationalRoleStructure.md;D\:\\Zotero Storage\\Zotero\\storage\\CT658G2X\\Ostojic and Fusi - The computational role of structure in neural acti.pdf}
}

@article{parkerChoiceselectiveSequencesDominate2022,
  title = {Choice-Selective Sequences Dominate in Cortical Relative to Thalamic Inputs to {{NAc}} to Support Reinforcement Learning},
  author = {Parker, N. F. and Baidya, A. and Cox, J. and Haetzel, L. M. and Zhukovskaya, A. and Murugan, M. and Engelhard, B. and Goldman, M. S. and Witten, I. B.},
  date = {2022-05-17},
  journaltitle = {Cell Rep},
  volume = {39},
  number = {7},
  pages = {110756},
  issn = {2211-1247 (Electronic)},
  doi = {10.1016/j.celrep.2022.110756},
  abstract = {How are actions linked with subsequent outcomes to guide choices? The nucleus accumbens, which is implicated in this process, receives glutamatergic inputs from the prelimbic cortex and midline regions of the thalamus. However, little is known about whether and how representations differ across these input pathways. By comparing these inputs during a reinforcement learning task in mice, we discovered that prelimbic cortical inputs preferentially represent actions and choices, whereas midline thalamic inputs preferentially represent cues. Choice-selective activity in the prelimbic cortical inputs is organized in sequences that persist beyond the outcome. Through computational modeling, we demonstrate that these sequences can support the neural implementation of reinforcement-learning algorithms, in both a circuit model based on synaptic plasticity and one based on neural dynamics. Finally, we test and confirm a prediction of our circuit models by direct manipulation of nucleus accumbens input neurons.},
  pmcid = {PMC9218875},
  keywords = {*circuit modeling,*CP: Neuroscience,*imaging,*learning,*nucleus accumbens,*Nucleus Accumbens/physiology,*optogenetics,*prelimbic,*reinforcement learning,*thalamus,*Thalamus/physiology,Animals,Mice,Neural Pathways/physiology,Neurons/physiology,{Reinforcement, Psychology}}
}

@article{patonNeuralBasisTiming2018,
  title = {The {{Neural Basis}} of {{Timing}}: {{Distributed Mechanisms}} for {{Diverse Functions}}},
  author = {Paton, J. J. and Buonomano, D. V.},
  date = {2018-05-16},
  journaltitle = {Neuron},
  volume = {98},
  number = {4},
  pages = {687--705},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2018.03.045},
  abstract = {Timing is critical to most forms of learning, behavior, and sensory-motor processing. Converging evidence supports the notion that, precisely because of its importance across a wide range of brain functions, timing relies on intrinsic and general properties of neurons and neural circuits; that is, the brain uses its natural cellular and network dynamics to solve a diversity of temporal computations. Many circuits have been shown to encode elapsed time in dynamically changing patterns of neural activity-so-called population clocks. But temporal processing encompasses a wide range of different computations, and just as there are different circuits and mechanisms underlying computations about space, there are a multitude of circuits and mechanisms underlying the ability to tell time and generate temporal patterns.},
  pmcid = {PMC5962026},
  keywords = {*Time Perception,Animals,{Anticipation, Psychological},Behavior,Biological Clocks/*physiology,Brain,Cognition,Humans,Learning,{Models, Neurological},Neurons/*physiology,Time}
}

@article{pedersenComputationalPhenotypingBrainbehavior2021,
  title = {Computational Phenotyping of Brain-Behavior Dynamics Underlying Approach-Avoidance Conflict in Major Depressive Disorder},
  author = {Pedersen, Mads L. and Ironside, Maria and Amemori, Ken-ichi and McGrath, Callie L. and Kang, Min S. and Graybiel, Ann M. and Pizzagalli, Diego A. and Frank, Michael J.},
  year = {2021年5月10日},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {17},
  number = {5},
  pages = {e1008955},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008955},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008955},
  urldate = {2023-10-26},
  abstract = {Adaptive behavior requires balancing approach and avoidance based on the rewarding and aversive consequences of actions. Imbalances in this evaluation are thought to characterize mood disorders such as major depressive disorder (MDD). We present a novel application of the drift diffusion model (DDM) suited to quantify how offers of reward and aversiveness, and neural correlates thereof, are dynamically integrated to form decisions, and how such processes are altered in MDD. Hierarchical parameter estimation from the DDM demonstrated that the MDD group differed in three distinct reward-related parameters driving approach-based decision making. First, MDD was associated with reduced reward sensitivity, measured as the impact of offered reward on evidence accumulation. Notably, this effect was replicated in a follow-up study. Second, the MDD group showed lower starting point bias towards approaching offers. Third, this starting point was influenced in opposite directions by Pavlovian effects and by nucleus accumbens activity across the groups: greater accumbens activity was related to approach bias in controls but avoid bias in MDD. Cross-validation revealed that the combination of these computational biomarkers were diagnostic of patient status, with accumbens influences being particularly diagnostic. Finally, within the MDD group, reward sensitivity and nucleus accumbens parameters were differentially related to symptoms of perceived stress and depression. Collectively, these findings establish the promise of computational psychiatry approaches to dissecting approach-avoidance decision dynamics relevant for affective disorders.},
  langid = {english},
  keywords = {Behavior,Biomarkers,Caudate nucleus,Cognition,Decision making,Depression,Nucleus accumbens,Probability distribution},
  file = {D:\Zotero Storage\Zotero\storage\M55J6R7G\Pedersen 等 - 2021 - Computational phenotyping of brain-behavior dynami.pdf}
}

@article{pereraClinicalTMSSociety2016,
  title = {The {{Clinical TMS Society Consensus Review}} and {{Treatment Recommendations}} for {{TMS Therapy}} for {{Major Depressive Disorder}}},
  author = {Perera, Tarique and George, Mark S. and Grammer, Geoffrey and Janicak, Philip G. and Pascual-Leone, Alvaro and Wirecki, Theodore S.},
  date = {2016-05-01},
  journaltitle = {Brain Stimulation},
  shortjournal = {Brain Stimulation},
  volume = {9},
  number = {3},
  pages = {336--346},
  issn = {1935-861X},
  doi = {10.1016/j.brs.2016.03.010},
  url = {https://www.sciencedirect.com/science/article/pii/S1935861X16300389},
  urldate = {2023-09-04},
  abstract = {Background Prefrontal Transcranial Magnetic Stimulation (TMS) therapy repeated daily over 4–6 weeks (20–30 sessions) is US Food and Drug Administration (FDA) approved for treating Major Depressive Disorder in adults who have not responded to prior antidepressant medications. In 2011, leading TMS clinical providers and researchers created the Clinical TMS Society (cTMSs) (www.clinicaltmssociety.org, Greenwich, CT, USA), incorporated in 2013. Methods This consensus review was written by cTMSs leaders, informed by membership polls, and approved by the governing board. It summarizes current evidence for the safety and efficacy of the use of TMS therapy for treating depression in routine clinical practice. Authors systematically reviewed the published TMS antidepressant therapy clinical trials. Studies were then assessed and graded on their strength of evidence using the Levels of Evidence framework published by the University of Oxford Centre for Evidence Based Medicine. The authors then summarize essentials for using TMS therapy in routine clinical practice settings derived from discussions and polls of cTMSs members. Finally, each summary clinical recommendation is presented with the substantiating peer-reviewed, published evidence supporting that recommendation. When the current published clinical trial evidence was insufficient or incomplete, expert opinion was included when sufficient consensus was available from experienced clinician users among the membership of the cTMSs, who were polled at the Annual Meetings in 2014 and 2015. Conclusions Daily left prefrontal TMS has substantial evidence of efficacy and safety for treating the acute phase of depression in patients who are treatment resistant or intolerant. Following the clinical recommendations in this document should result in continued safe and effective use of this exciting new treatment modality.},
  keywords = {Depression,Guidelines,Review,TMS},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@pereraClinicalTMSSociety2016.md;D\:\\Zotero Storage\\Zotero\\storage\\P297EGRE\\Perera et al. - 2016 - The Clinical TMS Society Consensus Review and Trea.pdf;D\:\\Zotero Storage\\Zotero\\storage\\W2ULBN7K\\S1935861X16300389.html}
}

@article{piccininiFoundationsComputationalNeuroscience2014,
  title = {Foundations of Computational Neuroscience},
  author = {Piccinini, Gualtiero and Shagrir, Oron},
  date = {2014-04-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Theoretical and Computational Neuroscience},
  volume = {25},
  pages = {25--30},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2013.10.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438813002043},
  urldate = {2023-10-16},
  abstract = {Most computational neuroscientists assume that nervous systems compute and process information. We discuss foundational issues such as what we mean by ‘computation’ and ‘information processing’ in nervous systems; whether computation and information processing are matters of objective fact or of conventional, observer-dependent description; and how computational descriptions and explanations are related to other levels of analysis and organization.},
  file = {D:\Zotero Storage\Zotero\storage\SV9SIZXZ\S0959438813002043.html}
}

@article{pnevmatikakisSimultaneousDenoisingDeconvolution2016,
  title = {Simultaneous Denoising, Deconvolution, and Demixing of Calcium Imaging Data},
  author = {Pnevmatikakis, Eftychios A. and Soudry, Daniel and Gao, Yuanjun and Machado, Timothy A. and Merel, Josh and Pfau, David and Reardon, Thomas and Mu, Yu and Lacefield, Clay and Yang, Weijian \%J Neuron},
  date = {2016},
  volume = {89},
  number = {2},
  pages = {285--299},
  issn = {0896-6273}
}

@article{pouncyInductiveBiasesTheorybased2022,
  title = {Inductive Biases in Theory-Based Reinforcement Learning},
  author = {Pouncy, T. and Gershman, S. J.},
  date = {2022-11},
  journaltitle = {Cogn Psychol},
  volume = {138},
  pages = {101509},
  issn = {1095-5623 (Electronic) 0010-0285 (Linking)},
  doi = {10.1016/j.cogpsych.2022.101509},
  abstract = {Understanding the inductive biases that allow humans to learn in complex environments has been an important goal of cognitive science. Yet, while we have discovered much about human biases in specific learning domains, much of this research has focused on simple tasks that lack the complexity of the real world. In contrast, video games involving agents and objects embedded in richly structured systems provide an experimentally tractable proxy for real-world complexity. Recent work has suggested that key aspects of human learning in domains like video games can be captured by model-based reinforcement learning (RL) with object-oriented relational models-what we term theory-based RL. Restricting the model class in this way provides an inductive bias that dramatically increases learning efficiency, but in this paper we show that humans employ a stronger set of biases in addition to syntactic constraints on the structure of theories. In particular, we catalog a set of semantic biases that constrain the content of theories. Building these semantic biases into a theory-based RL system produces more human-like learning in video game environments.},
  keywords = {{*Reinforcement, Psychology},*Video Games,Ai,Bias,Cognitive science,Humans,Inductive bias,Learning,Psychology,Semantics}
}

@article{rajanEigenvalueSpectraRandom2006,
  title = {Eigenvalue {{Spectra}} of {{Random Matrices}} for {{Neural Networks}}},
  author = {Rajan, Kanaka and Abbott, L. F.},
  date = {2006-11-02},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {97},
  number = {18},
  pages = {188104},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.97.188104},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.97.188104},
  urldate = {2023-09-08},
  abstract = {The dynamics of neural networks is influenced strongly by the spectrum of eigenvalues of the matrix describing their synaptic connectivity. In large networks, elements of the synaptic connectivity matrix can be chosen randomly from appropriate distributions, making results from random matrix theory highly relevant. Unfortunately, classic results on the eigenvalue spectra of random matrices do not apply to synaptic connectivity matrices because of the constraint that individual neurons are either excitatory or inhibitory. Therefore, we compute eigenvalue spectra of large random matrices with excitatory and inhibitory columns drawn from distributions with different means and equal or different variances.},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@rajanEigenvalueSpectraRandom2006.md;D\:\\Zotero Storage\\Zotero\\storage\\E6HIE2M6\\Rajan and Abbott - 2006 - Eigenvalue Spectra of Random Matrices for Neural N.pdf;D\:\\Zotero Storage\\Zotero\\storage\\DUB6JMLW\\PhysRevLett.97.html}
}

@article{rajanStimulusdependentSuppressionChaos2010,
  title = {Stimulus-Dependent Suppression of Chaos in Recurrent Neural Networks},
  author = {Rajan, Kanaka and Abbott, L. F. and Sompolinsky, Haim},
  date = {2010-07-07},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {82},
  number = {1},
  pages = {011903},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.82.011903},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.82.011903},
  urldate = {2023-09-08},
  abstract = {Neuronal activity arises from an interaction between ongoing firing generated spontaneously by neural circuits and responses driven by external stimuli. Using mean-field analysis, we ask how a neural network that intrinsically generates chaotic patterns of activity can remain sensitive to extrinsic input. We find that inputs not only drive network responses, but they also actively suppress ongoing activity, ultimately leading to a phase transition in which chaos is completely eliminated. The critical input intensity at the phase transition is a nonmonotonic function of stimulus frequency, revealing a “resonant” frequency at which the input is most effective at suppressing chaos even though the power spectrum of the spontaneous activity peaks at zero and falls exponentially. A prediction of our analysis is that the variance of neural responses should be most strongly suppressed at frequencies matching the range over which many sensory systems operate.},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@rajanStimulusdependentSuppressionChaos2010.md;D\:\\Zotero Storage\\Zotero\\storage\\96HSPS7N\\Rajan et al. - 2010 - Stimulus-dependent suppression of chaos in recurre.pdf}
}

@article{ramirez-mahalufComputationalModelMajor2017,
  title = {A {{Computational Model}} of {{Major Depression}}: The {{Role}} of {{Glutamate Dysfunction}} on {{Cingulo-Frontal Network Dynamics}}},
  shorttitle = {A {{Computational Model}} of {{Major Depression}}},
  author = {Ramirez-Mahaluf, Juan P. and Roxin, Alexander and Mayberg, Helen S. and Compte, Albert},
  date = {2017-01-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {27},
  number = {1},
  pages = {660--679},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhv249},
  url = {https://doi.org/10.1093/cercor/bhv249},
  urldate = {2023-10-26},
  abstract = {Major depression disease (MDD) is associated with the dysfunction of multinode brain networks. However, converging evidence implicates the reciprocal interaction between midline limbic regions (typified by the ventral anterior cingulate cortex, vACC) and the dorso-lateral prefrontal cortex (dlPFC), reflecting interactions between emotions and cognition. Furthermore, growing evidence suggests a role for abnormal glutamate metabolism in the vACC, while serotonergic treatments (selective serotonin reuptake inhibitor, SSRI) effective for many patients implicate the serotonin system. Currently, no mechanistic framework describes how network dynamics, glutamate, and serotonin interact to explain MDD symptoms and treatments. Here, we built a biophysical computational model of 2 areas (vACC and dlPFC) that can switch between emotional and cognitive processing. MDD networks were simulated by slowing glutamate decay in vACC and demonstrated sustained vACC activation. This hyperactivity was not suppressed by concurrent dlPFC activation and interfered with expected dlPFC responses to cognitive signals, mimicking cognitive dysfunction seen in MDD. Simulation of clinical treatments (SSRI or deep brain stimulation) counteracted this aberrant vACC activity. Theta and beta/gamma oscillations correlated with network function, representing markers of switch-like operation in the network. The model shows how glutamate dysregulation can cause aberrant brain dynamics, respond to treatments, and be reflected in EEG rhythms as biomarkers of MDD.},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\XQ4HFIMR\\Ramirez-Mahaluf 等 - 2017 - A Computational Model of Major Depression the Rol.pdf;D\:\\Zotero Storage\\Zotero\\storage\\WDBVPC3N\\3056182.html}
}

@report{ratzonRepresentationalDriftResult2023,
  type = {preprint},
  title = {Representational Drift as a Result of Implicit Regularization},
  author = {Ratzon, Aviv and Derdikman, Dori and Barak, Omri},
  date = {2023-05-09},
  institution = {{Neuroscience}},
  doi = {10.1101/2023.05.04.539512},
  url = {http://biorxiv.org/lookup/doi/10.1101/2023.05.04.539512},
  urldate = {2023-10-09},
  abstract = {Recent studies show that, even in constant environments, the tuning of single neurons changes over time in a variety of brain regions. This representational drift has been suggested to be a consequence of continuous learning under noise, but its properties are still not fully understood. To uncover the underlying mechanism, we trained an artificial network on a simplified navigational task, inspired by the predictive coding literature. The network quickly reached a state of high performance, and many neurons exhibited spatial tuning. We then continued training the network and noticed that the activity became sparser with time. We observed vastly different time scales between the initial learning and the ensuing sparsification. We verified the generality of this phenomenon across tasks, learning algorithms, and parameters. This sparseness is a manifestation of the movement within the solution space - the networks drift until they reach a flat loss landscape. This is consistent with recent experimental results demonstrating that CA1 neurons increase sparseness with exposure to the same environment and become more spatially informative. We conclude that learning is divided into three overlapping phases: Fast familiarity with the environment, slow implicit regularization, and a steady state of null drift. The variability in drift dynamics opens the possibility of inferring learning algorithms from observations of drift statistics.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\DHJIBRSY\Ratzon 等 - 2023 - Representational drift as a result of implicit reg.pdf}
}

@online{renScalingForwardGradient2023,
  title = {Scaling {{Forward Gradient With Local Losses}}},
  author = {Ren, Mengye and Kornblith, Simon and Liao, Renjie and Hinton, Geoffrey},
  date = {2023-03-01},
  eprint = {2210.03310},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2210.03310},
  urldate = {2023-09-07},
  abstract = {Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. However, the standard forward gradient algorithm, when applied naively, suffers from high variance when the number of parameters to be learned is large. In this paper, we propose a series of architectural and algorithmic modifications that together make forward gradient learning practical for standard deep learning benchmark tasks. We show that it is possible to substantially reduce the variance of the forward gradient estimator by applying perturbations to activations rather than weights. We further improve the scalability of forward gradient by introducing a large number of local greedy loss functions, each of which involves only a small number of learnable parameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more suitable for local learning. Our approach matches backprop on MNIST and CIFAR-10 and significantly outperforms previously proposed backprop-free algorithms on ImageNet. Code is released at https://github.com/google-research/ google-research/tree/master/local\_forward\_gradient.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {D:\Zotero Storage\Zotero\storage\Q4INJDBW\Ren et al. - 2023 - Scaling Forward Gradient With Local Losses.pdf}
}

@online{renScalingForwardGradient2023a,
  title = {Scaling {{Forward Gradient With Local Losses}}},
  author = {Ren, Mengye and Kornblith, Simon and Liao, Renjie and Hinton, Geoffrey},
  date = {2023-03-01},
  eprint = {2210.03310},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.03310},
  url = {http://arxiv.org/abs/2210.03310},
  urldate = {2023-09-07},
  abstract = {Forward gradient learning computes a noisy directional gradient and is a biologically plausible alternative to backprop for learning deep neural networks. However, the standard forward gradient algorithm, when applied naively, suffers from high variance when the number of parameters to be learned is large. In this paper, we propose a series of architectural and algorithmic modifications that together make forward gradient learning practical for standard deep learning benchmark tasks. We show that it is possible to substantially reduce the variance of the forward gradient estimator by applying perturbations to activations rather than weights. We further improve the scalability of forward gradient by introducing a large number of local greedy loss functions, each of which involves only a small number of learnable parameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more suitable for local learning. Our approach matches backprop on MNIST and CIFAR-10 and significantly outperforms previously proposed backprop-free algorithms on ImageNet.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\arXiv2023Ren et alScaling Forward Gradient With Local LossesarXivCompNeuro_Literature\\Machine LearningRenM et alMR et alPreprint\\2023_-Scaling Forward Gradient With Local Losses.pdf;D\:\\Zotero Storage\\Zotero\\storage\\YAI5QTZE\\2210.html}
}

@article{rivkindLocalDynamicsTrained2017,
  title = {Local {{Dynamics}} in {{Trained Recurrent Neural Networks}}},
  author = {Rivkind, Alexander and Barak, Omri},
  date = {2017-06-23},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {118},
  number = {25},
  pages = {258101},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.118.258101},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.118.258101},
  urldate = {2023-09-15},
  abstract = {Learning a task induces connectivity changes in neural circuits, thereby changing their dynamics. To elucidate task-related neural dynamics, we study trained recurrent neural networks. We develop a mean field theory for reservoir computing networks trained to have multiple fixed point attractors. Our main result is that the dynamics of the network’s output in the vicinity of attractors is governed by a low-order linear ordinary differential equation. The stability of the resulting equation can be assessed, predicting training success or failure. As a consequence, networks of rectified linear units and of sigmoidal nonlinearities are shown to have diametrically different properties when it comes to learning attractors. Furthermore, a characteristic time constant, which remains finite at the edge of chaos, offers an explanation of the network’s output robustness in the presence of variability of the internal neural dynamics. Finally, the proposed theory predicts state-dependent frequency selectivity in the network response.},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@rivkindLocalDynamicsTrained2017.md;D\:\\Zotero Storage\\Zotero\\storage\\EMGVX7ES\\Rivkind and Barak - 2017 - Local Dynamics in Trained Recurrent Neural Network.pdf;D\:\\Zotero Storage\\Zotero\\storage\\R5L2VCFE\\PhysRevLett.118.html}
}

@article{rolandHowFarNeuroscience2023,
  title = {How Far Neuroscience Is from Understanding Brains},
  author = {Roland, Per E.},
  date = {2023-10-05},
  journaltitle = {Frontiers in Systems Neuroscience},
  shortjournal = {Front. Syst. Neurosci.},
  volume = {17},
  pages = {1147896},
  issn = {1662-5137},
  doi = {10.3389/fnsys.2023.1147896},
  url = {https://www.frontiersin.org/articles/10.3389/fnsys.2023.1147896/full},
  urldate = {2023-10-09},
  abstract = {The cellular biology of brains is relatively well-understood, but neuroscientists have not yet generated a theory explaining how brains work. Explanations of how neurons collectively operate to produce what brains can do are tentative and incomplete. Without prior assumptions about the brain mechanisms, I attempt here to identify major obstacles to progress in neuroscientific understanding of brains and central nervous systems. Most of the obstacles to our understanding are conceptual. Neuroscience lacks concepts and models rooted in experimental results explaining how neurons interact at all scales. The cerebral cortex is thought to control awake activities, which contrasts with recent experimental results. There is ambiguity distinguishing task-related brain activities from spontaneous activities and organized intrinsic activities. Brains are regarded as driven by external and internal stimuli in contrast to their considerable autonomy. Experimental results are explained by sensory inputs, behavior, and psychological concepts. Time and space are regarded as mutually independent variables for spiking, post-synaptic events, and other measured variables, in contrast to experimental results. Dynamical systems theory and models describing evolution of variables with time as the independent variable are insufficient to account for central nervous system activities. Spatial dynamics may be a practical solution. The general hypothesis that measurements of changes in fundamental brain variables, action potentials, transmitter releases, post-synaptic transmembrane currents, etc., propagating in central nervous systems reveal how they work, carries no additional assumptions. Combinations of current techniques could reveal many aspects of spatial dynamics of spiking, post-synaptic processing, and plasticity in insects and rodents to start with. But problems defining baseline and reference conditions hinder interpretations of the results. Furthermore, the facts that pooling and averaging of data destroy their underlying dynamics imply that single-trial designs and statistics are necessary.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\USDWKQMP\Roland - 2023 - How far neuroscience is from understanding brains.pdf}
}

@article{ruleCausesConsequencesRepresentational2019,
  title = {Causes and Consequences of Representational Drift},
  author = {Rule, Michael E and O’Leary, Timothy and Harvey, Christopher D},
  date = {2019-10-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {58},
  pages = {141--147},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.08.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438819300303},
  urldate = {2023-10-09},
  abstract = {The nervous system learns new associations while maintaining memories over long periods, exhibiting a balance between flexibility and stability. Recent experiments reveal that neuronal representations of learned sensorimotor tasks continually change over days and weeks, even after animals have achieved expert behavioral performance. How is learned information stored to allow consistent behavior despite ongoing changes in neuronal activity? What functions could ongoing reconfiguration serve? We highlight recent experimental evidence for such representational drift in sensorimotor systems, and discuss how this fits into a framework of distributed population codes. We identify recent theoretical work that suggests computational roles for drift and argue that the recurrent and distributed nature of sensorimotor representations permits drift while limiting disruptive effects. We propose that representational drift may create error signals between interconnected brain regions that can be used to keep neural codes consistent in the presence of continual change. These concepts suggest experimental and theoretical approaches to studying both learning and maintenance of distributed and adaptive population codes.},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\G7B2RZG9\\Rule 等 - 2019 - Causes and consequences of representational drift.pdf;D\:\\Zotero Storage\\Zotero\\storage\\956XGMUG\\S0959438819300303.html}
}

@article{scangosStatedependentResponsesIntracranial2021,
  title = {State-Dependent Responses to Intracranial Brain Stimulation in a Patient with Depression},
  author = {Scangos, Katherine W. and Makhoul, Ghassan S. and Sugrue, Leo P. and Chang, Edward F. and Krystal, Andrew D.},
  date = {2021-02},
  journaltitle = {Nature Medicine},
  shortjournal = {Nat Med},
  volume = {27},
  number = {2},
  pages = {229--231},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-020-01175-8},
  url = {https://www.nature.com/articles/s41591-020-01175-8},
  urldate = {2023-09-20},
  abstract = {Deep brain stimulation is a promising treatment for severe depression, but lack of efficacy in randomized trials raises questions regarding anatomical targeting. We implanted multi-site intracranial electrodes in a severely depressed patient and systematically assessed the acute response to focal electrical neuromodulation. We found an elaborate repertoire of distinctive emotional responses that were rapid in onset, reproducible, and context and state dependent. Results provide proof of concept for personalized, circuit-specific medicine in psychiatry.},
  issue = {2},
  langid = {english},
  keywords = {Depression,Neurophysiology},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\scangosStatedependentResponsesIntracranial2021.md;D\:\\Zotero Storage\\Zotero\\storage\\B7YN5DDS\\Scangos et al. - 2021 - State-dependent responses to intracranial brain st.pdf}
}

@article{schneidmanWeakPairwiseCorrelations2006,
  title = {Weak Pairwise Correlations Imply Strongly Correlated Network States in a Neural Population},
  author = {Schneidman, Elad and Berry, Michael J. and Segev, Ronen and Bialek, William},
  date = {2006-04},
  journaltitle = {Nature},
  volume = {440},
  number = {7087},
  pages = {1007--1012},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature04701},
  url = {https://www.nature.com/articles/nature04701},
  urldate = {2023-08-29},
  abstract = {Biological networks have so many possible states that exhaustive sampling is impossible. Successful analysis thus depends on simplifying hypotheses, but experiments on many systems hint that complicated, higher-order interactions among large groups of elements have an important role. Here we show, in the vertebrate retina, that weak correlations between pairs of neurons coexist with strongly collective behaviour in the responses of ten or more neurons. We find that this collective behaviour is described quantitatively by models that capture the observed pairwise correlations but assume no higher-order interactions. These maximum entropy models are equivalent to Ising models, and predict that larger networks are completely dominated by correlation effects. This suggests that the neural code has associative or error-correcting properties, and we provide preliminary evidence for such behaviour. As a first test for the generality of these ideas, we show that similar results are obtained from networks of cultured cortical neurons.},
  issue = {7087},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@schneidmanWeakPairwiseCorrelations2006.md;D\:\\Zotero Storage\\Zotero\\storage\\7KS7IDSV\\Schneidman et al. - 2006 - Weak pairwise correlations imply strongly correlat.pdf}
}

@incollection{schultzPhasicRewardSignal1997,
  title = {The Phasic Reward Signal of Primate Dopamine Neurons},
  booktitle = {Advances in Pharmacology},
  author = {Schultz, Wolfram},
  date = {1997},
  volume = {42},
  pages = {686--690},
  publisher = {{Elsevier}},
  isbn = {1054-3589}
}

@article{schultzPredictiveRewardSignal1998,
  title = {Predictive Reward Signal of Dopamine Neurons},
  author = {Schultz, W.},
  date = {1998-07},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J Neurophysiol},
  volume = {80},
  number = {1},
  eprint = {9658025},
  eprinttype = {pmid},
  pages = {1--27},
  issn = {0022-3077},
  doi = {10.1152/jn.1998.80.1.1},
  abstract = {The effects of lesions, receptor blocking, electrical self-stimulation, and drugs of abuse suggest that midbrain dopamine systems are involved in processing reward information and learning approach behavior. Most dopamine neurons show phasic activations after primary liquid and food rewards and conditioned, reward-predicting visual and auditory stimuli. They show biphasic, activation-depression responses after stimuli that resemble reward-predicting stimuli or are novel or particularly salient. However, only few phasic activations follow aversive stimuli. Thus dopamine neurons label environmental stimuli with appetitive value, predict and detect rewards and signal alerting and motivating events. By failing to discriminate between different rewards, dopamine neurons appear to emit an alerting message about the surprising presence or absence of rewards. All responses to rewards and reward-predicting stimuli depend on event predictability. Dopamine neurons are activated by rewarding events that are better than predicted, remain uninfluenced by events that are as good as predicted, and are depressed by events that are worse than predicted. By signaling rewards according to a prediction error, dopamine responses have the formal characteristics of a teaching signal postulated by reinforcement learning theories. Dopamine responses transfer during learning from primary rewards to reward-predicting stimuli. This may contribute to neuronal mechanisms underlying the retrograde action of rewards, one of the main puzzles in reinforcement learning. The impulse response releases a short pulse of dopamine onto many dendrites, thus broadcasting a rather global reinforcement signal to postsynaptic neurons. This signal may improve approach behavior by providing advance reward information before the behavior occurs, and may contribute to learning by modifying synaptic transmission. The dopamine reward signal is supplemented by activity in neurons in striatum, frontal cortex, and amygdala, which process specific reward information but do not emit a global reward prediction error signal. A cooperation between the different reward signals may assure the use of specific rewards for selectively reinforcing behaviors. Among the other projection systems, noradrenaline neurons predominantly serve attentional mechanisms and nucleus basalis neurons code rewards heterogeneously. Cerebellar climbing fibers signal errors in motor performance or errors in the prediction of aversive events to cerebellar Purkinje cells. Most deficits following dopamine-depleting lesions are not easily explained by a defective reward signal but may reflect the absence of a general enabling function of tonic levels of extracellular dopamine. Thus dopamine systems may have two functions, the phasic transmission of reward information and the tonic enabling of postsynaptic neurons.},
  langid = {english},
  keywords = {Animals,Brain,Dopamine,Humans,Learning,{Models, Neurological},Neurons,Reward,Signal Transduction},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\Journal of Neurophysiology1998SchultzPredictive reward signal of dopamine neuronsJournal of NeurophysiologyJ Neurophysiol8011-27BooksSchultzWWSJournal Article\1998_-Predictive reward signal of dopamine neurons.pdf}
}

@article{schulzeNumberPulsesNumber2018,
  title = {Number of Pulses or Number of Sessions? {{An}} Open-Label Study of Trajectories of Improvement for Once-vs. Twice-Daily Dorsomedial Prefrontal {{rTMS}} in Major Depression},
  shorttitle = {Number of Pulses or Number of Sessions?},
  author = {Schulze, Laura and Feffer, Kfir and Lozano, Christopher and Giacobbe, Peter and Daskalakis, Zafiris J. and Blumberger, Daniel M. and Downar, Jonathan},
  date = {2018-03-01},
  journaltitle = {Brain Stimulation},
  shortjournal = {Brain Stimulation},
  volume = {11},
  number = {2},
  pages = {327--336},
  issn = {1935-861X},
  doi = {10.1016/j.brs.2017.11.002},
  url = {https://www.sciencedirect.com/science/article/pii/S1935861X17309580},
  urldate = {2023-09-24},
  abstract = {Background Repetitive transcranial magnetic stimulation (rTMS) shows efficacy in the treatment of major depressive episodes (MDEs), but can require ≥4–6 weeks for maximal effect. Recent studies suggest that multiple daily sessions of rTMS can accelerate response without reducing therapeutic efficacy. However, it is unresolved whether therapeutic effects track cumulative number of pulses, or cumulative number of sessions. Objective This open-label study reviewed clinical outcomes over a 20–30 session course of high-frequency bilateral dorsomedial prefrontal cortex (DMPFC)-rTMS among patients receiving 6000 pulses/day delivered either in twice-daily sessions 80~min apart (at 20~Hz) or single, longer, once-daily sessions (at 10~Hz). Methods A retrospective chart review identified 130 MDD patients who underwent 20–30 daily sessions of bilateral DMPFC-rTMS (Once-daily, n~=~65; Twice-daily, n~=~65) at a single Canadian clinic. Results Mixed-effects modeling revealed significantly faster improvement (group-by-time interaction) for twice-daily versus once-daily DMPFC-rTMS. Across both groups, the pace of improvement showed a consistent relationship with number of cumulative sessions, but not with cumulative number of pulses. Although the twice-daily group completed treatment in half as many days, final clinical outcomes did not differ significantly between groups on dichotomous measures (response/remission rates: once-daily, 35.4\%/33.8\%; twice-daily, 41.5\%/35.4\%), or continuous measures, or on overall response distribution. Conclusions Twice-daily rTMS appears feasible, tolerable, and capable of achieving comparable results to once-daily rTMS, while also reducing course length approximately twofold. Therapeutic gains tracked the cumulative number of sessions, not pulses. Future randomized studies comparing once-daily to multiple-daily rTMS sessions, while controlling for number of pulses, may be warranted.},
  keywords = {Accelerated,Case series,Depression,Dorsomedial,Dose-response,Interval,rTMS},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\schulzeNumberPulsesNumber2018.md;D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Brain Stimulation2018Schulze et alNumber of pulses or number of sessionsBrain StimulationBrain Stimulation112327-336Depression\\iTBSSchulzeL et alLS et al期刊文章\\2018_-Number of pulses or number of sessions.pdf;D\:\\Zotero Storage\\Zotero\\storage\\QW4PGUYJ\\S1935861X17309580.html}
}

@article{schwartzSpiketriggeredNeuralCharacterization2006,
  title = {Spike-Triggered Neural Characterization},
  author = {Schwartz, Odelia and Pillow, Jonathan W. and Rust, Nicole C. and family=Simoncelli, given=Eero P. \%J Journal, prefix=of vision, useprefix=false},
  date = {2006},
  volume = {6},
  number = {4},
  pages = {13--13},
  issn = {1534-7362}
}

@article{semedoFeedforwardFeedbackInteractions2022,
  title = {Feedforward and Feedback Interactions between Visual Cortical Areas Use Different Population Activity Patterns},
  author = {Semedo, J. D. and Jasper, A. I. and Zandvakili, A. and Krishna, A. and Aschner, A. and Machens, C. K. and Kohn, A. and Yu, B. M.},
  date = {2022-03-01},
  journaltitle = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {1099},
  issn = {2041-1723 (Electronic) 2041-1723 (Linking)},
  doi = {10.1038/s41467-022-28552-w},
  abstract = {Brain function relies on the coordination of activity across multiple, recurrently connected brain areas. For instance, sensory information encoded in early sensory areas is relayed to, and further processed by, higher cortical areas and then fed back. However, the way in which feedforward and feedback signaling interact with one another is incompletely understood. Here we investigate this question by leveraging simultaneous neuronal population recordings in early and midlevel visual areas (V1-V2 and V1-V4). Using a dimensionality reduction approach, we find that population interactions are feedforward-dominated shortly after stimulus onset and feedback-dominated during spontaneous activity. The population activity patterns most correlated across areas were distinct during feedforward- and feedback-dominated periods. These results suggest that feedforward and feedback signaling rely on separate "channels", which allows feedback signals to not directly affect activity that is fed forward.},
  pmcid = {PMC8888615},
  keywords = {*Visual Cortex/physiology,Feedback,Neurons/physiology,Photic Stimulation,Visual Pathways/physiology}
}

@article{shamabadiNeuroimagingCorrelatesTreatment2023,
  title = {Neuroimaging {{Correlates}} of {{Treatment Response}} to {{Transcranial Magnetic Stimulation}} in {{Bipolar Depression}}: {{A Systematic Review}}},
  shorttitle = {Neuroimaging {{Correlates}} of {{Treatment Response}} to {{Transcranial Magnetic Stimulation}} in {{Bipolar Depression}}},
  author = {Shamabadi, Ahmad and Karimi, Hanie and Cattarinussi, Giulia and Moghaddam, Hossein Sanjari and Akhondzadeh, Shahin and Sambataro, Fabio and Schiena, Giandomenico and Delvecchio, Giuseppe},
  date = {2023-05},
  journaltitle = {Brain Sciences},
  volume = {13},
  number = {5},
  pages = {801},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3425},
  doi = {10.3390/brainsci13050801},
  url = {https://www.mdpi.com/2076-3425/13/5/801},
  urldate = {2023-09-25},
  abstract = {Transcranial magnetic stimulation (TMS) has become a promising strategy for bipolar disorder (BD). This study reviews neuroimaging findings, indicating functional, structural, and metabolic brain changes associated with TMS in BD. Web of Science, Embase, Medline, and Google Scholar were searched without any restrictions for studies investigating neuroimaging biomarkers, through structural magnetic resonance imaging (MRI), diffusion tensor imaging (DTI), functional MRI (fMRI), magnetic resonance spectroscopy (MRS), positron emission tomography (PET), and single photon emission computed tomography (SPECT), in association with response to TMS in patients with BD. Eleven studies were included (fMRI = 4, MRI = 1, PET = 3, SPECT = 2, and MRS = 1). Important fMRI predictors of response to repetitive TMS (rTMS) included higher connectivity of emotion regulation and executive control regions. Prominent MRI predictors included lower ventromedial prefrontal cortex connectivity and lower superior frontal and caudal middle frontal volumes. SPECT studies found hypoconnectivity of the uncus/parahippocampal cortex and right thalamus in non-responders. The post-rTMS changes using fMRI mostly showed increased connectivity among the areas neighboring the coil. Increased blood perfusion was reported post-rTMS in PET and SPECT studies. Treatment response comparison between unipolar depression and BD revealed almost equal responses. Neuroimaging evidence suggests various correlates of response to rTMS in BD, which needs to be further replicated in future studies.},
  issue = {5},
  langid = {english},
  keywords = {bipolar depression,brain imaging,functional neuroimaging,systematic review,transcranial magnetic stimulations},
  file = {D:\Zotero Storage\Zotero\storage\9CGQXJJ6\Shamabadi 等 - 2023 - Neuroimaging Correlates of Treatment Response to T.pdf}
}

@article{shourieNeurofeedbackTrainingProtocols2018,
  title = {Neurofeedback Training Protocols Based on Spectral {{EEG}} Feature Subset and Channel Selection for Performance Enhancement of Novice Visual Artists},
  author = {Shourie, Nasrin and Firoozabadi, Mohammad and Badie, Kambiz},
  date = {2018},
  journaltitle = {Biomedical Signal Processing and Control},
  volume = {43},
  pages = {117--129},
  issn = {17468094},
  doi = {10.1016/j.bspc.2018.02.017}
}

@article{sohogluDetectingRepresentingPredictable2016,
  title = {Detecting and Representing Predictable Structure during Auditory Scene Analysis},
  author = {Sohoglu, E. and Chait, M.},
  date = {2016-09-07},
  journaltitle = {Elife},
  volume = {5},
  issn = {2050-084X (Electronic) 2050-084X (Linking)},
  doi = {10.7554/eLife.19113},
  abstract = {We use psychophysics and MEG to test how sensitivity to input statistics facilitates auditory-scene-analysis (ASA). Human subjects listened to 'scenes' comprised of concurrent tone-pip streams (sources). On occasional trials a new source appeared partway. Listeners were more accurate and quicker to detect source appearance in scenes comprised of temporally-regular (REG), rather than random (RAND), sources. MEG in passive listeners and those actively detecting appearance events revealed increased sustained activity in auditory and parietal cortex in REG relative to RAND scenes, emerging \textasciitilde 400 ms of scene-onset. Over and above this, appearance in REG scenes was associated with increased responses relative to RAND scenes. The effect of temporal structure on appearance-evoked responses was delayed when listeners were focused on the scenes relative to when listening passively, consistent with the notion that attention reduces 'surprise'. Overall, the results implicate a mechanism that tracks predictability of multiple concurrent sources to facilitate active and passive ASA.},
  pmcid = {PMC5014546},
  keywords = {{*Anticipation, Psychological},Acoustic Stimulation,Adolescent,Adult,attention,Attention/physiology,Auditory Cortex/anatomy \& histology/*physiology,Auditory Perception/*physiology,change detection,{Evoked Potentials, Auditory/physiology},Female,Functional Laterality/*physiology,human,Humans,Magnetoencephalography,Male,neuroscience,Parietal Lobe/anatomy \& histology/*physiology,predictive coding,Psychophysics,Reaction Time,scene analysis,surprise}
}

@article{sompolinskyChaosRandomNeural1988,
  title = {Chaos in {{Random Neural Networks}}},
  author = {Sompolinsky, H. and Crisanti, A. and Sommers, H. J.},
  date = {1988-07-18},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {61},
  number = {3},
  pages = {259--262},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.61.259},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.61.259},
  urldate = {2023-09-08},
  abstract = {A continuous-time dynamic model of a network of N nonlinear elements interacting via random asymmetric couplings is studied. A self-consistent mean-field theory, exact in the N→∞ limit, predicts a transition from a stationary phase to a chaotic phase occurring at a critical value of the gain parameter. The autocorrelations of the chaotic flow as well as the maximal Lyapunov exponent are calculated.},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@sompolinskyChaosRandomNeural1988.md;D\:\\Zotero Storage\\Zotero\\storage\\2WD8UVFW\\Sompolinsky et al. - 1988 - Chaos in Random Neural Networks.pdf}
}

@article{sonmezAcceleratedTMSDepression2019,
  title = {Accelerated {{TMS}} for {{Depression}}: {{A}} Systematic Review and Meta-Analysis},
  shorttitle = {Accelerated {{TMS}} for {{Depression}}},
  author = {Sonmez, A. Irem and Camsari, Deniz Doruk and Nandakumar, Aiswarya L. and Voort, Jennifer L. Vande and Kung, Simon and Lewis, Charles P. and Croarkin, Paul E.},
  date = {2019-03-01},
  journaltitle = {Psychiatry Research},
  shortjournal = {Psychiatry Research},
  volume = {273},
  pages = {770--781},
  issn = {0165-1781},
  doi = {10.1016/j.psychres.2018.12.041},
  url = {https://www.sciencedirect.com/science/article/pii/S016517811831326X},
  urldate = {2023-09-04},
  abstract = {Repetitive transcranial magnetic stimulation (TMS) is now widely available for the clinical treatment of depression, but the associated financial and time burdens are problematic for patients. Accelerated TMS (aTMS) protocols address these burdens and attempt to increase the efficiency of standard TMS. This systematic review and meta-analysis aimed to examine accelerated TMS studies for depressive disorders in accordance with PRISMA guidelines. Inclusion criteria consisted of studies with full text publications available in English describing more than one session of TMS (repetitive or theta burst stimulation) per day. Studies describing accelerated TMS protocols for conditions other than depression or alternative neuromodulation methods, preclinical studies, and neurophysiology studies regarding transcranial stimulation were excluded. Eighteen articles describing eleven distinct studies (seven publications described overlapping samples) met eligibility criteria. A Hedges’ g effect size and confidence intervals were calculated. The summary analysis of three suitable randomized control trials revealed a cumulative effect size of 0.39 (95\% CI 0.005–0.779). A separate analysis including open-label trials and active arms of suitable RCTs revealed a g of 1.27 (95\% CI 0.902–1.637). Overall, the meta-analysis suggested that aTMS improves depressive symptom severity. In general, study methodologies were acceptable, but future efforts could enhance sham techniques and blinding.},
  keywords = {Accelerated TMS,Depression,Major depressive disorder,MDD,TMS,TRD,Treatment resistant depression},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@sonmezAcceleratedTMSDepression2019.md;D\:\\Zotero Storage\\Web Storage\\08-Assets\\pdfs\\Psychiatry Research2019Sonmez et alAccelerated TMS for DepressionPsychiatry ResearchPsychiatry Research273770-781EMPTY_COLLECTION_NAMESonmezA et alAS et alJournal Article\\2019_-Accelerated TMS for Depression.pdf;D\:\\Zotero Storage\\Zotero\\storage\\UZU3LYDI\\S016517811831326X.html}
}

@article{southwellPredictabilitySalientStudy2017,
  title = {Is Predictability Salient? {{A}} Study of Attentional Capture by Auditory Patterns},
  author = {Southwell, R. and Baumann, A. and Gal, C. and Barascud, N. and Friston, K. and Chait, M.},
  date = {2017-02-19},
  journaltitle = {Philos Trans R Soc Lond B Biol Sci},
  volume = {372},
  number = {1714},
  issn = {1471-2970 (Electronic) 0962-8436 (Print) 0962-8436 (Linking)},
  doi = {10.1098/rstb.2016.0105},
  abstract = {In this series of behavioural and electroencephalography (EEG) experiments, we investigate the extent to which repeating patterns of sounds capture attention. Work in the visual domain has revealed attentional capture by statistically predictable stimuli, consistent with predictive coding accounts which suggest that attention is drawn to sensory regularities. Here, stimuli comprised rapid sequences of tone pips, arranged in regular (REG) or random (RAND) patterns. EEG data demonstrate that the brain rapidly recognizes predictable patterns manifested as a rapid increase in responses to REG relative to RAND sequences. This increase is reminiscent of the increase in gain on neural responses to attended stimuli often seen in the neuroimaging literature, and thus consistent with the hypothesis that predictable sequences draw attention. To study potential attentional capture by auditory regularities, we used REG and RAND sequences in two different behavioural tasks designed to reveal effects of attentional capture by regularity. Overall, the pattern of results suggests that regularity does not capture attention.This article is part of the themed issue 'Auditory and visual scene analysis'.},
  pmcid = {PMC5206273},
  keywords = {*Attention,*Auditory Perception,Acoustic Stimulation,Adult,attention,auditory scene analysis,Electroencephalography,Female,Humans,Male,predictive coding,regularity,statistical learning,Young Adult}
}

@article{stamCharacterizationAnatomicalFunctional2010,
  title = {Characterization of Anatomical and Functional Connectivity in the Brain: {{A}} Complex Networks Perspective},
  shorttitle = {Characterization of Anatomical and Functional Connectivity in the Brain},
  author = {Stam, C.J.},
  date = {2010-09},
  journaltitle = {International Journal of Psychophysiology},
  shortjournal = {International Journal of Psychophysiology},
  volume = {77},
  number = {3},
  pages = {186--194},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2010.06.024},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167876010001686},
  urldate = {2023-12-11},
  abstract = {A central question in modern neuroscience is how anatomical and functional connections between brain areas are organized to allow optimal information processing. In particular, both segregation and integration of information have to be dealt with in a single architecture of brain networks. There is strong evidence that synchronization of neural activity, both locally and between distant regions is a crucial code for functional interactions. However, a powerful theoretical framework to describe the structural and functional topology of system-wide brain networks has only become available with the discovery of ‘small-world’ and ‘scale-free’ networks in 1998 and 1999. There is now strong evidence that brain networks, ranging from simple nets of interconnected neurons up to macroscopic networks of brain areas display the typical features of complex systems: high clustering, short path lengths (both typical of ‘small-world’ networks), skewed degree distributions, presence of hubs, assortative mixing and the presence of modules. This has been demonstrated for anatomical and functional networks using neuroanatomical techniques, EEG, MEG and structural and functional MRI, in organisms ranging from C. elegans to man. In addition, network topology has been shown to be highly heritable, and very predictive of cognitive functioning. A short path length, which implies that from any area in the brain any other area can be reached in a small number of steps, is strongly correlated with IQ. Computational models are now beginning to reveal how the complex structure of adult brain networks could arise during development.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\MWN54MH7\Stam - 2010 - Characterization of anatomical and functional conn.pdf}
}

@article{stamFunctionalConnectivityPatterns2004,
  title = {Functional Connectivity Patterns of Human Magnetoencephalographic Recordings: A ‘Small-World’ Network?},
  shorttitle = {Functional Connectivity Patterns of Human Magnetoencephalographic Recordings},
  author = {Stam, C.J.},
  date = {2004-01},
  journaltitle = {Neuroscience Letters},
  shortjournal = {Neuroscience Letters},
  volume = {355},
  number = {1-2},
  pages = {25--28},
  issn = {03043940},
  doi = {10.1016/j.neulet.2003.10.063},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0304394003012722},
  urldate = {2023-12-11},
  abstract = {EEG and MEG (magnetoencephalography) are widely used to study functional connectivity between different brain regions. We address the question whether such connectivity patterns display an optimal organization for information processing. MEG recordings of five healthy human subjects were converted to sparsely connected graphs (N ¼ 126; k ¼ 15) by applying a suitable threshold to the N p N matrix of synchronization strengths. For intermediate frequencies (8– 30 Hz) the synchronization patterns were similar to those of an ordered graph with a consistent drop of synchronization strength as a function of distance. For low (,8 Hz) and high (.30 Hz) frequency bands the synchronization patterns displayed the features of a so-called ‘small-world’ network. This might reflect an optimal organization pattern for information processing, connecting any two brain area by only a small number of intermediate steps.},
  langid = {english},
  keywords = {Graph Theory,MEG},
  file = {D:\Zotero Storage\Zotero\storage\CN84UMXX\Stam - 2004 - Functional connectivity patterns of human magnetoe.pdf}
}

@article{stamNonlinearDynamicalAnalysis2005,
  title = {Nonlinear Dynamical Analysis of {{EEG}} and {{MEG}}: {{Review}} of an Emerging Field},
  shorttitle = {Nonlinear Dynamical Analysis of {{EEG}} and {{MEG}}},
  author = {Stam, C. J.},
  date = {2005-10-01},
  journaltitle = {Clinical Neurophysiology},
  shortjournal = {Clinical Neurophysiology},
  volume = {116},
  number = {10},
  pages = {2266--2301},
  issn = {1388-2457},
  doi = {10.1016/j.clinph.2005.06.011},
  url = {https://www.sciencedirect.com/science/article/pii/S1388245705002403},
  urldate = {2023-11-21},
  abstract = {Many complex and interesting phenomena in nature are due to nonlinear phenomena. The theory of nonlinear dynamical systems, also called ‘chaos theory’, has now progressed to a stage, where it becomes possible to study self-organization and pattern formation in the complex neuronal networks of the brain. One approach to nonlinear time series analysis consists of reconstructing, from time series of EEG or MEG, an attractor of the underlying dynamical system, and characterizing it in terms of its dimension (an estimate of the degrees of freedom of the system), or its Lyapunov exponents and entropy (reflecting unpredictability of the dynamics due to the sensitive dependence on initial conditions). More recently developed nonlinear measures characterize other features of local brain dynamics (forecasting, time asymmetry, determinism) or the nonlinear synchronization between recordings from different brain regions. Nonlinear time series has been applied to EEG and MEG of healthy subjects during no-task resting states, perceptual processing, performance of cognitive tasks and different sleep stages. Many pathologic states have been examined as well, ranging from toxic states, seizures, and psychiatric disorders to Alzheimer's, Parkinson's and Cre1utzfeldt-Jakob's disease. Interpretation of these results in terms of ‘functional sources’ and ‘functional networks’ allows the identification of three basic patterns of brain dynamics: (i) normal, ongoing dynamics during a no-task, resting state in healthy subjects; this state is characterized by a high dimensional complexity and a relatively low and fluctuating level of synchronization of the neuronal networks; (ii) hypersynchronous, highly nonlinear dynamics of epileptic seizures; (iii) dynamics of degenerative encephalopathies with an abnormally low level of between area synchronization. Only intermediate levels of rapidly fluctuating synchronization, possibly due to critical dynamics near a phase transition, are associated with normal information processing, whereas both hyper—as well as hyposynchronous states result in impaired information processing and disturbed consciousness.},
  keywords = {chaos,complexity,EEG,MEG,Nonlinear dynamics,self-organization,time series analysis},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\1-summary\\Computational Neuroscience\\Nonlinear dynamical analysis of EEG and MEG Review of an emerging field.md;D\:\\Zotero Storage\\Zotero\\storage\\RAPKKVWI\\Stam - 2005 - Nonlinear dynamical analysis of EEG and MEG Revie.pdf}
}

@article{stephanTenSimpleRules2010,
  title = {Ten Simple Rules for Dynamic Causal Modeling},
  author = {Stephan, K. E. and Penny, W. D. and Moran, R. J. and family=Ouden, given=H. E., prefix=den, useprefix=true and Daunizeau, J. and Friston, K. J.},
  date = {2010-02-15},
  journaltitle = {Neuroimage},
  volume = {49},
  number = {4},
  pages = {3099--109},
  issn = {1095-9572 (Electronic) 1053-8119 (Print) 1053-8119 (Linking)},
  doi = {10.1016/j.neuroimage.2009.11.015},
  abstract = {Dynamic causal modeling (DCM) is a generic Bayesian framework for inferring hidden neuronal states from measurements of brain activity. It provides posterior estimates of neurobiologically interpretable quantities such as the effective strength of synaptic connections among neuronal populations and their context-dependent modulation. DCM is increasingly used in the analysis of a wide range of neuroimaging and electrophysiological data. Given the relative complexity of DCM, compared to conventional analysis techniques, a good knowledge of its theoretical foundations is needed to avoid pitfalls in its application and interpretation of results. By providing good practice recommendations for DCM, in the form of ten simple rules, we hope that this article serves as a helpful tutorial for the growing community of DCM users.},
  pmcid = {PMC2825373},
  keywords = {*Algorithms,*Bayes Theorem,{*Models, Neurological},Animals,Brain Mapping/*methods,Brain/*physiology,Causality,Computer Simulation,Evoked Potentials/*physiology,Humans,Nerve Net/*physiology,{Pattern Recognition, Automated/methods}}
}

@online{StructureFunctionRelationshipBrain,
  title = {Structure-Function Relationship of the Brain: A Comparison Between the 2D Classical Ising Model and the Generalized Ising Model - ProQuest},
  shorttitle = {Structure-Function Relationship of the Brain},
  url = {https://www.proquest.com/openview/0b1c9bf2e8ec6b8e2c64c4efe7b4dd1e/1?pq-origsite=gscholar&cbl=18750&diss=y},
  urldate = {2023-08-23},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.},
  langid = {chinese},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@StructureFunctionRelationshipBrain.md;D\:\\Zotero Storage\\Zotero\\storage\\QLRJ2E7K\\Structure-Function Relationship of the Brain.pdf;D\:\\Zotero Storage\\Zotero\\storage\\4QNDBK5X\\1.html}
}

@article{sussilloGeneratingCoherentPatterns2009,
  title = {Generating {{Coherent Patterns}} of {{Activity}} from {{Chaotic Neural Networks}}},
  author = {Sussillo, David and Abbott, L.F.},
  date = {2009-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {63},
  number = {4},
  pages = {544--557},
  issn = {08966273},
  doi = {10.1016/j.neuron.2009.07.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627309005479},
  urldate = {2023-08-21},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@sussilloGeneratingCoherentPatterns2009.md;D\:\\Zotero Storage\\Zotero\\storage\\58GEZRXM\\sussillo2009.pdf.pdf;D\:\\Zotero Storage\\Zotero\\storage\\FTHU5WEX\\Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf}
}

@article{sussilloGeneratingCoherentPatterns2009a,
  title = {Generating {{Coherent Patterns}} of {{Activity}} from {{Chaotic Neural Networks}}},
  author = {Sussillo, David and Abbott, L. F.},
  date = {2009-08-27},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {63},
  number = {4},
  pages = {544--557},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.07.018},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627309005479},
  urldate = {2023-09-13},
  abstract = {Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.},
  keywords = {SYSNEURO},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@sussilloGeneratingCoherentPatterns2009a.md;D\:\\Zotero Storage\\Zotero\\storage\\5FS25TSP\\Sussillo and Abbott - 2009 - Generating Coherent Patterns of Activity from Chao.pdf;D\:\\Zotero Storage\\Zotero\\storage\\GDRQNNPJ\\S0896627309005479.html}
}

@article{tewarieTrackingDynamicBrain2019,
  title = {Tracking Dynamic Brain Networks Using High Temporal Resolution {{MEG}} Measures of Functional Connectivity},
  author = {Tewarie, Prejaas and Liuzzi, Lucrezia and O'Neill, George C. and Quinn, Andrew J. and Griffa, Alessandra and Woolrich, Mark W. and Stam, Cornelis J. and Hillebrand, Arjan and Brookes, Matthew J.},
  date = {2019-10-15},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {200},
  pages = {38--50},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2019.06.006},
  url = {https://www.sciencedirect.com/science/article/pii/S1053811919304914},
  urldate = {2023-12-06},
  abstract = {Fluctuations in functional interactions between brain regions typically occur at the millisecond time scale. Conventional connectivity metrics are not adequately time-resolved to detect such fast fluctuations in functional connectivity. At the same time, attempts to use conventional metrics in a time-resolved manner usually come with the selection of sliding windows of fixed arbitrary length. In the current work, we evaluated the use of high temporal resolution metrics of functional connectivity in conjunction with non-negative tensor factorisation to detect fast fluctuations in connectivity and temporally evolving subnetworks. To this end, we used the phase difference derivative, wavelet coherence, and we also introduced a new metric, the instantaneous amplitude correlation. In order to deal with the inherently noisy nature of magnetoencephalography data and large datasets, we make use of recurrence plots and we used pair-wise orthogonalisation to avoid spurious estimates of functional connectivity due to signal leakage. Firstly, metrics were evaluated in the context of dynamically coupled neural mass models in the presence and absence of delays and also compared to conventional static metrics with fixed sliding windows. Simulations showed that these high temporal resolution metrics outperformed conventional static connectivity metrics. Secondly, the sensitivity of the metrics to fluctuations in connectivity was analysed in post-movement beta rebound magnetoencephalography data, which showed time locked sensorimotor subnetworks that modulated with the post-movement beta rebound. Finally, sensitivity of the metrics was evaluated in resting-state magnetoencephalography, showing similar spatial patterns across metrics, thereby indicating the robustness of the current analysis. The current methods can be applied in cognitive experiments that involve fast modulations in connectivity in relation to cognition. In addition, these methods could also be used as input to temporal graph analysis to further characterise the rapid fluctuation in brain network topology.},
  keywords = {Dynamic functional connectivity,Instantaneous amplitude correlation,Magnetoencephalography,Phase difference derivative,Temporal networks,Wavelet coherence},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\W4NGHYWI\\Tewarie 等 - 2019 - Tracking dynamic brain networks using high tempora.pdf;D\:\\Zotero Storage\\Zotero\\storage\\ENLZCDDJ\\S1053811919304914.html}
}

@article{tianResearchDifferentialBrain2021,
  title = {Research on {{Differential Brain Networks}} before and after {{WM Training}} under {{Different Frequency Band Oscillations}}},
  author = {Tian, Y. and Zhou, H. and Zhang, H. and Li, T.},
  date = {2021},
  journaltitle = {Neural Plast},
  volume = {2021},
  pages = {6628021},
  issn = {1687-5443 (Electronic) 1687-5443 (Linking)},
  doi = {10.1155/2021/6628021},
  abstract = {Previous studies have shown that different frequency band oscillations are associated with cognitive processing such as working memory (WM). Electroencephalogram (EEG) coherence and graph theory can be used to measure functional connections between different brain regions and information interaction between different clusters of neurons. At the same time, it was found that better cognitive performance of individuals indicated stronger small-world characteristics of resting-state WM networks. However, little is known about the neural synchronization of the retention stage during ongoing WM tasks (i.e., online WM) by training on the whole-brain network level. Therefore, combining EEG coherence and graph theory analysis, the present study examined the topological changes of WM networks before and after training based on the whole brain and constructed differential networks with different frequency band oscillations (i.e., theta, alpha, and beta). The results showed that after WM training, the subjects' WM networks had higher clustering coefficients and shorter optimal path lengths than before training during the retention period. Moreover, the increased synchronization of the frontal theta oscillations seemed to reflect the improved executive ability of WM and the more mature resource deployment; the enhanced alpha oscillatory synchronization in the frontoparietal and fronto-occipital regions may reflect the enhanced ability to suppress irrelevant information during the delay and pay attention to memory guidance; the enhanced beta oscillatory synchronization in the temporoparietal and frontoparietal regions may indicate active memory maintenance and preparation for memory-guided attention. The findings may add new evidence to understand the neural mechanisms of WM on the changes of network topological attributes in the task-related mode.},
  pmcid = {PMC8007374},
  keywords = {Alpha Rhythm/physiology,Beta Rhythm/physiology,Brain Waves/*physiology,Brain/*physiology,Electroencephalography/methods,Humans,Male,{Memory, Short-Term/*physiology},Nerve Net/*physiology,Photic Stimulation/methods,Theta Rhythm/physiology,Young Adult}
}

@book{TongJiXueXiFangFa,
  title = {统计学习方法},
  file = {D:\Zotero Storage\Zotero\storage\VRVU7CQ2\统计学习方法(李航).pdf}
}

@article{umakanthaBridgingNeuronalCorrelations2021,
  title = {Bridging Neuronal Correlations and Dimensionality Reduction},
  author = {Umakantha, A. and Morina, R. and Cowley, B. R. and Snyder, A. C. and Smith, M. A. and Yu, B. M.},
  date = {2021-09-01},
  journaltitle = {Neuron},
  volume = {109},
  number = {17},
  pages = {2740-2754 e12},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2021.06.028},
  abstract = {Two commonly used approaches to study interactions among neurons are spike count correlation, which describes pairs of neurons, and dimensionality reduction, applied to a population of neurons. Although both approaches have been used to study trial-to-trial neuronal variability correlated among neurons, they are often used in isolation and have not been directly related. We first established concrete mathematical and empirical relationships between pairwise correlation and metrics of population-wide covariability based on dimensionality reduction. Applying these insights to macaque V4 population recordings, we found that the previously reported decrease in mean pairwise correlation associated with attention stemmed from three distinct changes in population-wide covariability. Overall, our work builds the intuition and formalism to bridge between pairwise correlation and population-wide covariability and presents a cautionary tale about the inferences one can make about population activity by using a single statistic, whether it be mean pairwise correlation or dimensionality.},
  pmcid = {PMC8505167},
  keywords = {{*Models, Neurological},*Spatial Processing,Action Potentials,Animals,Attention,dimensionality reduction,Macaca mulatta,neuronal population,Neurons/*physiology,spatial attention,spike count correlation,visual area V4,Visual Cortex/cytology/*physiology}
}

@inproceedings{valenteExtractingComputationalMechanisms2022,
  title = {Extracting Computational Mechanisms from Neural Data Using Low-Rank {{RNNs}}},
  author = {Valente, Adrian and Pillow, Jonathan W. and Ostojic, Srdjan},
  date = {2022-05-16},
  url = {https://openreview.net/forum?id=M12autRxeeS},
  urldate = {2023-09-15},
  abstract = {An influential framework within systems neuroscience posits that neural computations can be understood in terms of low-dimensional dynamics in recurrent circuits. A number of methods have thus been developed to extract latent dynamical systems from neural recordings, but inferring models that are both predictive and interpretable remains a difficult challenge. Here we propose a new method called Low-rank Inference from Neural Trajectories (LINT), based on a class of low-rank recurrent neural networks (lrRNNs) for which a link between connectivity and dynamics has been previously demonstrated. By fitting such networks to trajectories of neural activity, LINT yields a mechanistic model of latent dynamics, as well as a set of axes for dimensionality reduction and verifiable predictions for inactivations of specific populations of neurons. Here, we first demonstrate the consistency of our method and apply it to two use cases: (i) we reverse-engineer "black-box" vanilla RNNs trained to perform cognitive tasks, and (ii) we infer latent dynamics and neural contributions from electrophysiological recordings of nonhuman primates performing a similar task.},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\8RHZWLKL\Valente et al. - 2022 - Extracting computational mechanisms from neural da.pdf}
}

@article{vanedeMnemonicAttentionalRoles2018,
  title = {Mnemonic and Attentional Roles for States of Attenuated Alpha Oscillations in Perceptual Working Memory: A Review},
  author = {family=Ede, given=F., prefix=van, useprefix=true},
  date = {2018-10},
  journaltitle = {Eur J Neurosci},
  volume = {48},
  number = {7},
  pages = {2509--2515},
  issn = {1460-9568 (Electronic) 0953-816X (Linking)},
  doi = {10.1111/ejn.13759},
  abstract = {Alpha oscillations are often reported to be amplified during working memory (WM) retention, serving to disengage sensory areas to protect internal representations from external interference. At the same time, contemporary views of WM postulate that sensory areas may often also be recruited for retention. I here review recent evidence that during such 'perceptual' WM, alpha oscillations in mnemonically relevant sensory areas are not amplified but attenuated instead. I will argue that such attenuated alpha states serve a mnemonic role and, further, that larger attenuation may support item-specific attentional prioritisation within perceptual WM. In critically evaluating this role, I also consider (and argue against) four alternatives to a strictly mnemonic account of the available data that may also prove useful to consider in future research. Finally, I highlight key implications of these data for the study of WM and for our understanding of the functional roles of states of attenuated alpha oscillations in cognition.},
  pmcid = {PMC6220786},
  keywords = {*attentional prioritisation,*electroencephalography,*neuronal oscillations,*sensory recruitment,*working memory retention,Alpha Rhythm/*physiology,Animals,Attention/*physiology,Brain Mapping/methods,Cognition/physiology,Humans,{Memory, Short-Term/*physiology},Visual Perception/*physiology}
}

@article{vanveenLocalizationBrainElectrical1997,
  title = {Localization of Brain Electrical Activity via Linearly Constrained Minimum Variance Spatial Filtering},
  author = {Van Veen, B.D. and Van Drongelen, W. and Yuchtman, M. and Suzuki, A.},
  date = {1997-09},
  journaltitle = {IEEE Transactions on Biomedical Engineering},
  volume = {44},
  number = {9},
  pages = {867--880},
  issn = {1558-2531},
  doi = {10.1109/10.623056},
  url = {https://ieeexplore.ieee.org/abstract/document/623056?casa_token=cXSME_AGtNoAAAAA:Kd8uZbgIjiKkaQ_50wzbbZXqE-SFEDDmZHWm6b3QLaUs2nr_RlCZuBbCPXqu85WfG7JDDwK18zsw},
  urldate = {2023-12-06},
  abstract = {A spatial filtering method for localizing sources of brain electrical activity from surface recordings is described and analyzed. The spatial filters are implemented as a weighted sum of the data recorded at different sites. The weights are chosen to minimize the filter output power subject to a linear constraint. The linear constraint forces the filter to pass brain electrical activity from a specified location, while the power minimization attenuates activity originating at other locations. The estimated output power as a function of location is normalized by the estimated noise power as a function of location to obtain a neural activity index map. Locations of source activity correspond to maxima in the neural activity index map. The method does not require any prior assumptions about the number of active sources of their geometry because it exploits the spatial covariance of the source electrical activity. This paper presents a development and analysis of the method and explores its sensitivity to deviations between actual and assumed data models. The effect on the algorithm of covariance matrix estimation, correlation between sources, and choice of reference is discussed. Simulated and measured data is used to illustrate the efficacy of the approach.},
  eventtitle = {{{IEEE Transactions}} on {{Biomedical Engineering}}},
  keywords = {Beamformer,MEG,Source Localization},
  file = {D:\Zotero Storage\Zotero\storage\SVCTTL4R\Van Veen 等 - 1997 - Localization of brain electrical activity via line.pdf}
}

@article{wangCoordinationEscapeSpatial2021,
  title = {Coordination of Escape and Spatial Navigation Circuits Orchestrates Versatile Flight from Threats},
  author = {Wang, W. and Schuette, P. J. and Nagai, J. and Tobias, B. C. and Cuccovia, V. Reis F. M. and Ji, S. and family=Lima, given=M. A. X., prefix=de, useprefix=true and La-Vu, M. Q. and Maesta-Pereira, S. and Chakerian, M. and Leonard, S. J. and Lin, L. and Severino, A. L. and Cahill, C. M. and Canteras, N. S. and Khakh, B. S. and Kao, J. C. and Adhikari, A.},
  date = {2021-06-02},
  journaltitle = {Neuron},
  volume = {109},
  number = {11},
  pages = {1848-1860 e8},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2021.03.033},
  abstract = {Naturalistic escape requires versatile context-specific flight with rapid evaluation of local geometry to identify and use efficient escape routes. It is unknown how spatial navigation and escape circuits are recruited to produce context-specific flight. Using mice, we show that activity in cholecystokinin-expressing hypothalamic dorsal premammillary nucleus (PMd-cck) cells is sufficient and necessary for context-specific escape that adapts to each environment's layout. In contrast, numerous other nuclei implicated in flight only induced stereotyped panic-related escape. We reasoned the dorsal premammillary nucleus (PMd) can induce context-specific escape because it projects to escape and spatial navigation nuclei. Indeed, activity in PMd-cck projections to thalamic spatial navigation circuits is necessary for context-specific escape induced by moderate threats but not panic-related stereotyped escape caused by perceived asphyxiation. Conversely, the PMd projection to the escape-inducing dorsal periaqueductal gray projection is necessary for all tested escapes. Thus, PMd-cck cells control versatile flight, engaging spatial navigation and escape circuits.},
  pmcid = {PMC8178241},
  keywords = {*anterior medial ventral thalamus,*calcium imaging,*Dorsal premammillary nucleus,*Dorsolateral periaqueductal gray,*Escape,*Escape Reaction,*Fear,*hypercapnia,*optogenetics,*Panic,*Predator,*Spatial Navigation,Animals,Female,{Hypothalamus, Posterior/*physiology},Male,Mice,{Mice, Inbred C57BL},Neural Pathways/physiology,Periaqueductal Gray/*physiology,Rats,{Rats, Long-Evans},Thalamus/*physiology}
}

@article{wangSegregationIntegrationBalance2021,
  title = {Segregation, Integration, and Balance of Large-Scale Resting Brain Networks Configure Different Cognitive Abilities},
  author = {Wang, Rong and Liu, Mianxin and Cheng, Xinhong and Wu, Ying and Hildebrandt, Andrea and Zhou, Changsong},
  date = {2021-06-08},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {118},
  number = {23},
  pages = {e2022288118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2022288118},
  url = {https://pnas.org/doi/full/10.1073/pnas.2022288118},
  urldate = {2023-08-20},
  abstract = {Significance             Mastering diverse cognitive tasks is crucial for humans. We study how the brain’s functional organization at rest is configured to support diverse cognitive phenotypes. Emphasizing the multilevel, hierarchical modular structure of brain’s functional connectivity to derive eigenmode-based measures, we demonstrate that the resting brain’s functional organization in healthy young adults is configured to maintain a balance between network segregation and integration. This functional balance is associated with better memory. Furthermore, brains tending toward stronger segregation versus integration foster different cognitive abilities. Thus, the segregation–integration balance empowers the brain to support diverse cognitive abilities. These findings yield high potential to understand the role of whole-brain resting state dynamics in human cognition and to develop neural biomarkers of atypical cognition.           ,                             Diverse cognitive processes set different demands on locally segregated and globally integrated brain activity. However, it remains an open question how resting brains configure their functional organization to balance the demands on network segregation and integration to best serve cognition. Here we use an eigenmode-based approach to identify hierarchical modules in functional brain networks and quantify the functional balance between network segregation and integration. In a large sample of healthy young adults (                                                   n                                               = 991), we combine the whole-brain resting state functional magnetic resonance imaging (fMRI) data with a mean-filed model on the structural network derived from diffusion tensor imaging and demonstrate that resting brain networks are on average close to a balanced state. This state allows for a balanced time dwelling at segregated and integrated configurations and highly flexible switching between them. Furthermore, we employ structural equation modeling to estimate general and domain-specific cognitive phenotypes from nine tasks and demonstrate that network segregation, integration, and their balance in resting brains predict individual differences in diverse cognitive phenotypes. More specifically, stronger integration is associated with better general cognitive ability, stronger segregation fosters crystallized intelligence and processing speed, and an individual’s tendency toward balance supports better memory. Our findings provide a comprehensive and deep understanding of the brain’s functioning principles in supporting diverse functional demands and cognitive abilities and advance modern network neuroscience theories of human cognition.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@wangSegregationIntegrationBalance2021.md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\Summary\\@wangSegregationIntegrationBalance2021.md;D\:\\Zotero Storage\\Zotero\\storage\\EP5ZIIBC\\Wang et al. - 2021 - Segregation, integration, and balance of large-sca.pdf}
}

@article{watanabePairwiseMaximumEntropy2013,
  title = {A Pairwise Maximum Entropy Model Accurately Describes Resting-State Human Brain Networks},
  author = {Watanabe, Takamitsu and Hirose, Satoshi and Wada, Hiroyuki and Imai, Yoshio and Machida, Toru and Shirouzu, Ichiro and Konishi, Seiki and Miyashita, Yasushi and Masuda, Naoki},
  date = {2013-01-22},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {4},
  number = {1},
  pages = {1370},
  issn = {2041-1723},
  doi = {10.1038/ncomms2388},
  url = {https://www.nature.com/articles/ncomms2388},
  urldate = {2023-08-19},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@watanabePairwiseMaximumEntropy2013.md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@watanabePairwiseMaximumEntropy2013.md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\watanabePairwiseMaximumEntropy2013 - Annotations (8192023, 93350 PM).md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\watanabePairwiseMaximumEntropy2013 - Annotations (8202023, 42856 PM).md;D\:\\Zotero Storage\\Web Storage\\02-Reading\\Summary\\@watanabePairwiseMaximumEntropy2013.md;D\:\\Zotero Storage\\Zotero\\storage\\4M96KZ3I\\watanabe2013.pdf.pdf;D\:\\Zotero Storage\\Zotero\\storage\\I4JVM29D\\Watanabe et al. - 2013 - A pairwise maximum entropy model accurately descri.pdf}
}

@article{watanabePairwiseMaximumEntropy2013a,
  title = {A Pairwise Maximum Entropy Model Accurately Describes Resting-State Human Brain Networks},
  author = {Watanabe, Takamitsu and Hirose, Satoshi and Wada, Hiroyuki and Imai, Yoshio and Machida, Toru and Shirouzu, Ichiro and Konishi, Seiki and Miyashita, Yasushi and Masuda, Naoki},
  date = {2013-01-22},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {4},
  number = {1},
  pages = {1370},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms2388},
  url = {https://www.nature.com/articles/ncomms2388},
  urldate = {2023-08-19},
  abstract = {The resting-state human brain networks underlie fundamental cognitive functions and consist of complex interactions among brain regions. However, the level of complexity of the resting-state networks has not been quantified, which has prevented comprehensive descriptions of the brain activity as an integrative system. Here, we address this issue by demonstrating that a pairwise maximum entropy model, which takes into account region-specific activity rates and pairwise interactions, can be robustly and accurately fitted to resting-state human brain activities obtained by functional magnetic resonance imaging. Furthermore, to validate the approximation of the resting-state networks by the pairwise maximum entropy model, we show that the functional interactions estimated by the pairwise maximum entropy model reflect anatomical connexions more accurately than the conventional functional connectivity method. These findings indicate that a relatively simple statistical model not only captures the structure of the resting-state networks but also provides a possible method to derive physiological information about various large-scale brain networks.},
  issue = {1},
  langid = {english},
  keywords = {Network models,Neuronal physiology},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\X8SJPW7B\\Watanabe et al. - 2013 - A pairwise maximum entropy model accurately descri.pdf;D\:\\Zotero Storage\\Zotero\\storage\\ZLUN7LKJ\\watanabe2013.pdf.pdf}
}

@article{weigandProspectiveValidationThat2018,
  title = {Prospective {{Validation That Subgenual Connectivity Predicts Antidepressant Efficacy}} of {{Transcranial Magnetic Stimulation Sites}}},
  author = {Weigand, Anne and Horn, Andreas and Caballero, Ruth and Cooke, Danielle and Stern, Adam P. and Taylor, Stephan F. and Press, Daniel and Pascual-Leone, Alvaro and Fox, Michael D.},
  date = {2018-07-01},
  journaltitle = {Biological Psychiatry},
  shortjournal = {Biological Psychiatry},
  series = {Mechanisms of {{Depression}} and {{Antidepressant Treatment}}},
  volume = {84},
  number = {1},
  pages = {28--37},
  issn = {0006-3223},
  doi = {10.1016/j.biopsych.2017.10.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0006322317321583},
  urldate = {2023-09-25},
  abstract = {Background The optimal target in the dorsolateral prefrontal cortex for treating depression with repetitive transcranial magnetic stimulation (rTMS) remains unknown. Better efficacy has been associated with stimulation sites that are 1) more anterior and lateral and 2) more functionally connected to the subgenual cingulate. Here we prospectively test whether these factors predict response in individual patients. Methods A primary cohort (Boston, n~= 25) with medication-refractory depression underwent conventional open-label rTMS to the left dorsolateral prefrontal cortex. A secondary cohort (Michigan, n~= 16) underwent 4 weeks of sham followed by open-label rTMS for nonresponders (n~= 12). In each patient, the location of the stimulation site was recorded with frameless stereotaxy. Connectivity between each patient’s stimulation site and the subgenual cingulate was assessed using resting-state functional connectivity magnetic resonance imaging from a cohort of healthy subjects (n~= 1000) and confirmed using connectivity from patients with depression (n~= 38). Results In our primary cohort, antidepressant efficacy was predicted by stimulation sites that were both more anterolateral (r~= .51, p {$<$} .01) and more negatively correlated with the subgenual cingulate (r~=~−.55, p {$<$} .005). However, subgenual connectivity was the only independent predictor of response and the only factor to predict response to active (r~=~−.52, p {$<$} .05) but not sham rTMS in our secondary cohort. Conclusions This study provides prospective validation that functional connectivity between an individual’s rTMS cortical target and the subgenual cingulate predicts antidepressant response. Implications for improving the cortical rTMS target for depression are discussed.},
  keywords = {Depression,Dorsolateral prefrontal cortex,Resting-state functional connectivity,Subgenual cingulate,TMS,Transcranial magnetic stimulation},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\2-topics\\Depression&TMS\\weigandProspectiveValidationThat2018.md;D\:\\Zotero Storage\\Zotero\\storage\\G6YEVASQ\\Weigand 等 - 2018 - Prospective Validation That Subgenual Connectivity.pdf;D\:\\Zotero Storage\\Zotero\\storage\\GFJSBDIS\\S0006322317321583.html}
}

@article{weinForecastingBrainActivity2022,
  title = {Forecasting Brain Activity Based on Models of Spatiotemporal Brain Dynamics: {{A}} Comparison of Graph Neural Network Architectures},
  shorttitle = {Forecasting Brain Activity Based on Models of Spatiotemporal Brain Dynamics},
  author = {Wein, S. and Schüller, A. and Tomé, A. M. and Malloni, W. M. and Greenlee, M. W. and Lang, E. W.},
  date = {2022-07-01},
  journaltitle = {Network Neuroscience},
  volume = {6},
  number = {3},
  pages = {665--701},
  issn = {2472-1751},
  doi = {10.1162/netn_a_00252},
  url = {https://direct.mit.edu/netn/article/6/3/665/111069/Forecasting-brain-activity-based-on-models-of},
  urldate = {2023-09-26},
  abstract = {Comprehending the interplay between spatial and temporal characteristics of neural dynamics can contribute to our understanding of information processing in the human brain. Graph neural networks (GNNs) provide a new possibility to interpret graph-structured signals like those observed in complex brain networks. In our study we compare different spatiotemporal GNN architectures and study their ability to model neural activity distributions obtained in functional MRI (fMRI) studies. We evaluate the performance of the GNN models on a variety of scenarios in MRI studies and also compare it to a VAR model, which is currently often used for directed functional connectivity analysis. We show that by learning localized functional interactions on the anatomical substrate, GNN-based approaches are able to robustly scale to large network studies, even when available data are scarce. By including anatomical connectivity as the physical substrate for information propagation, such GNNs also provide a multimodal perspective on directed connectivity analysis, offering a novel possibility to investigate the spatiotemporal dynamics in brain networks.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\QBMJ7BDA\Wein 等 - 2022 - Forecasting brain activity based on models of spat.pdf}
}

@article{weinForecastingBrainActivity2022a,
  title = {Forecasting Brain Activity Based on Models of Spatiotemporal Brain Dynamics: {{A}} Comparison of Graph Neural Network Architectures},
  shorttitle = {Forecasting Brain Activity Based on Models of Spatiotemporal Brain Dynamics},
  author = {Wein, S. and Schüller, A. and Tomé, A. M. and Malloni, W. M. and Greenlee, M. W. and Lang, E. W.},
  date = {2022-07-01},
  journaltitle = {Network Neuroscience},
  volume = {6},
  number = {3},
  pages = {665--701},
  issn = {2472-1751},
  doi = {10.1162/netn_a_00252},
  url = {https://direct.mit.edu/netn/article/6/3/665/111069/Forecasting-brain-activity-based-on-models-of},
  urldate = {2023-10-06},
  abstract = {Comprehending the interplay between spatial and temporal characteristics of neural dynamics can contribute to our understanding of information processing in the human brain. Graph neural networks (GNNs) provide a new possibility to interpret graph-structured signals like those observed in complex brain networks. In our study we compare different spatiotemporal GNN architectures and study their ability to model neural activity distributions obtained in functional MRI (fMRI) studies. We evaluate the performance of the GNN models on a variety of scenarios in MRI studies and also compare it to a VAR model, which is currently often used for directed functional connectivity analysis. We show that by learning localized functional interactions on the anatomical substrate, GNN-based approaches are able to robustly scale to large network studies, even when available data are scarce. By including anatomical connectivity as the physical substrate for information propagation, such GNNs also provide a multimodal perspective on directed connectivity analysis, offering a novel possibility to investigate the spatiotemporal dynamics in brain networks.},
  langid = {english},
  file = {D:\Zotero Storage\Zotero\storage\IMB9QAKA\Wein 等 - 2022 - Forecasting brain activity based on models of spat.pdf}
}

@article{weiV4ShapeFeatures2018,
  title = {V4 Shape Features for Contour Representation and Object Detection},
  author = {Wei, Hui and Dong, Zheng and Wang, Luping},
  date = {2018-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {97},
  pages = {46--61},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2017.09.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608017302137},
  urldate = {2023-09-04},
  abstract = {Cortical area V4 lies in the middle of the visual pathway involved with object recognition. Neurons in V4 selectively respond to different curve fragments along the object contour. In this paper, we propose a computational model that captures the shape features extracted by V4 neurons. The computational model emulated the information processing mechanism in the visual cortex. It extracted curve segments that V4 neurons respond to and quantitatively represented features of the curve segments. The proposed V4 shape features could describe object contours accurately and efficiently. With quantitative evaluation using the MPEG7 shape dataset, we showed that complex shapes could be represented with a very limited number of V4 shape features. Based on V4 features, we further developed a self-organizing map neural network to learn object shape models. The shape model was defined by a group of V4 features with constraints on their spatial relationships. The model was evaluated in object detection experiments using ETHZ objects and INRIA horses datasets. The proposed model could learn to recognize objects by shapes and accurately outline the object contour in the images. Thus, this model provides insight into the neural mechanisms of shape-based object recognition.},
  keywords = {Contour representation,Object detection,Shape feature,V4}
}

@article{wienerIntrinsicRoleBeta2018,
  title = {An {{Intrinsic Role}} of {{Beta Oscillations}} in {{Memory}} for {{Time Estimation}}},
  author = {Wiener, M. and Parikh, A. and Krakow, A. and Coslett, H. B.},
  date = {2018-05-22},
  journaltitle = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {7992},
  issn = {2045-2322 (Electronic) 2045-2322 (Linking)},
  doi = {10.1038/s41598-018-26385-6},
  abstract = {The neural mechanisms underlying time perception are of vital importance to a comprehensive understanding of behavior and cognition. Recent work has suggested a supramodal role for beta oscillations in measuring temporal intervals. However, the precise function of beta oscillations and whether their manipulation alters timing has yet to be determined. To accomplish this, we first re-analyzed two, separate EEG datasets and demonstrate that beta oscillations are associated with the retention and comparison of a memory standard for duration. We next conducted a study of 20 human participants using transcranial alternating current stimulation (tACS), over frontocentral cortex, at alpha and beta frequencies, during a visual temporal bisection task, finding that beta stimulation exclusively shifts the perception of time such that stimuli are reported as longer in duration. Finally, we decomposed trialwise choice data with a drift diffusion model of timing, revealing that the shift in timing is caused by a change in the starting point of accumulation, rather than the drift rate or threshold. Our results provide evidence for the intrinsic involvement of beta oscillations in the perception of time, and point to a specific role for beta oscillations in the encoding and retention of memory for temporal intervals.},
  pmcid = {PMC5964239},
  keywords = {*Electroencephalography/psychology,Adult,Biological Clocks/*physiology,Cerebral Cortex/physiology,Cognition/physiology,Female,Humans,Male,Memory/*physiology,Neural Pathways/physiology,Psychomotor Performance/physiology,Time,Time Perception/*physiology,Transcranial Direct Current Stimulation,Young Adult}
}

@article{willettHighperformanceSpeechNeuroprosthesis2023,
  title = {A High-Performance Speech Neuroprosthesis},
  author = {Willett, Francis R. and Kunz, Erin M. and Fan, Chaofei and Avansino, Donald T. and Wilson, Guy H. and Choi, Eun Young and Kamdar, Foram and Glasser, Matthew F. and Hochberg, Leigh R. and Druckmann, Shaul and Shenoy, Krishna V. and Henderson, Jaimie M.},
  date = {2023-08},
  journaltitle = {Nature},
  volume = {620},
  number = {7976},
  pages = {1031--1036},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06377-x},
  url = {https://www.nature.com/articles/s41586-023-06377-x},
  urldate = {2023-08-31},
  abstract = {Speech brain–computer interfaces (BCIs) have the potential to restore rapid communication to people with paralysis by decoding neural activity evoked by attempted speech into text1,2 or sound3,4. Early demonstrations, although promising, have not yet achieved accuracies sufficiently high for communication of unconstrained sentences from a large vocabulary1–7. Here we demonstrate a speech-to-text BCI that records spiking activity from intracortical microelectrode arrays. Enabled by these high-resolution recordings, our study participant—who can no longer speak intelligibly owing to amyotrophic lateral sclerosis—achieved a 9.1\% word error rate on a 50-word vocabulary (2.7\,times fewer errors than the previous state-of-the-art speech BCI2) and a 23.8\% word error rate on a 125,000-word vocabulary (the first successful demonstration, to our knowledge, of large-vocabulary decoding). Our participant’s attempted speech was decoded~ at 62\,words per minute, which is 3.4\,times as fast as the previous record8 and begins to approach the speed of natural conversation (160\,words per minute9). Finally, we highlight two aspects of the neural code for speech that are encouraging for speech BCIs: spatially intermixed tuning to speech articulators that makes accurate decoding possible from only a small region of cortex, and a detailed articulatory representation of phonemes that persists years after paralysis. These results show a feasible path forward for~restoring rapid communication to people with paralysis who can no longer speak.},
  issue = {7976},
  langid = {english},
  keywords = {Brain–machine interface,Neural decoding},
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\Nature2023Willett et alA high-performance speech neuroprosthesisNature62079761031-1036CompNeuro_Literature\IsingWillettF et alFW et alJournal Article\2023_-A high-performance speech neuroprosthesis.pdf}
}

@article{wongRecurrentNetworkMechanism2006,
  title = {A {{Recurrent Network Mechanism}} of {{Time Integration}} in {{Perceptual Decisions}}},
  author = {Wong, Kong-Fatt and Wang, Xiao-Jing},
  date = {2006-01-25},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {26},
  number = {4},
  pages = {1314--1328},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3733-05.2006},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3733-05.2006},
  urldate = {2023-08-20},
  abstract = {Recent physiological studies using behaving monkeys revealed that, in a two-alternative forced-choice visual motion discrimination task, reaction time was correlated with ramping of spike activity of lateral intraparietal cortical neurons. The ramping activity appears to reflect temporal accumulation, on a timescale of hundreds of milliseconds, of sensory evidence before a decision is reached. To elucidate the cellular and circuit basis of such integration times, we developed and investigated a simplified two-variable version of a biophysically realistic cortical network model of decision making. In this model, slow time integration can be achieved robustly if excitatory reverberation is primarily mediated by NMDA receptors; our model with only fast AMPA receptors at recurrent synapses produces decision times that are not comparable with experimental observations. Moreover, we found two distinct modes of network behavior, in which decision computation by winner-take-all competition is instantiated with or without attractor states for working memory. Decision process is closely linked to the local dynamics, in the “decision space” of the system, in the vicinity of an unstable saddle steady state that separates the basins of attraction for the two alternative choices. This picture provides a rigorous and quantitative explanation for the dependence of performance and response time on the degree of task difficulty, and the reason for which reaction times are longer in error trials than in correct trials as observed in the monkey experiment. Our reduced two-variable neural model offers a simple yet biophysically plausible framework for studying perceptual decision making in general.},
  langid = {english},
  file = {D\:\\Zotero Storage\\Zotero\\storage\\6QI8KIJT\\wong2006.pdf.pdf;D\:\\Zotero Storage\\Zotero\\storage\\UIFYME26\\Wong and Wang - 2006 - A Recurrent Network Mechanism of Time Integration .pdf}
}

@article{xuCrossspeciesFunctionalAlignment2020,
  title = {Cross-Species Functional Alignment Reveals Evolutionary Hierarchy within the Connectome},
  author = {Xu, T. and Nenning, K. H. and Schwartz, E. and Hong, S. J. and Vogelstein, J. T. and Goulas, A. and Fair, D. A. and Schroeder, C. E. and Margulies, D. S. and Smallwood, J. and Milham, M. P. and Langs, G.},
  date = {2020-12},
  journaltitle = {Neuroimage},
  volume = {223},
  pages = {117346},
  issn = {1095-9572 (Electronic) 1053-8119 (Linking)},
  doi = {10.1016/j.neuroimage.2020.117346},
  abstract = {Evolution provides an important window into how cortical organization shapes function and vice versa. The complex mosaic of changes in brain morphology and functional organization that have shaped the mammalian cortex during evolution, complicates attempts to chart cortical differences across species. It limits our ability to fully appreciate how evolution has shaped our brain, especially in systems associated with unique human cognitive capabilities that lack anatomical homologues in other species. Here, we develop a function-based method for cross-species alignment that enables the quantification of homologous regions between humans and rhesus macaques, even when their location is decoupled from anatomical landmarks. Critically, we find cross-species similarity in functional organization reflects a gradient of evolutionary change that decreases from unimodal systems and culminates with the most pronounced changes in posterior regions of the default mode network (angular gyrus, posterior cingulate and middle temporal cortices). Our findings suggest that the establishment of the default mode network, as the apex of a cognitive hierarchy, has changed in a complex manner during human evolution - even within subnetworks.},
  pmcid = {PMC7871099},
  keywords = {*Biological Evolution,*Magnetic Resonance Imaging,Animals,Cerebral Cortex/*physiology,Connectome/*methods,Cross-species alignment,Default mode network,Evolution,Hierarchy,Humans,Joint embedding,Macaca mulatta,Neural Pathways/physiology,Species Specificity}
}

@article{xue2021,
  author = {Xue, Xiaohe and Halassa, Michael M. and Chen, Zhe S.},
  date = {2021},
  doi = {10.1101/2021.01.21.427464}
}

@article{yanModelingSpatiotemporalPatterns2022,
  title = {Modeling Spatio-Temporal Patterns of Holistic Functional Brain Networks via Multi-Head Guided Attention Graph Neural Networks ({{Multi-Head GAGNNs}})},
  author = {Yan, Jiadong and Chen, Yuzhong and Xiao, Zhenxiang and Zhang, Shu and Jiang, Mingxin and Wang, Tianqi and Zhang, Tuo and Lv, Jinglei and Becker, Benjamin and Zhang, Rong and Zhu, Dajiang and Han, Junwei and Yao, Dezhong and Kendrick, Keith M. and Liu, Tianming and Jiang, Xi},
  date = {2022-08-01},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {80},
  pages = {102518},
  issn = {1361-8415},
  doi = {10.1016/j.media.2022.102518},
  url = {https://www.sciencedirect.com/science/article/pii/S1361841522001657},
  urldate = {2023-09-26},
  abstract = {Mounting evidence has demonstrated that complex brain function processes are realized by the interaction of holistic functional brain networks which are spatially distributed across specific brain regions in a temporally dynamic fashion. Therefore, modeling spatio-temporal patterns of holistic functional brain networks plays an important role in understanding brain function. Compared to traditional modeling methods such as principal component analysis, independent component analysis, and sparse coding, superior performance has been achieved by recent deep learning methodologies. However, there are still two limitations of existing deep learning approaches for functional brain network modeling. They either (1) merely modeled a single targeted network and ignored holistic ones at one time, or (2) underutilized both spatial and temporal features of fMRI during network modeling, and the spatial/temporal accuracy was thus not warranted. To address these limitations, we proposed a novel Multi-Head Guided Attention Graph Neural Network (Multi-Head GAGNN) to simultaneously model both spatial and temporal patterns of holistic functional brain networks. Specifically, a spatial Multi-Head Attention Graph U-Net was first adopted to model the spatial patterns of multiple brain networks, and a temporal Multi-Head Guided Attention Network was then introduced to model the corresponding temporal patterns under the guidance of modeled spatial patterns. Based on seven task fMRI datasets from the public Human Connectome Project and resting state fMRI datasets from the public Autism Brain Imaging Data Exchange I of 1448 subjects, the proposed Multi-Head GAGNN showed superior ability and generalizability in modeling both spatial and temporal patterns of holistic functional brain networks in individual brains compared to other state-of-the-art (SOTA) models. Furthermore, the modeled spatio-temporal patterns of functional brain networks via the proposed Multi-Head GAGNN can better predict the individual cognitive behavioral measures compared to the other SOTA models. This study provided a novel and powerful tool for brain function modeling as well as for understanding the brain-cognitive behavior associations.},
  keywords = {Functional brain network,Graph convolution,Multi-Head Guided Attention,Spatio-temporal pattern},
  file = {D:\Zotero Storage\Zotero\storage\B7U8RSIW\Yan 等 - 2022 - Modeling spatio-temporal patterns of holistic func.pdf}
}

@article{yanModelingSpatiotemporalPatterns2022a,
  title = {Modeling Spatio-Temporal Patterns of Holistic Functional Brain Networks via Multi-Head Guided Attention Graph Neural Networks ({{Multi-Head GAGNNs}})},
  author = {Yan, Jiadong and Chen, Yuzhong and Xiao, Zhenxiang and Zhang, Shu and Jiang, Mingxin and Wang, Tianqi and Zhang, Tuo and Lv, Jinglei and Becker, Benjamin and Zhang, Rong and Zhu, Dajiang and Han, Junwei and Yao, Dezhong and Kendrick, Keith M. and Liu, Tianming and Jiang, Xi},
  date = {2022-08-01},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {80},
  pages = {102518},
  issn = {1361-8415},
  doi = {10.1016/j.media.2022.102518},
  url = {https://www.sciencedirect.com/science/article/pii/S1361841522001657},
  urldate = {2023-10-10},
  abstract = {Mounting evidence has demonstrated that complex brain function processes are realized by the interaction of holistic functional brain networks which are spatially distributed across specific brain regions in a temporally dynamic fashion. Therefore, modeling spatio-temporal patterns of holistic functional brain networks plays an important role in understanding brain function. Compared to traditional modeling methods such as principal component analysis, independent component analysis, and sparse coding, superior performance has been achieved by recent deep learning methodologies. However, there are still two limitations of existing deep learning approaches for functional brain network modeling. They either (1) merely modeled a single targeted network and ignored holistic ones at one time, or (2) underutilized both spatial and temporal features of fMRI during network modeling, and the spatial/temporal accuracy was thus not warranted. To address these limitations, we proposed a novel Multi-Head Guided Attention Graph Neural Network (Multi-Head GAGNN) to simultaneously model both spatial and temporal patterns of holistic functional brain networks. Specifically, a spatial Multi-Head Attention Graph U-Net was first adopted to model the spatial patterns of multiple brain networks, and a temporal Multi-Head Guided Attention Network was then introduced to model the corresponding temporal patterns under the guidance of modeled spatial patterns. Based on seven task fMRI datasets from the public Human Connectome Project and resting state fMRI datasets from the public Autism Brain Imaging Data Exchange I of 1448 subjects, the proposed Multi-Head GAGNN showed superior ability and generalizability in modeling both spatial and temporal patterns of holistic functional brain networks in individual brains compared to other state-of-the-art (SOTA) models. Furthermore, the modeled spatio-temporal patterns of functional brain networks via the proposed Multi-Head GAGNN can better predict the individual cognitive behavioral measures compared to the other SOTA models. This study provided a novel and powerful tool for brain function modeling as well as for understanding the brain-cognitive behavior associations.},
  keywords = {Functional brain network,Graph convolution,Multi-Head Guided Attention,Spatio-temporal pattern},
  file = {D:\Zotero Storage\Zotero\storage\8BPLYRZR\S1361841522001657.html}
}

@article{yanReducedDefaultMode2019,
  title = {Reduced Default Mode Network Functional Connectivity in Patients with Recurrent Major Depressive Disorder},
  author = {Yan, Chao-Gan and Chen, Xiao and Li, Le and Castellanos, Francisco Xavier and Bai, Tong-Jian and Bo, Qi-Jing and Cao, Jun and Chen, Guan-Mao and Chen, Ning-Xuan and Chen, Wei and Cheng, Chang and Cheng, Yu-Qi and Cui, Xi-Long and Duan, Jia and Fang, Yi-Ru and Gong, Qi-Yong and Guo, Wen-Bin and Hou, Zheng-Hua and Hu, Lan and Kuang, Li and Li, Feng and Li, Kai-Ming and Li, Tao and Liu, Yan-Song and Liu, Zhe-Ning and Long, Yi-Cheng and Luo, Qing-Hua and Meng, Hua-Qing and Peng, Dai-Hui and Qiu, Hai-Tang and Qiu, Jiang and Shen, Yue-Di and Shi, Yu-Shu and Wang, Chuan-Yue and Wang, Fei and Wang, Kai and Wang, Li and Wang, Xiang and Wang, Ying and Wu, Xiao-Ping and Wu, Xin-Ran and Xie, Chun-Ming and Xie, Guang-Rong and Xie, Hai-Yan and Xie, Peng and Xu, Xiu-Feng and Yang, Hong and Yang, Jian and Yao, Jia-Shu and Yao, Shu-Qiao and Yin, Ying-Ying and Yuan, Yong-Gui and Zhang, Ai-Xia and Zhang, Hong and Zhang, Ke-Rang and Zhang, Lei and Zhang, Zhi-Jun and Zhou, Ru-Bai and Zhou, Yi-Ting and Zhu, Jun-Juan and Zou, Chao-Jie and Si, Tian-Mei and Zuo, Xi-Nian and Zhao, Jing-Ping and Zang, Yu-Feng},
  date = {2019-04-30},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {18},
  pages = {9078--9083},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1900390116},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.1900390116},
  urldate = {2023-11-15},
  abstract = {Major depressive disorder (MDD) is common and disabling, but its neuropathophysiology remains unclear. Most studies of functional brain networks in MDD have had limited statistical power and data analysis approaches have varied widely. The REST-meta-MDD Project of resting-state fMRI (R-fMRI) addresses these issues. Twenty-five research groups in China established the REST-meta-MDD Consortium by contributing R-fMRI data from 1,300 patients with MDD and 1,128 normal controls (NCs). Data were preprocessed locally with a standardized protocol before aggregated group analyses. We focused on functional connectivity (FC) within the default mode network (DMN), frequently reported to be increased in MDD. Instead, we found decreased DMN FC when we compared 848 patients with MDD to 794 NCs from 17 sites after data exclusion. We found FC reduction only in recurrent MDD, not in first-episode drug-naïve MDD. Decreased DMN FC was associated with medication usage but not with MDD duration. DMN FC was also positively related to symptom severity but only in recurrent MDD. Exploratory analyses also revealed alterations in FC of visual, sensory-motor, and dorsal attention networks in MDD. We confirmed the key role of DMN in MDD but found reduced rather than increased FC within the DMN. Future studies should test whether decreased DMN FC mediates response to treatment. All R-fMRI indices of data contributed by the REST-meta-MDD consortium are being shared publicly via the R-fMRI Maps Project.},
  file = {D:\Zotero Storage\Zotero\storage\4NN7BNZ5\Yan 等 - 2019 - Reduced default mode network functional connectivi.pdf}
}

@article{youngUncoveringHeterogeneityTemporal2018,
  title = {Uncovering the Heterogeneity and Temporal Complexity of Neurodegenerative Diseases with {{Subtype}} and {{Stage Inference}}},
  author = {Young, Alexandra L. and Marinescu, Razvan V. and Oxtoby, Neil P. and Bocchetta, Martina and Yong, Keir and Firth, Nicholas C. and Cash, David M. and Thomas, David L. and Dick, Katrina M. and Cardoso, Jorge and family=Swieten, given=John, prefix=van, useprefix=true and Borroni, Barbara and Galimberti, Daniela and Masellis, Mario and Tartaglia, Maria Carmela and Rowe, James B. and Graff, Caroline and Tagliavini, Fabrizio and Frisoni, Giovanni B. and Laforce, Robert and Finger, Elizabeth and family=Mendonça, given=Alexandre, prefix=de, useprefix=true and Sorbi, Sandro and Warren, Jason D. and Crutch, Sebastian and Fox, Nick C. and Ourselin, Sebastien and Schott, Jonathan M. and Rohrer, Jonathan D. and Alexander, Daniel C.},
  date = {2018-10-15},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {4273},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05892-0},
  url = {https://www.nature.com/articles/s41467-018-05892-0},
  urldate = {2023-10-25},
  abstract = {The heterogeneity of neurodegenerative diseases is a key confound to disease understanding and treatment development, as study cohorts typically include multiple phenotypes on distinct disease trajectories. Here we introduce a machine-learning technique—Subtype and Stage Inference (SuStaIn)—able to uncover data-driven disease phenotypes with distinct temporal progression patterns, from widely available cross-sectional patient studies. Results from imaging studies in two neurodegenerative diseases reveal subgroups and their distinct trajectories of regional neurodegeneration. In genetic frontotemporal dementia, SuStaIn identifies genotypes from imaging alone, validating its ability to identify subtypes; further the technique reveals within-genotype heterogeneity. In Alzheimer’s disease, SuStaIn uncovers three subtypes, uniquely characterising their temporal complexity. SuStaIn provides fine-grained patient stratification, which substantially enhances the ability to predict conversion between diagnostic categories over standard models that ignore subtype (p\,=\,7.18\,×\,10−4) or temporal stage (p\,=\,3.96\,×\,10−5). SuStaIn offers new promise for enabling disease subtype discovery and precision medicine.},
  issue = {1},
  langid = {english},
  keywords = {Computer science,Neurodegenerative diseases},
  file = {D:\Zotero Storage\Zotero\storage\A427G3DA\Young 等 - 2018 - Uncovering the heterogeneity and temporal complexi.pdf}
}

@article{yuanSituBidirectionalHumanrobot2022,
  title = {In Situ Bidirectional Human-Robot Value Alignment},
  author = {Yuan, Luyao and Gao, Xiaofeng and Zheng, Zilong and Edmonds, Mark and Wu, Ying Nian and Rossano, Federico and Lu, Hongjing and Zhu, Yixin and family=Zhu, given=Song-Chun \%J Science, prefix=robotics, useprefix=false},
  date = {2022},
  volume = {7},
  number = {68},
  pages = {eabm4183},
  issn = {2470-9476}
}

@article{yuVisualCortexEncodes2022,
  title = {Visual Cortex Encodes Timing Information in Humans and Mice},
  author = {Yu, Q. and Bi, Z. and Jiang, S. and Yan, B. and Chen, H. and Wang, Y. and Miao, Y. and Li, K. and Wei, Z. and Xie, Y. and Tan, X. and Liu, X. and Fu, H. and Cui, L. and Xing, L. and Weng, S. and Wang, X. and Yuan, Y. and Zhou, C. and Wang, G. and Li, L. and Ma, L. and Mao, Y. and Chen, L. and Zhang, J.},
  date = {2022-12-21},
  journaltitle = {Neuron},
  volume = {110},
  number = {24},
  pages = {4194-4211 e10},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2022.09.008},
  abstract = {Despite the importance of timing in our daily lives, our understanding of how the human brain mediates second-scale time perception is limited. Here, we combined intracranial stereoelectroencephalography (SEEG) recordings in epileptic patients and circuit dissection in mice to show that visual cortex (VC) encodes timing information. We first asked human participants to perform an interval-timing task and found VC to be a key timing brain area. We then conducted optogenetic experiments in mice and showed that VC plays an important role in the interval-timing behavior. We further found that VC neurons fired in a time-keeping sequential manner and exhibited increased excitability in a timed manner. Finally, we used a computational model to illustrate a self-correcting learning process that generates interval-timed activities with scalar-timing property. Our work reveals how localized oscillations in VC occurring in the seconds to deca-seconds range relate timing information from the external world to guide behavior.},
  keywords = {*Time Perception/physiology,*Visual Cortex/physiology,Animals,human visual cortex,Humans,Learning,Mice,mouse visual cortex,Neurons/physiology,Seeg,Time Factors,time-keeping sequence,timing}
}

@article{yuVisualCortexEncodes2022a,
  title = {Visual Cortex Encodes Timing Information in Humans and Mice},
  author = {Yu, Qingpeng and Bi, Zedong and Jiang, Shize and Yan, Biao and Chen, Heming and Wang, Yiting and Miao, Yizhan and Li, Kexin and Wei, Zixuan and Xie, Yuanting and Tan, Xinrong and Liu, Xiaodi and Fu, Hang and Cui, Liyuan and Xing, Lu and Weng, Shijun and Wang, Xin and Yuan, Yuanzhi and Zhou, Changsong and Wang, Gang and Li, Liang and Ma, Lan and Mao, Ying and Chen, Liang and Zhang, Jiayi},
  date = {2022-12},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {24},
  pages = {4194-4211.e10},
  issn = {08966273},
  doi = {10.1016/j.neuron.2022.09.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627322008133},
  urldate = {2023-08-21},
  langid = {english},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\@yuVisualCortexEncodes2022a.md;D\:\\Zotero Storage\\Zotero\\storage\\DKSDCAH4\\Yu et al. - 2022 - Visual cortex encodes timing information in humans.pdf}
}

@article{zhaoPupillinkedPhasicArousal2019,
  title = {Pupil-Linked Phasic Arousal Evoked by Violation but Not Emergence of Regularity within Rapid Sound Sequences},
  author = {Zhao, S. and Chait, M. and Dick, F. and Dayan, P. and Furukawa, S. and Liao, H. I.},
  date = {2019-09-06},
  journaltitle = {Nat Commun},
  volume = {10},
  number = {1},
  pages = {4030},
  issn = {2041-1723 (Electronic) 2041-1723 (Linking)},
  doi = {10.1038/s41467-019-12048-1},
  abstract = {The ability to track the statistics of our surroundings is a key computational challenge. A prominent theory proposes that the brain monitors for unexpected uncertainty - events which deviate substantially from model predictions, indicating model failure. Norepinephrine is thought to play a key role in this process by serving as an interrupt signal, initiating model-resetting. However, evidence is from paradigms where participants actively monitored stimulus statistics. To determine whether Norepinephrine routinely reports the statistical structure of our surroundings, even when not behaviourally relevant, we used rapid tone-pip sequences that contained salient pattern-changes associated with abrupt structural violations vs. emergence of regular structure. Phasic pupil dilations (PDR) were monitored to assess Norepinephrine. We reveal a remarkable specificity: When not behaviourally relevant, only abrupt structural violations evoke a PDR. The results demonstrate that Norepinephrine tracks unexpected uncertainty on rapid time scales relevant to sensory signals.},
  pmcid = {PMC6731273},
  keywords = {*Sound,Acoustic Stimulation,Adult,Arousal/*physiology,Brain/metabolism/physiology,{Evoked Potentials, Auditory/*physiology},Female,Humans,Male,Norepinephrine/metabolism,Psychomotor Performance/*physiology,Pupil/*physiology,Reaction Time/*physiology,Uncertainty,Young Adult}
}

@article{zhaoRapidOcularResponses2019,
  title = {Rapid {{Ocular Responses Are Modulated}} by {{Bottom-up-Driven Auditory Salience}}},
  author = {Zhao, S. and Yum, N. W. and Benjamin, L. and Benhamou, E. and Yoneya, M. and Furukawa, S. and Dick, F. and Slaney, M. and Chait, M.},
  date = {2019-09-25},
  journaltitle = {J Neurosci},
  volume = {39},
  number = {39},
  pages = {7703--7714},
  issn = {1529-2401 (Electronic) 0270-6474 (Print) 0270-6474 (Linking)},
  doi = {10.1523/JNEUROSCI.0776-19.2019},
  abstract = {Despite the prevalent use of alerting sounds in alarms and human-machine interface systems and the long-hypothesized role of the auditory system as the brain's "early warning system," we have only a rudimentary understanding of what determines auditory salience-the automatic attraction of attention by sound-and which brain mechanisms underlie this process. A major roadblock has been the lack of a robust, objective means of quantifying sound-driven attentional capture. Here we demonstrate that: (1) a reliable salience scale can be obtained from crowd-sourcing (N = 911), (2) acoustic roughness appears to be a driving feature behind this scaling, consistent with previous reports implicating roughness in the perceptual distinctiveness of sounds, and (3) crowd-sourced auditory salience correlates with objective autonomic measures. Specifically, we show that a salience ranking obtained from online raters correlated robustly with the superior colliculus-mediated ocular freezing response, microsaccadic inhibition (MSI), measured in naive, passively listening human participants (of either sex). More salient sounds evoked earlier and larger MSI, consistent with a faster orienting response. These results are consistent with the hypothesis that MSI reflects a general reorienting response that is evoked by potentially behaviorally important events regardless of their modality.SIGNIFICANCE STATEMENT Microsaccades are small, rapid, fixational eye movements that are measurable with sensitive eye-tracking equipment. We reveal a novel, robust link between microsaccade dynamics and the subjective salience of brief sounds (salience rankings obtained from a large number of participants in an online experiment): Within 300 ms of sound onset, the eyes of naive, passively listening participants demonstrate different microsaccade patterns as a function of the sound's crowd-sourced salience. These results position the superior colliculus (hypothesized to underlie microsaccade generation) as an important brain area to investigate in the context of a putative multimodal salience hub. They also demonstrate an objective means for quantifying auditory salience.},
  pmcid = {PMC6764203},
  keywords = {Acoustic Stimulation,Adolescent,Adult,attention,Attention/*physiology,Auditory Perception/*physiology,auditory scene analysis,Crowdsourcing,Female,Humans,Male,microsaccades,pupil dilation,Saccades/*physiology,Superior Colliculi/*physiology,superior colliculus,Young Adult}
}

@article{zhaoRapidOcularResponses2019a,
  title = {Rapid {{Ocular Responses Are Modulated}} by {{Bottom-up-Driven Auditory Salience}}},
  author = {Zhao, S. and Yum, N. W. and Benjamin, L. and Benhamou, E. and Yoneya, M. and Furukawa, S. and Dick, F. and Slaney, M. and Chait, M.},
  date = {2019-09-25},
  journaltitle = {J Neurosci},
  volume = {39},
  number = {39},
  pages = {7703--7714},
  issn = {1529-2401 (Electronic) 0270-6474 (Print) 0270-6474 (Linking)},
  doi = {10.1523/JNEUROSCI.0776-19.2019},
  abstract = {Despite the prevalent use of alerting sounds in alarms and human-machine interface systems and the long-hypothesized role of the auditory system as the brain's "early warning system," we have only a rudimentary understanding of what determines auditory salience-the automatic attraction of attention by sound-and which brain mechanisms underlie this process. A major roadblock has been the lack of a robust, objective means of quantifying sound-driven attentional capture. Here we demonstrate that: (1) a reliable salience scale can be obtained from crowd-sourcing (N = 911), (2) acoustic roughness appears to be a driving feature behind this scaling, consistent with previous reports implicating roughness in the perceptual distinctiveness of sounds, and (3) crowd-sourced auditory salience correlates with objective autonomic measures. Specifically, we show that a salience ranking obtained from online raters correlated robustly with the superior colliculus-mediated ocular freezing response, microsaccadic inhibition (MSI), measured in naive, passively listening human participants (of either sex). More salient sounds evoked earlier and larger MSI, consistent with a faster orienting response. These results are consistent with the hypothesis that MSI reflects a general reorienting response that is evoked by potentially behaviorally important events regardless of their modality.SIGNIFICANCE STATEMENT Microsaccades are small, rapid, fixational eye movements that are measurable with sensitive eye-tracking equipment. We reveal a novel, robust link between microsaccade dynamics and the subjective salience of brief sounds (salience rankings obtained from a large number of participants in an online experiment): Within 300 ms of sound onset, the eyes of naive, passively listening participants demonstrate different microsaccade patterns as a function of the sound's crowd-sourced salience. These results position the superior colliculus (hypothesized to underlie microsaccade generation) as an important brain area to investigate in the context of a putative multimodal salience hub. They also demonstrate an objective means for quantifying auditory salience.},
  pmcid = {PMC6764203},
  keywords = {Acoustic Stimulation,Adolescent,Adult,attention,Attention/*physiology,Auditory Perception/*physiology,auditory scene analysis,Crowdsourcing,Female,Humans,Male,microsaccades,pupil dilation,Saccades/*physiology,Superior Colliculi/*physiology,superior colliculus,Young Adult}
}

@book{ZhouJiQiXueXi,
  title = {机器学习},
  author = {周, 志华},
  file = {D\:\\Zotero Storage\\Web Storage\\02-Reading\\mdnotes\\ZhouJiQiXueXi -.md;D\:\\Zotero Storage\\Zotero\\storage\\YRUZC7JK\\周志华-机器学习.pdf}
}

@article{zhouNeuralPopulationClocks2022,
  title = {Neural Population Clocks: {{Encoding}} Time in Dynamic Patterns of Neural Activity},
  author = {Zhou, S. and Buonomano, D. V.},
  date = {2022-10},
  journaltitle = {Behav Neurosci},
  volume = {136},
  number = {5},
  pages = {374--382},
  issn = {1939-0084 (Electronic) 0735-7044 (Linking)},
  doi = {10.1037/bne0000515},
  abstract = {The ability to predict and prepare for near- and far-future events is among the most fundamental computations the brain performs. Because of the importance of time for prediction and sensorimotor processing, the brain has evolved multiple mechanisms to tell and encode time across scales ranging from microseconds to days and beyond. Converging experimental and computational data indicate that, on the scale of seconds, timing relies on diverse neural mechanisms distributed across different brain areas. Among the different encoding mechanisms on the scale of seconds, we distinguish between neural population clocks and ramping activity as distinct strategies to encode time. One instance of neural population clocks, neural sequences, represents in some ways an optimal and flexible dynamic regime for the encoding of time. Specifically, neural sequences comprise a high-dimensional representation that can be used by downstream areas to flexibly generate arbitrarily simple and complex output patterns using biologically plausible learning rules. We propose that high-level integration areas may use high-dimensional dynamics such as neural sequences to encode time, providing downstream areas information to build low-dimensional ramp-like activity that can drive movements and temporal expectation. (PsycInfo Database Record (c) 2022 APA, all rights reserved).},
  pmcid = {PMC9561006},
  keywords = {*Brain,*Time Perception,Learning,{Models, Neurological}}
}

@article{zhouNeuralSequencesOptimal2020,
  title = {Neural {{Sequences}} as an {{Optimal Dynamical Regime}} for the {{Readout}} of {{Time}}},
  author = {Zhou, S. and Masmanidis, S. C. and Buonomano, D. V.},
  date = {2020-11-25},
  journaltitle = {Neuron},
  volume = {108},
  number = {4},
  pages = {651-658 e5},
  issn = {1097-4199 (Electronic) 0896-6273 (Linking)},
  doi = {10.1016/j.neuron.2020.08.020},
  abstract = {Converging evidence suggests that the brain encodes time through dynamically changing patterns of neural activity, including neural sequences, ramping activity, and complex spatiotemporal dynamics. However, the potential computational significance and advantage of these different regimes have remained unaddressed. We combined large-scale recordings and modeling to compare population dynamics between premotor cortex and striatum in mice performing a two-interval timing task. Conventional decoders revealed that the dynamics within each area encoded time equally well; however, the dynamics in striatum exhibited a higher degree of sequentiality. Analysis of premotor and striatal dynamics, together with a large set of simulated prototypical dynamical regimes, revealed that regimes with higher sequentiality allowed a biologically constrained artificial downstream network to better read out time. These results suggest that, although different strategies exist for encoding time in the brain, neural sequences represent an ideal and flexible dynamical regime for enabling downstream areas to read out this information.},
  pmcid = {PMC7825362},
  keywords = {*anticipatory timing,*computational model,*interval,{*Models, Neurological},*neural sequences,*neurocomputation,*striatum,*time,*timing,Action Potentials/physiology,Animals,Computer Simulation,Corpus Striatum/*physiology,Male,Mice,Motor Cortex/*physiology,Neurons/physiology,Time Perception/*physiology}
}

@article{zotero-125,
  title = {{$<$}{{NeurIPS-2021-a-mechanistic-multi-area-recurrent-network-model-of-decision-making-Paper}}.Pdf{$>$}}
}

@article{zotero-126,
  title = {{$<$}nips18\_{{MAB}}.Pdf{$>$}}
}

@article{zotero-1331,
  file = {D:\Zotero Storage\Web Storage\08-Assets\pdfs\CompNeuro_Literature\Machine LearningJournal Article\-.pdf}
}

@article{zotero-136,
  title = {{$<$}pnas.0901831106.Pdf{$>$}}
}

@article{zotero-162,
  title = {{$<$}research202011.Pdf{$>$}}
}

@article{zotero-163,
  title = {{$<$}sciadv.Abg5244.Pdf{$>$}}
}

@article{zotero-17,
  title = {{$<$}{{AnnRev2017final}}.Pdf{$>$}},
  doi = {10.1146/((please}
}

@online{zotero-2097,
  url = {https://chat.openai.com/},
  urldate = {2023-11-01},
  file = {D:\Zotero Storage\Zotero\storage\Y57BEF2M\chat.openai.com.html}
}

@article{zotero-2325,
  entrysubtype = {newspaper}
}

@misc{zotero-791,
  type = {misc}
}
